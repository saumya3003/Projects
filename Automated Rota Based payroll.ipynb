{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "467b2620-aa86-4999-b5cf-20fec1a6fd6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Name                         Email Company Client  \\\n",
      "0         ankit thakkar        ankit.thakkar@xxxx.com    XXXX   YYYY   \n",
      "1          Ayush Rajeev         ayush.rajeev@xxxx.com    XXXX   YYYY   \n",
      "2    muthumani gurusamy   muthumani.gurusamy@xxxx.com    XXXX   YYYY   \n",
      "3         sahil kanojia        sahil.kanojia@xxxx.com    XXXX   YYYY   \n",
      "4     nirmalraja selvam    nirmalraja.selvam@xxxx.com    XXXX   YYYY   \n",
      "5           Kapil Jugnu          kapil.jugnu@xxxx.com    XXXX   YYYY   \n",
      "6             akash dey            akash.dey@xxxx.com    XXXX   YYYY   \n",
      "7         vamshi bandla        vamshi.bandla@xxxx.com    XXXX   YYYY   \n",
      "8   Basudev Singh Munda        basudev.munda@xxxx.com    XXXX   YYYY   \n",
      "9     Prakash Rajendran    prakash.rajendran@xxxx.com    XXXX   YYYY   \n",
      "10         Ahalya Hegde         ahalya.hegde@xxxx.com    XXXX   YYYY   \n",
      "11         Dolly Chahar         dolly.chahar@xxxx.com    XXXX   YYYY   \n",
      "12     Durai Ramalingam     durai.ramalingam@xxxx.com    XXXX   YYYY   \n",
      "13       Jithin Johnson       jithin.johnson@xxxx.com    XXXX   YYYY   \n",
      "14     Durai Ramalingam     durai.ramalingam@xxxx.com    XXXX   YYYY   \n",
      "15       Jithin Johnson       jithin.johnson@xxxx.com    XXXX   YYYY   \n",
      "16     Durai Ramalingam     durai.ramalingam@xxxx.com    XXXX   YYYY   \n",
      "17  Keerthivasan Kannan  keerthivasan.kannan@xxxx.com    XXXX   YYYY   \n",
      "18  Keerthivasan Kannan  keerthivasan.kannan@xxxx.com    XXXX   YYYY   \n",
      "\n",
      "                Team Business Unit  From Date From Time    To Date   To Time  \\\n",
      "0            Backend           ITS 2025-02-10  05:30:00 2025-02-17  05:30:00   \n",
      "1            Backend           ITS 2025-02-03  05:30:00 2025-02-10  05:30:00   \n",
      "2            Backend           ITS 2025-02-24  05:30:00 2025-03-01  00:00:00   \n",
      "3                Web           ITS 2025-02-03  04:30:00 2025-02-10  04:30:00   \n",
      "4                Web           ITS 2025-02-10  04:30:00 2025-02-17  04:30:00   \n",
      "5                Web           ITS 2025-02-17  04:30:00 2025-02-24  04:30:00   \n",
      "6                Web           ITS 2025-02-01  00:00:00 2025-02-03  04:30:00   \n",
      "7      Data Pipeline          Data 2025-02-24  09:00:00 2025-03-01  00:00:00   \n",
      "8      Data Pipeline          Data 2025-02-03  09:00:00 2025-02-11  09:00:00   \n",
      "9      Data Pipeline          Data 2025-02-01  00:00:00 2025-02-03  09:00:00   \n",
      "10     Data Pipeline          Data 2025-02-11  09:00:00 2025-02-17  09:00:00   \n",
      "11     Data Pipeline          Data 2025-02-17  09:00:00 2025-02-24  09:00:00   \n",
      "12  Branded Business           ITS 2025-02-24  04:30:00 2025-03-01  00:00:00   \n",
      "13  Branded Business           ITS 2025-02-17  04:30:00 2025-02-24  04:30:00   \n",
      "14  Branded Business           ITS 2025-02-10  04:30:00 2025-02-17  04:30:00   \n",
      "15  Branded Business           ITS 2025-02-03  04:30:00 2025-02-10  04:30:00   \n",
      "16  Branded Business           ITS 2025-02-01  00:00:00 2025-02-03  04:30:00   \n",
      "17             Atlas         Atlas 2025-02-11  10:00:00 2025-02-16  01:43:00   \n",
      "18             Atlas         Atlas 2025-02-16  11:45:00 2025-02-18  10:00:00   \n",
      "\n",
      "    Total Duration  \n",
      "0              NaN  \n",
      "1              NaN  \n",
      "2              NaN  \n",
      "3              NaN  \n",
      "4              NaN  \n",
      "5              NaN  \n",
      "6              NaN  \n",
      "7              NaN  \n",
      "8              NaN  \n",
      "9              NaN  \n",
      "10             NaN  \n",
      "11             NaN  \n",
      "12             NaN  \n",
      "13             NaN  \n",
      "14             NaN  \n",
      "15             NaN  \n",
      "16             NaN  \n",
      "17             NaN  \n",
      "18             NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file\n",
    "file_path = \"C:/Users/HP/Desktop/finalCopy of PagerDutyLog - Feb.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Show the first few rows of data\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3b2e95e6-ec0f-4adf-8631-8890b9ad9fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Team     Total Worked (Formatted)\n",
      "0             Atlas   6 days 13 hours 58 minutes\n",
      "1           Backend  18 days 18 hours 30 minutes\n",
      "2  Branded Business    28 days 0 hours 0 minutes\n",
      "3     Data Pipeline    28 days 0 hours 0 minutes\n",
      "4               Web   23 days 4 hours 30 minutes\n",
      "                   Name                         Email Company Client  \\\n",
      "0         ankit thakkar        ankit.thakkar@xxxx.com    XXXX   YYYY   \n",
      "1          Ayush Rajeev         ayush.rajeev@xxxx.com    XXXX   YYYY   \n",
      "2    muthumani gurusamy   muthumani.gurusamy@xxxx.com    XXXX   YYYY   \n",
      "3         sahil kanojia        sahil.kanojia@xxxx.com    XXXX   YYYY   \n",
      "4     nirmalraja selvam    nirmalraja.selvam@xxxx.com    XXXX   YYYY   \n",
      "5           Kapil Jugnu          kapil.jugnu@xxxx.com    XXXX   YYYY   \n",
      "6             akash dey            akash.dey@xxxx.com    XXXX   YYYY   \n",
      "7         vamshi bandla        vamshi.bandla@xxxx.com    XXXX   YYYY   \n",
      "8   Basudev Singh Munda        basudev.munda@xxxx.com    XXXX   YYYY   \n",
      "9     Prakash Rajendran    prakash.rajendran@xxxx.com    XXXX   YYYY   \n",
      "10         Ahalya Hegde         ahalya.hegde@xxxx.com    XXXX   YYYY   \n",
      "11         Dolly Chahar         dolly.chahar@xxxx.com    XXXX   YYYY   \n",
      "12     Durai Ramalingam     durai.ramalingam@xxxx.com    XXXX   YYYY   \n",
      "13       Jithin Johnson       jithin.johnson@xxxx.com    XXXX   YYYY   \n",
      "14     Durai Ramalingam     durai.ramalingam@xxxx.com    XXXX   YYYY   \n",
      "15       Jithin Johnson       jithin.johnson@xxxx.com    XXXX   YYYY   \n",
      "16     Durai Ramalingam     durai.ramalingam@xxxx.com    XXXX   YYYY   \n",
      "17  Keerthivasan Kannan  keerthivasan.kannan@xxxx.com    XXXX   YYYY   \n",
      "18  Keerthivasan Kannan  keerthivasan.kannan@xxxx.com    XXXX   YYYY   \n",
      "\n",
      "                Team Business Unit  From Date From Time    To Date   To Time  \n",
      "0            Backend           ITS 2025-02-10  05:30:00 2025-02-17  05:30:00  \n",
      "1            Backend           ITS 2025-02-03  05:30:00 2025-02-10  05:30:00  \n",
      "2            Backend           ITS 2025-02-24  05:30:00 2025-03-01  00:00:00  \n",
      "3                Web           ITS 2025-02-03  04:30:00 2025-02-10  04:30:00  \n",
      "4                Web           ITS 2025-02-10  04:30:00 2025-02-17  04:30:00  \n",
      "5                Web           ITS 2025-02-17  04:30:00 2025-02-24  04:30:00  \n",
      "6                Web           ITS 2025-02-01  00:00:00 2025-02-03  04:30:00  \n",
      "7      Data Pipeline          Data 2025-02-24  09:00:00 2025-03-01  00:00:00  \n",
      "8      Data Pipeline          Data 2025-02-03  09:00:00 2025-02-11  09:00:00  \n",
      "9      Data Pipeline          Data 2025-02-01  00:00:00 2025-02-03  09:00:00  \n",
      "10     Data Pipeline          Data 2025-02-11  09:00:00 2025-02-17  09:00:00  \n",
      "11     Data Pipeline          Data 2025-02-17  09:00:00 2025-02-24  09:00:00  \n",
      "12  Branded Business           ITS 2025-02-24  04:30:00 2025-03-01  00:00:00  \n",
      "13  Branded Business           ITS 2025-02-17  04:30:00 2025-02-24  04:30:00  \n",
      "14  Branded Business           ITS 2025-02-10  04:30:00 2025-02-17  04:30:00  \n",
      "15  Branded Business           ITS 2025-02-03  04:30:00 2025-02-10  04:30:00  \n",
      "16  Branded Business           ITS 2025-02-01  00:00:00 2025-02-03  04:30:00  \n",
      "17             Atlas         Atlas 2025-02-11  10:00:00 2025-02-16  01:43:00  \n",
      "18             Atlas         Atlas 2025-02-16  11:45:00 2025-02-18  10:00:00  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_path = \"C:/Users/HP/Desktop/finalCopy of PagerDutyLog - Feb.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "\n",
    "# Add an empty 'duration' column to store the result\n",
    "df['duration'] = None\n",
    "\n",
    "for ind in df.index:\n",
    "    name1 = df[\"Name\"][ind]\n",
    "    email = df[\"Email\"][ind]\n",
    "    company = df[\"Company\"][ind]\n",
    "    client = df[\"Client\"][ind]\n",
    "    team = df[\"Team\"][ind]\n",
    "    bu = df[\"Business Unit\"][ind]\n",
    "\n",
    "    fromdate = df[\"From Date\"][ind]\n",
    "    fromtime = df[\"From Time\"][ind]\n",
    "    todate = df[\"To Date\"][ind]\n",
    "    totime = (df[\"To Time\"][ind])\n",
    "    # Combine From Date and Time\n",
    "df['From DateTime'] = pd.to_datetime(df['From Date'].astype(str) + ' ' + df['From Time'].astype(str), errors='coerce')\n",
    "\n",
    "# Combine To Date and Time\n",
    "df['To DateTime'] = pd.to_datetime(df['To Date'].astype(str) + ' ' + df['To Time'].astype(str), errors='coerce')\n",
    "\n",
    "# Calculate time worked\n",
    "df['Time Worked'] = df['To DateTime'] - df['From DateTime']\n",
    "\n",
    "# Group by Name and sum the actual timedelta column\n",
    "summary = df.groupby('Team')['Time Worked'].sum().reset_index()\n",
    "\n",
    "# Convert total timedelta to total seconds\n",
    "summary['Total Seconds'] = summary['Time Worked'].dt.total_seconds()\n",
    "\n",
    "# Convert to days, hours, and minutes\n",
    "summary['Days'] = (summary['Total Seconds'] // (24 * 3600)).astype(int)\n",
    "summary['Hours'] = ((summary['Total Seconds'] % (24 * 3600)) // 3600).astype(int)\n",
    "summary['Minutes'] = ((summary['Total Seconds'] % 3600) // 60).astype(int)\n",
    "\n",
    "# Create formatted string\n",
    "summary['Total Worked (Formatted)'] = (\n",
    "    summary['Days'].astype(str) + \" days \" +\n",
    "    summary['Hours'].astype(str) + \" hours \" +\n",
    "    summary['Minutes'].astype(str) + \" minutes\"\n",
    ")\n",
    "\n",
    "# Display the final summary\n",
    "print(summary[['Team', 'Total Worked (Formatted)']])\n",
    "\n",
    "\n",
    "\n",
    "# Finally, print the DataFrame with the new duration column\n",
    "print(df[['Name', 'Email','Company','Client','Team','Business Unit','From Date','From Time','To Date','To Time']])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "eae56d71-fcec-4c79-96ad-a5762cd7f38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Name    Total Worked (Formatted)\n",
      "0          Ahalya Hegde    6 days 0 hours 0 minutes\n",
      "1          Ayush Rajeev    7 days 0 hours 0 minutes\n",
      "2   Basudev Singh Munda    8 days 0 hours 0 minutes\n",
      "3          Dolly Chahar    7 days 0 hours 0 minutes\n",
      "4      Durai Ramalingam   14 days 0 hours 0 minutes\n",
      "5        Jithin Johnson   14 days 0 hours 0 minutes\n",
      "6           Kapil Jugnu    7 days 0 hours 0 minutes\n",
      "7   Keerthivasan Kannan  6 days 13 hours 58 minutes\n",
      "8     Prakash Rajendran    2 days 9 hours 0 minutes\n",
      "9             akash dey   2 days 4 hours 30 minutes\n",
      "10        ankit thakkar    7 days 0 hours 0 minutes\n",
      "11   muthumani gurusamy  4 days 18 hours 30 minutes\n",
      "12    nirmalraja selvam    7 days 0 hours 0 minutes\n",
      "13        sahil kanojia    7 days 0 hours 0 minutes\n",
      "14        vamshi bandla   4 days 15 hours 0 minutes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_path = \"C:/Users/HP/Desktop/finalCopy of PagerDutyLog - Feb.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    " # Combine From Date and Time\n",
    "df['From DateTime'] = pd.to_datetime(df['From Date'].astype(str) + ' ' + df['From Time'].astype(str), errors='coerce')\n",
    "\n",
    "# Combine To Date and Time\n",
    "df['To DateTime'] = pd.to_datetime(df['To Date'].astype(str) + ' ' + df['To Time'].astype(str), errors='coerce')\n",
    "\n",
    "# Calculate time worked\n",
    "df['Time Worked'] = df['To DateTime'] - df['From DateTime']\n",
    "\n",
    "# Group by Name and sum the actual timedelta column\n",
    "summary = df.groupby('Name')['Time Worked'].sum().reset_index()\n",
    "\n",
    "# Convert total timedelta to total seconds\n",
    "summary['Total Seconds'] = summary['Time Worked'].dt.total_seconds()\n",
    "\n",
    "# Convert to days, hours, and minutes\n",
    "summary['Days'] = (summary['Total Seconds'] // (24 * 3600)).astype(int)\n",
    "summary['Hours'] = ((summary['Total Seconds'] % (24 * 3600)) // 3600).astype(int)\n",
    "summary['Minutes'] = ((summary['Total Seconds'] % 3600) // 60).astype(int)\n",
    "\n",
    "# Create formatted string\n",
    "summary['Total Worked (Formatted)'] = (\n",
    "    summary['Days'].astype(str) + \" days \" +\n",
    "    summary['Hours'].astype(str) + \" hours \" +\n",
    "    summary['Minutes'].astype(str) + \" minutes\"\n",
    ")\n",
    "\n",
    "# Display the final summary\n",
    "print(summary[['Name', 'Total Worked (Formatted)']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "85fb9481-80ef-4252-8f75-f2d01c3e8fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Name       From DateTime         To DateTime  \\\n",
      "0         ankit thakkar 2025-02-10 05:30:00 2025-02-17 05:30:00   \n",
      "1          Ayush Rajeev 2025-02-03 05:30:00 2025-02-10 05:30:00   \n",
      "2    muthumani gurusamy 2025-02-24 05:30:00 2025-03-01 00:00:00   \n",
      "3         sahil kanojia 2025-02-03 04:30:00 2025-02-10 04:30:00   \n",
      "4     nirmalraja selvam 2025-02-10 04:30:00 2025-02-17 04:30:00   \n",
      "5           Kapil Jugnu 2025-02-17 04:30:00 2025-02-24 04:30:00   \n",
      "6             akash dey 2025-02-01 00:00:00 2025-02-03 04:30:00   \n",
      "7         vamshi bandla 2025-02-24 09:00:00 2025-03-01 00:00:00   \n",
      "8   Basudev Singh Munda 2025-02-03 09:00:00 2025-02-11 09:00:00   \n",
      "9     Prakash Rajendran 2025-02-01 00:00:00 2025-02-03 09:00:00   \n",
      "10         Ahalya Hegde 2025-02-11 09:00:00 2025-02-17 09:00:00   \n",
      "11         Dolly Chahar 2025-02-17 09:00:00 2025-02-24 09:00:00   \n",
      "12     Durai Ramalingam 2025-02-24 04:30:00 2025-03-01 00:00:00   \n",
      "13       Jithin Johnson 2025-02-17 04:30:00 2025-02-24 04:30:00   \n",
      "14     Durai Ramalingam 2025-02-10 04:30:00 2025-02-17 04:30:00   \n",
      "15       Jithin Johnson 2025-02-03 04:30:00 2025-02-10 04:30:00   \n",
      "16     Durai Ramalingam 2025-02-01 00:00:00 2025-02-03 04:30:00   \n",
      "17  Keerthivasan Kannan 2025-02-11 10:00:00 2025-02-16 01:43:00   \n",
      "18  Keerthivasan Kannan 2025-02-16 11:45:00 2025-02-18 10:00:00   \n",
      "\n",
      "   Time Worked (Formatted)  \n",
      "0           7 days 0 hours  \n",
      "1           7 days 0 hours  \n",
      "2          4 days 18 hours  \n",
      "3           7 days 0 hours  \n",
      "4           7 days 0 hours  \n",
      "5           7 days 0 hours  \n",
      "6           2 days 4 hours  \n",
      "7          4 days 15 hours  \n",
      "8           8 days 0 hours  \n",
      "9           2 days 9 hours  \n",
      "10          6 days 0 hours  \n",
      "11          7 days 0 hours  \n",
      "12         4 days 19 hours  \n",
      "13          7 days 0 hours  \n",
      "14          7 days 0 hours  \n",
      "15          7 days 0 hours  \n",
      "16          2 days 4 hours  \n",
      "17         4 days 15 hours  \n",
      "18         1 days 22 hours  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_excel(\"C:/Users/HP/Desktop/finalCopy of PagerDutyLog - Feb.xlsx\")\n",
    "\n",
    "# Combine From Date and Time\n",
    "df['From DateTime'] = pd.to_datetime(df['From Date'].astype(str) + ' ' + df['From Time'].astype(str), errors='coerce')\n",
    "\n",
    "# Combine To Date and Time\n",
    "df['To DateTime'] = pd.to_datetime(df['To Date'].astype(str) + ' ' + df['To Time'].astype(str), errors='coerce')\n",
    "\n",
    "# Calculate time worked\n",
    "df['Time Worked'] = df['To DateTime'] - df['From DateTime']\n",
    "\n",
    "# Format the time worked into days and hours\n",
    "df['Time Worked (Formatted)'] = df['Time Worked'].apply(\n",
    "    lambda td: f\"{td.days} days {td.seconds // 3600} hours\" if pd.notnull(td) else \"Invalid\"\n",
    ")\n",
    "\n",
    "# Show the result\n",
    "print(df[['Name', 'From DateTime', 'To DateTime', 'Time Worked (Formatted)']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "06ee79e9-2351-4381-9b80-14b6c4d51d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend -- 18 days 18.5 hours\n",
      "\n",
      "ankit thakkar : Backend --> 7 days 0.0 hours\n",
      "=====\n",
      "10 Feb 2025 05:30 To 17 Feb 2025 05:30\n",
      "=====\n",
      "\n",
      "Ayush Rajeev : Backend --> 7 days 0.0 hours\n",
      "=====\n",
      "03 Feb 2025 05:30 To 10 Feb 2025 05:30\n",
      "=====\n",
      "\n",
      "muthumani gurusamy : Backend --> 4 days 18.5 hours\n",
      "=====\n",
      "24 Feb 2025 05:30 To 01 Mar 2025 00:00\n",
      "=====\n",
      "Web -- 23 days 4.5 hours\n",
      "\n",
      "sahil kanojia : Web --> 7 days 0.0 hours\n",
      "=====\n",
      "03 Feb 2025 04:30 To 10 Feb 2025 04:30\n",
      "=====\n",
      "\n",
      "nirmalraja selvam : Web --> 7 days 0.0 hours\n",
      "=====\n",
      "10 Feb 2025 04:30 To 17 Feb 2025 04:30\n",
      "=====\n",
      "\n",
      "Kapil Jugnu : Web --> 7 days 0.0 hours\n",
      "=====\n",
      "17 Feb 2025 04:30 To 24 Feb 2025 04:30\n",
      "=====\n",
      "\n",
      "akash dey : Web --> 2 days 4.5 hours\n",
      "=====\n",
      "01 Feb 2025 00:00 To 03 Feb 2025 04:30\n",
      "=====\n",
      "Data Pipeline -- 28 days 0.0 hours\n",
      "\n",
      "vamshi bandla : Data Pipeline --> 4 days 15.0 hours\n",
      "=====\n",
      "24 Feb 2025 09:00 To 01 Mar 2025 00:00\n",
      "=====\n",
      "\n",
      "Basudev Singh Munda : Data Pipeline --> 8 days 0.0 hours\n",
      "=====\n",
      "03 Feb 2025 09:00 To 11 Feb 2025 09:00\n",
      "=====\n",
      "\n",
      "Prakash Rajendran : Data Pipeline --> 2 days 9.0 hours\n",
      "=====\n",
      "01 Feb 2025 00:00 To 03 Feb 2025 09:00\n",
      "=====\n",
      "\n",
      "Ahalya Hegde : Data Pipeline --> 6 days 0.0 hours\n",
      "=====\n",
      "11 Feb 2025 09:00 To 17 Feb 2025 09:00\n",
      "=====\n",
      "\n",
      "Dolly Chahar : Data Pipeline --> 7 days 0.0 hours\n",
      "=====\n",
      "17 Feb 2025 09:00 To 24 Feb 2025 09:00\n",
      "=====\n",
      "Branded Business -- 28 days 0.0 hours\n",
      "\n",
      "Durai Ramalingam : Branded Business --> 14 days 0.0 hours\n",
      "=====\n",
      "24 Feb 2025 04:30 To 01 Mar 2025 00:00\n",
      "10 Feb 2025 04:30 To 17 Feb 2025 04:30\n",
      "01 Feb 2025 00:00 To 03 Feb 2025 04:30\n",
      "=====\n",
      "\n",
      "Jithin Johnson : Branded Business --> 14 days 0.0 hours\n",
      "=====\n",
      "17 Feb 2025 04:30 To 24 Feb 2025 04:30\n",
      "03 Feb 2025 04:30 To 10 Feb 2025 04:30\n",
      "=====\n",
      "Atlas -- 6 days 14.0 hours\n",
      "\n",
      "Keerthivasan Kannan : Atlas --> 6 days 14.0 hours\n",
      "=====\n",
      "11 Feb 2025 10:00 To 16 Feb 2025 01:43\n",
      "16 Feb 2025 11:45 To 18 Feb 2025 10:00\n",
      "=====\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Load Excel data (replace with your file path if needed)\n",
    "df = pd.read_excel(\"C:/Users/HP/Desktop/finalCopy of PagerDutyLog - Feb.xlsx\")\n",
    "\n",
    "# Combine 'From Date' and 'From Time' into a single datetime\n",
    "df['Start Time'] = pd.to_datetime(df['From Date'].astype(str) + ' ' + df['From Time'].astype(str))\n",
    "\n",
    "# Combine 'To Date' and 'To Time' into a single datetime\n",
    "df['End Time'] = pd.to_datetime(df['To Date'].astype(str) + ' ' + df['To Time'].astype(str))\n",
    "\n",
    "# Calculate duration in hours\n",
    "df['Duration'] = (df['End Time'] - df['Start Time']).dt.total_seconds() / 3600\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Get list of unique teams\n",
    "teams = df['Team'].unique()\n",
    "\n",
    "# Loop over each team\n",
    "for team in teams:\n",
    "    team_df = df[df['Team'] == team]\n",
    "    team_total = team_df['Duration'].sum()\n",
    "    days = int(team_total // 24)\n",
    "    hours = round(team_total % 24, 1)\n",
    "    print(team + \" -- \" + str(days) + \" days \" + str(hours) + \" hours\")\n",
    "\n",
    "    # Get unique names under this team\n",
    "    names = team_df['Name'].unique()\n",
    "    \n",
    "    for name in names:\n",
    "        name_df = team_df[team_df['Name'] == name]\n",
    "        name_total = name_df['Duration'].sum()\n",
    "        name_days = int(name_total // 24)\n",
    "        name_hours = round(name_total % 24, 1)\n",
    "\n",
    "        print(\"\")  # spacing\n",
    "        print(name + \" : \" + team + \" --> \" + str(name_days) + \" days \" + str(name_hours) + \" hours\")\n",
    "        print(\"=====\")  # One opening bar\n",
    "\n",
    "        # Print all shift blocks (without surrounding each one with \"=====\")\n",
    "        for i in range(len(name_df)):\n",
    "            row = name_df.iloc[i]\n",
    "            start = row['Start Time'].strftime('%d %b %Y %H:%M')\n",
    "            end = row['End Time'].strftime('%d %b %Y %H:%M')\n",
    "            print(start + \" To \" + end)\n",
    "\n",
    "        print(\"=====\")  # One closing bar\n",
    "\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c7f46e56-8a5f-4c2c-8b9e-38aa9ae663a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Load Excel data (replace with your file path if needed)\n",
    "df = pd.read_excel(\"C:/Users/HP/Desktop/finalCopy of PagerDutyLog - Feb.xlsx\")\n",
    "\n",
    "# Combine 'From Date' and 'From Time' into a single datetime\n",
    "df['Start Time'] = pd.to_datetime(df['From Date'].astype(str) + ' ' + df['From Time'].astype(str))\n",
    "\n",
    "# Combine 'To Date' and 'To Time' into a single datetime\n",
    "df['End Time'] = pd.to_datetime(df['To Date'].astype(str) + ' ' + df['To Time'].astype(str))\n",
    "\n",
    "# Calculate duration in hours\n",
    "df['Duration'] = (df['End Time'] - df['Start Time']).dt.total_seconds() / 3600\n",
    "\n",
    "# Get list of unique teams\n",
    "teams = df['Team'].unique()\n",
    "\n",
    "with open(\"output.txt\", \"w\") as file:\n",
    "    for team in teams:\n",
    "        team_df = df[df['Team'] == team]\n",
    "        team_total = team_df['Duration'].sum()\n",
    "        days = int(team_total // 24)\n",
    "        hours = round(team_total % 24, 1)\n",
    "        file.write(team + \" -- \" + str(days) + \" days \" + str(hours) + \" hours\\n\")\n",
    "\n",
    "        # Get unique names under this team\n",
    "        names = team_df['Name'].unique()\n",
    "        \n",
    "        for name in names:\n",
    "            name_df = team_df[team_df['Name'] == name]\n",
    "            name_total = name_df['Duration'].sum()\n",
    "            name_days = int(name_total // 24)\n",
    "            name_hours = round(name_total % 24, 1)\n",
    "\n",
    "            file.write(\"\\n\")  # spacing\n",
    "            file.write(name + \" : \" + team + \" --> \" + str(name_days) + \" days \" + str(name_hours) + \" hours\\n\")\n",
    "            file.write(\"=====\\n\")  # One opening bar\n",
    "\n",
    "            # Print all shift blocks (without surrounding each one with \"=====\")\n",
    "            for i in range(len(name_df)):\n",
    "                row = name_df.iloc[i]\n",
    "                start = row['Start Time'].strftime('%d %b %Y %H:%M')\n",
    "                end = row['End Time'].strftime('%d %b %Y %H:%M')\n",
    "                file.write(start + \" To \" + end + \"\\n\")\n",
    "\n",
    "            file.write(\"=====\\n\")  # One closing bar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "621e6f7f-3488-4f4c-a66d-a5cc2b471ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                         Name                  From DateTime                    To DateTime\n",
      "0                                               ankit thakkar            2025-02-10 05:30:00            2025-02-17 05:30:00\n",
      "1                                                Ayush Rajeev            2025-02-03 05:30:00            2025-02-10 05:30:00\n",
      "2                                          muthumani gurusamy            2025-02-24 05:30:00            2025-03-01 00:00:00\n",
      "3                                               sahil kanojia            2025-02-03 04:30:00            2025-02-10 04:30:00\n",
      "4                                           nirmalraja selvam            2025-02-10 04:30:00            2025-02-17 04:30:00\n",
      "5                                                 Kapil Jugnu            2025-02-17 04:30:00            2025-02-24 04:30:00\n",
      "6                                                   akash dey            2025-02-01 00:00:00            2025-02-03 04:30:00\n",
      "7                                               vamshi bandla            2025-02-24 09:00:00            2025-03-01 00:00:00\n",
      "8                                         Basudev Singh Munda            2025-02-03 09:00:00            2025-02-11 09:00:00\n",
      "9                                           Prakash Rajendran            2025-02-01 00:00:00            2025-02-03 09:00:00\n",
      "10                                               Ahalya Hegde            2025-02-11 09:00:00            2025-02-17 09:00:00\n",
      "11                                               Dolly Chahar            2025-02-17 09:00:00            2025-02-24 09:00:00\n",
      "12                                           Durai Ramalingam            2025-02-24 04:30:00            2025-03-01 00:00:00\n",
      "13                                             Jithin Johnson            2025-02-17 04:30:00            2025-02-24 04:30:00\n",
      "14                                           Durai Ramalingam            2025-02-10 04:30:00            2025-02-17 04:30:00\n",
      "15                                             Jithin Johnson            2025-02-03 04:30:00            2025-02-10 04:30:00\n",
      "16                                           Durai Ramalingam            2025-02-01 00:00:00            2025-02-03 04:30:00\n",
      "17                                        Keerthivasan Kannan            2025-02-11 10:00:00            2025-02-16 01:43:00\n",
      "18                                        Keerthivasan Kannan            2025-02-16 11:45:00            2025-02-18 10:00:00\n",
      "                 Name       From DateTime         To DateTime  Days Worked  \\\n",
      "0       ankit thakkar 2025-02-10 05:30:00 2025-02-17 05:30:00            7   \n",
      "1        Ayush Rajeev 2025-02-03 05:30:00 2025-02-10 05:30:00            7   \n",
      "2  muthumani gurusamy 2025-02-24 05:30:00 2025-03-01 00:00:00            4   \n",
      "3       sahil kanojia 2025-02-03 04:30:00 2025-02-10 04:30:00            7   \n",
      "4   nirmalraja selvam 2025-02-10 04:30:00 2025-02-17 04:30:00            7   \n",
      "\n",
      "   Hours Worked  \n",
      "0           0.0  \n",
      "1           0.0  \n",
      "2          18.5  \n",
      "3           0.0  \n",
      "4           0.0  \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Client/Project'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[90], line 66\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28mprint\u001b[39m(df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrom DateTime\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTo DateTime\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDays Worked\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHours Worked\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mhead())\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# Group by Name and Department, and sum the total days and hours worked\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m summary \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClient/Project\u001b[39m\u001b[38;5;124m'\u001b[39m])[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDays Worked\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHours Worked\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# Sort the result (optional, for readability)\u001b[39;00m\n\u001b[0;32m     69\u001b[0m summary \u001b[38;5;241m=\u001b[39m summary\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClient/Project\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:9183\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[0;32m   9180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   9181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 9183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameGroupBy(\n\u001b[0;32m   9184\u001b[0m     obj\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   9185\u001b[0m     keys\u001b[38;5;241m=\u001b[39mby,\n\u001b[0;32m   9186\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   9187\u001b[0m     level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   9188\u001b[0m     as_index\u001b[38;5;241m=\u001b[39mas_index,\n\u001b[0;32m   9189\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m   9190\u001b[0m     group_keys\u001b[38;5;241m=\u001b[39mgroup_keys,\n\u001b[0;32m   9191\u001b[0m     observed\u001b[38;5;241m=\u001b[39mobserved,\n\u001b[0;32m   9192\u001b[0m     dropna\u001b[38;5;241m=\u001b[39mdropna,\n\u001b[0;32m   9193\u001b[0m )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1329\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[0;32m   1328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1329\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m get_grouper(\n\u001b[0;32m   1330\u001b[0m         obj,\n\u001b[0;32m   1331\u001b[0m         keys,\n\u001b[0;32m   1332\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   1333\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   1334\u001b[0m         sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m   1335\u001b[0m         observed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default \u001b[38;5;28;01melse\u001b[39;00m observed,\n\u001b[0;32m   1336\u001b[0m         dropna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna,\n\u001b[0;32m   1337\u001b[0m     )\n\u001b[0;32m   1339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[0;32m   1340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping\u001b[38;5;241m.\u001b[39m_passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper\u001b[38;5;241m.\u001b[39mgroupings):\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\grouper.py:1043\u001b[0m, in \u001b[0;36mget_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[0;32m   1041\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1043\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1045\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[0;32m   1046\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Client/Project'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read your Excel file\n",
    "df = pd.read_excel(\"C:/Users/HP/Desktop/finalCopy of PagerDutyLog - Feb.xlsx\")\n",
    "\n",
    "# Create empty lists for cleaned datetime values\n",
    "from_datetime = []\n",
    "to_datetime = []\n",
    "\n",
    "# Loop through each row in the DataFrame\n",
    "for i in df.index:\n",
    "    # Combine and parse From Date and Time\n",
    "    from_date = str(df.loc[i, 'From Date']).strip()\n",
    "    from_time = str(df.loc[i, 'From Time']).strip()\n",
    "    try:\n",
    "        from_dt = pd.to_datetime(from_date + ' ' + from_time)\n",
    "    except Exception:\n",
    "        from_dt = None  # or use pd.NaT\n",
    "    from_datetime.append(from_dt)\n",
    "\n",
    "    # Combine and parse To Date and Time\n",
    "    to_date = str(df.loc[i, 'To Date']).strip()\n",
    "    to_time = str(df.loc[i, 'To Time']).strip()\n",
    "    try:\n",
    "        to_dt = pd.to_datetime(to_date + ' ' + to_time)\n",
    "    except Exception:\n",
    "        to_dt = None\n",
    "    to_datetime.append(to_dt)\n",
    "\n",
    "# Add the clean datetime values back to the DataFrame\n",
    "df['From DateTime'] = from_datetime\n",
    "df['To DateTime'] = to_datetime\n",
    "\n",
    "# Show first few rows to confirm\n",
    "print(df[['Name', 'From DateTime', 'To DateTime']].to_string(col_space=30))\n",
    "# Calculate the duration between From and To times\n",
    "durations = []\n",
    "days_worked = []\n",
    "hours_worked = []\n",
    "\n",
    "for i in df.index:\n",
    "    start = df.loc[i, 'From DateTime']\n",
    "    end = df.loc[i, 'To DateTime']\n",
    "\n",
    "    if pd.notnull(start) and pd.notnull(end):\n",
    "        duration = end - start\n",
    "        days = duration.days\n",
    "        hours = round(duration.seconds / 3600, 1)\n",
    "    else:\n",
    "        duration = None\n",
    "        days = 0\n",
    "        hours = 0.0\n",
    "\n",
    "    durations.append(duration)\n",
    "    days_worked.append(days)\n",
    "    hours_worked.append(hours)\n",
    "\n",
    "# Add the new columns to the DataFrame\n",
    "df['Duration'] = durations\n",
    "df['Days Worked'] = days_worked\n",
    "df['Hours Worked'] = hours_worked\n",
    "\n",
    "# Preview the result\n",
    "print(df[['Name', 'From DateTime', 'To DateTime', 'Days Worked', 'Hours Worked']].head())\n",
    "# Group by Name and Department, and sum the total days and hours worked\n",
    "summary = df.groupby(['Name', 'Client/Project'])[['Days Worked', 'Hours Worked']].sum().reset_index()\n",
    "\n",
    "# Sort the result (optional, for readability)\n",
    "summary = summary.sort_values(by=['Client/Project', 'Name'])\n",
    "\n",
    "# Show the final summary\n",
    "print(summary)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351c9a2f-f9e8-48c6-a697-84ecc9411e26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf2d6b99-42a8-4d24-81ef-8364f805fb7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Name  Extra Hours\n",
      "0         Ayush Rajeev          1.2\n",
      "1     Durai Ramalingam          0.5\n",
      "2          Kapil Jugnu          1.3\n",
      "3  Keerthivasan Kannan          1.2\n",
      "4   Muthumani Gurusamy          0.5\n",
      "5        ankit thakkar          0.3\n"
     ]
    }
   ],
   "source": [
    "# Read extra hours Excel file\n",
    "extra_df = pd.read_excel(\"C:/Users/HP/Desktop/finalCopy of ExtraHoursLog - Feb.xlsx\")\n",
    "extra_df.columns = extra_df.columns.astype(str)\n",
    "\n",
    "# Get date columns (they are usually numeric like \"1\", \"2\", ..., \"28\")\n",
    "date_columns = [col for col in extra_df.columns if col.isdigit()]\n",
    "\n",
    "# Reshape from wide to long\n",
    "melted = extra_df.melt(id_vars=[\"Name\"], value_vars=date_columns, var_name=\"Day\", value_name=\"Minutes\")\n",
    "melted.dropna(subset=[\"Minutes\"], inplace=True)\n",
    "melted[\"Minutes\"] = melted[\"Minutes\"].astype(float)\n",
    "\n",
    "# Sum and convert to hours\n",
    "extra_summary = melted.groupby(\"Name\")[\"Minutes\"].sum().reset_index()\n",
    "extra_summary[\"Extra Hours\"] = (extra_summary[\"Minutes\"] / 60).round(1)\n",
    "extra_summary.drop(columns=[\"Minutes\"], inplace=True)  # remove the 'Minutes' column\n",
    "print(extra_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9df92329-6eed-41de-9cdf-3379f7eb9b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Employee name      Start Datetime        End Datetime Start Weekday  \\\n",
      "0  Keerthivasan Kannan                 NaT                 NaT           NaN   \n",
      "1        Ankit Thakkar 2025-02-10 05:30:00 2025-02-17 05:30:00        Monday   \n",
      "2         Ayush Rajeev 2025-02-03 05:30:00 2025-02-10 05:30:00        Monday   \n",
      "3   Muthumani Gurusamy 2025-02-24 05:30:00 2025-03-01 00:00:00        Monday   \n",
      "4     Durai Ramalingam                 NaT                 NaT           NaN   \n",
      "5       Jithin Johnson                 NaT                 NaT           NaN   \n",
      "6         Ahalya Hegde 2025-02-11 09:00:00 2025-02-17 09:00:00       Tuesday   \n",
      "7  Basudev Singh Munda 2025-02-03 09:00:00 2025-02-11 09:00:00        Monday   \n",
      "8         Dolly Chahar 2025-02-17 09:00:00 2025-02-24 09:00:00        Monday   \n",
      "9    Prakash Rajendran 2025-02-01 00:00:00 2025-02-03 09:00:00      Saturday   \n",
      "\n",
      "  End Weekday  Duration (days)  \n",
      "0         NaN              NaN  \n",
      "1      Monday         7.000000  \n",
      "2      Monday         7.000000  \n",
      "3    Saturday         4.770833  \n",
      "4         NaN              NaN  \n",
      "5         NaN              NaN  \n",
      "6      Monday         6.000000  \n",
      "7     Tuesday         8.000000  \n",
      "8      Monday         7.000000  \n",
      "9      Monday         2.375000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Load the Excel file\n",
    "df = pd.read_excel(\"C:/Users/HP/Desktop/Copy of Final_Oncall_Data_Feb (1).xlsx\")\n",
    "\n",
    "# Function to extract datetimes using split\n",
    "def extract_datetimes_simple(date_str):\n",
    "    try:\n",
    "        parts = str(date_str).split(\" To \")\n",
    "        start_str = parts[0].strip()           # e.g., \"Mon, Feb 10 @ 05:30\"\n",
    "        end_str = parts[1].strip()             # e.g., \"Mon, Feb 17 @ 05:30\"\n",
    "        \n",
    "        start_dt = datetime.strptime(start_str, \"%a, %b %d @ %H:%M\").replace(year=2025)\n",
    "        end_dt = datetime.strptime(end_str, \"%a, %b %d @ %H:%M\").replace(year=2025)\n",
    "        \n",
    "        return start_dt, end_dt\n",
    "    except:\n",
    "        return None, None\n",
    "\n",
    "# Apply function to DataFrame\n",
    "df['Start Datetime'], df['End Datetime'] = zip(*df['Date'].apply(extract_datetimes_simple))\n",
    "\n",
    "# Compute additional columns\n",
    "df['Duration (days)'] = (df['End Datetime'] - df['Start Datetime']).dt.total_seconds() / (3600 * 24)\n",
    "df['Start Weekday'] = df['Start Datetime'].dt.strftime('%A')\n",
    "df['End Weekday'] = df['End Datetime'].dt.strftime('%A')\n",
    "\n",
    "# Display result\n",
    "print(df[['Employee name', 'Start Datetime', 'End Datetime', 'Start Weekday', 'End Weekday', 'Duration (days)']].head(10))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1af1a96-1fca-410f-9f9d-36b11261dfb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Employee name                                      Date_1  \\\n",
      "0   Keerthivasan Kannan  Tue, Feb 11 @ 10:00 To Sun, Feb 16 @ 01:43   \n",
      "1         Ankit Thakkar  Mon, Feb 10 @ 05:30 To Mon, Feb 17 @ 05:30   \n",
      "2          Ayush Rajeev  Mon, Feb 03 @ 05:30 To Mon, Feb 10 @ 05:30   \n",
      "3    Muthumani Gurusamy  Mon, Feb 24 @ 05:30 To Sat, Mar 01 @ 00:00   \n",
      "4      Durai Ramalingam  Mon, Feb 24 @ 04:30 To Sat, Mar 01 @ 00:00   \n",
      "5        Jithin Johnson  Mon, Feb 17 @ 04:30 To Mon, Feb 24 @ 04:30   \n",
      "6          Ahalya Hegde  Tue, Feb 11 @ 09:00 To Mon, Feb 17 @ 09:00   \n",
      "7   Basudev Singh Munda  Mon, Feb 03 @ 09:00 To Tue, Feb 11 @ 09:00   \n",
      "8          Dolly Chahar  Mon, Feb 17 @ 09:00 To Mon, Feb 24 @ 09:00   \n",
      "9     Prakash Rajendran  Sat, Feb 01 @ 00:00 To Mon, Feb 03 @ 09:00   \n",
      "10        Vamshi Bandla  Mon, Feb 24 @ 09:00 To Sat, Mar 01 @ 00:00   \n",
      "11            Akash Dey  Sat, Feb 01 @ 00:00 To Mon, Feb 03 @ 04:30   \n",
      "12          Kapil Jugnu  Mon, Feb 17 @ 04:30 To Mon, Feb 24 @ 04:30   \n",
      "13    Nirmalraja Selvam  Mon, Feb 10 @ 04:30 To Mon, Feb 17 @ 04:30   \n",
      "14        Sahil Kanojia  Mon, Feb 03 @ 04:30 To Mon, Feb 10 @ 04:30   \n",
      "\n",
      "                                               Date_2      Start Datetime  \\\n",
      "0          Sun, Feb 16 @ 11:45 To Tue, Feb 18 @ 10:00 2025-02-11 10:00:00   \n",
      "1                                                None 2025-02-10 05:30:00   \n",
      "2                                                None 2025-02-03 05:30:00   \n",
      "3                                                None 2025-02-24 05:30:00   \n",
      "4   Mon, Feb 10 @ 04:30 To Mon, Feb 17 @ 04:30 | S... 2025-02-24 04:30:00   \n",
      "5          Mon, Feb 03 @ 04:30 To Mon, Feb 10 @ 04:30 2025-02-17 04:30:00   \n",
      "6                                                None 2025-02-11 09:00:00   \n",
      "7                                                None 2025-02-03 09:00:00   \n",
      "8                                                None 2025-02-17 09:00:00   \n",
      "9                                                None 2025-02-01 00:00:00   \n",
      "10                                               None 2025-02-24 09:00:00   \n",
      "11                                               None 2025-02-01 00:00:00   \n",
      "12                                               None 2025-02-17 04:30:00   \n",
      "13                                               None 2025-02-10 04:30:00   \n",
      "14                                               None 2025-02-03 04:30:00   \n",
      "\n",
      "          End Datetime Start Weekday End Weekday  Duration (days)  \n",
      "0  2025-02-16 01:43:00       Tuesday      Sunday         4.654861  \n",
      "1  2025-02-17 05:30:00        Monday      Monday         7.000000  \n",
      "2  2025-02-10 05:30:00        Monday      Monday         7.000000  \n",
      "3  2025-03-01 00:00:00        Monday    Saturday         4.770833  \n",
      "4  2025-03-01 00:00:00        Monday    Saturday         4.812500  \n",
      "5  2025-02-24 04:30:00        Monday      Monday         7.000000  \n",
      "6  2025-02-17 09:00:00       Tuesday      Monday         6.000000  \n",
      "7  2025-02-11 09:00:00        Monday     Tuesday         8.000000  \n",
      "8  2025-02-24 09:00:00        Monday      Monday         7.000000  \n",
      "9  2025-02-03 09:00:00      Saturday      Monday         2.375000  \n",
      "10 2025-03-01 00:00:00        Monday    Saturday         4.625000  \n",
      "11 2025-02-03 04:30:00      Saturday      Monday         2.187500  \n",
      "12 2025-02-24 04:30:00        Monday      Monday         7.000000  \n",
      "13 2025-02-17 04:30:00        Monday      Monday         7.000000  \n",
      "14 2025-02-10 04:30:00        Monday      Monday         7.000000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Load the Excel file\n",
    "df = pd.read_excel(\"C:/Users/HP/Desktop/Copy of Final_Oncall_Data_Feb (1).xlsx\")\n",
    "\n",
    "# --- STEP 1: Extract Date_1 and Date_2 manually using loop ---\n",
    "date_1_list = []\n",
    "date_2_list = []\n",
    "\n",
    "for val in df['Date'].astype(str):\n",
    "    separator_index = None\n",
    "    for i, char in enumerate(val):\n",
    "        if char == '|':\n",
    "            separator_index = i\n",
    "            break\n",
    "\n",
    "    if separator_index is not None:\n",
    "        date_1 = val[:separator_index].strip()\n",
    "        date_2 = val[separator_index + 1:].strip()\n",
    "    else:\n",
    "        date_1 = val.strip()\n",
    "        date_2 = None\n",
    "\n",
    "    date_1_list.append(date_1)\n",
    "    date_2_list.append(date_2)\n",
    "\n",
    "df['Date_1'] = date_1_list\n",
    "df['Date_2'] = date_2_list\n",
    "\n",
    "# --- STEP 2: Function to extract start/end datetimes from Date_1 ---\n",
    "def extract_datetimes_simple(date_str):\n",
    "    try:\n",
    "        parts = date_str.split(\" To \")  # safe here as we already cleaned the string\n",
    "        start_str = parts[0].strip()    # e.g., \"Mon, Feb 10 @ 05:30\"\n",
    "        end_str = parts[1].strip()      # e.g., \"Mon, Feb 17 @ 05:30\"\n",
    "        \n",
    "        start_dt = datetime.strptime(start_str, \"%a, %b %d @ %H:%M\").replace(year=2025)\n",
    "        end_dt = datetime.strptime(end_str, \"%a, %b %d @ %H:%M\").replace(year=2025)\n",
    "        \n",
    "        return start_dt, end_dt\n",
    "    except:\n",
    "        return None, None\n",
    "\n",
    "# Apply function to Date_1\n",
    "df['Start Datetime'], df['End Datetime'] = zip(*df['Date_1'].apply(extract_datetimes_simple))\n",
    "\n",
    "# --- STEP 3: Additional columns ---\n",
    "df['Duration (days)'] = (df['End Datetime'] - df['Start Datetime']).dt.total_seconds() / (3600 * 24)\n",
    "df['Start Weekday'] = df['Start Datetime'].dt.strftime('%A')\n",
    "df['End Weekday'] = df['End Datetime'].dt.strftime('%A')\n",
    "\n",
    "# --- Display Output ---\n",
    "print(df[['Employee name', 'Date_1', 'Date_2', 'Start Datetime', 'End Datetime', 'Start Weekday', 'End Weekday', 'Duration (days)']].head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5f234482-39a8-4ab9-bf13-2488dc06d36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Load the Excel file\n",
    "df = pd.read_excel(\"C:/Users/HP/Desktop/Copy of Final_Oncall_Data_Feb (1).xlsx\")\n",
    "\n",
    "def extract_work_summary(w_or_h):\n",
    "    lines = str(w_or_h).split('\\n')\n",
    "    result = {}\n",
    "    \n",
    "    for line in lines:\n",
    "        parts = line.split(':')\n",
    "        if len(parts) != 2:\n",
    "            continue\n",
    "        \n",
    "        label = parts[0].strip()\n",
    "        values = parts[1].strip().split(',')\n",
    "        \n",
    "        if len(values) >= 2:\n",
    "            days_part = values[0].strip().split(' ')[0]\n",
    "            hours_part = values[1].strip().split(' ')[0]\n",
    "            \n",
    "            if label == 'Weekdays':\n",
    "                result['Weekday Days'] = int(days_part)\n",
    "                result['Weekday Hours'] = float(hours_part)\n",
    "            elif label == 'Weekends':\n",
    "                result['Weekend Days'] = int(days_part)\n",
    "                result['Weekend Hours'] = float(hours_part)\n",
    "    \n",
    "    print(f\"Parsed: {result}\")  #  Add this line\n",
    "    return pd.Series(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "60269684-25e3-49be-a5ba-232ecb157ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed: {}\n",
      "Parsed: {}\n",
      "Parsed: {}\n",
      "Parsed: {}\n",
      "Parsed: {}\n",
      "Parsed: {}\n",
      "Parsed: {}\n",
      "Parsed: {}\n",
      "Parsed: {}\n",
      "Parsed: {}\n",
      "Parsed: {}\n",
      "Parsed: {}\n",
      "Parsed: {}\n",
      "Parsed: {}\n",
      "Parsed: {}\n"
     ]
    }
   ],
   "source": [
    "df_extracted = df['W or H'].apply(extract_work_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "29730427-c5b0-4582-baa8-c2e69b8d1273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=0, step=1)\n"
     ]
    }
   ],
   "source": [
    "print(df_extracted.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ab24645d-5917-4c16-a333-0e908a41d7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Employee name                                             W or H\n",
      "0  Keerthivasan Kannan  Weekdays - 5 days, 0.00 hours\\nWeekends/Holida...\n",
      "1        Ankit Thakkar  Weekdays - 5 days, 0.00 hours\\nWeekends/Holida...\n",
      "2         Ayush Rajeev  Weekdays - 5 days, 0.00 hours\\nWeekends/Holida...\n",
      "3   Muthumani Gurusamy  Weekdays - 4 days, 18.50 hours\\nWeekends/Holid...\n",
      "4     Durai Ramalingam  Weekdays - 10 days, 0.00 hours\\nWeekends/Holid...\n",
      "5       Jithin Johnson  Weekdays - 10 days, 0.00 hours\\nWeekends/Holid...\n",
      "6         Ahalya Hegde  Weekdays - 4 days, 0.00 hours\\nWeekends/Holida...\n",
      "7  Basudev Singh Munda  Weekdays - 6 days, 0.00 hours\\nWeekends/Holida...\n",
      "8         Dolly Chahar  Weekdays - 5 days, 0.00 hours\\nWeekends/Holida...\n",
      "9    Prakash Rajendran  Weekdays - 0 days, 9.00 hours\\nWeekends/Holida...\n"
     ]
    }
   ],
   "source": [
    "df = df.join(df_extracted)\n",
    "\n",
    "# Safe print using intersection with actual columns\n",
    "expected_cols = ['Weekday Days', 'Weekday Hours', 'Weekend Days', 'Weekend Hours']\n",
    "available_cols = [col for col in expected_cols if col in df.columns]\n",
    "\n",
    "print(df[['Employee name', 'W or H'] + available_cols].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da065eea-d425-468e-a0bb-257516bd95a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def extract_work_summary(w_or_h):\n",
    "    text = str(w_or_h)\n",
    "    result = {}\n",
    "\n",
    "    # Pattern for Weekdays - 5 days, 0.00 hours\n",
    "    match_wd = re.search(r'Weekdays\\s*-\\s*(\\d+)\\s+days,\\s*([\\d.]+)\\s+hours', text)\n",
    "    match_we = re.search(r'Weekends/Holidays\\s*-\\s*(\\d+)\\s+days,\\s*([\\d.]+)\\s+hours', text)\n",
    "\n",
    "    if match_wd:\n",
    "        result['Weekday Days'] = int(match_wd.group(1))\n",
    "        result['Weekday Hours'] = float(match_wd.group(2))\n",
    "\n",
    "    if match_we:\n",
    "        result['Weekend Days'] = int(match_we.group(1))\n",
    "        result['Weekend Hours'] = float(match_we.group(2))\n",
    "\n",
    "    print(f\"Parsed: {result}\")\n",
    "    return pd.Series(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8897a6bd-b201-48c5-80f9-ae4d1fb7472b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed: {'Weekday Days': 5, 'Weekday Hours': 8.0, 'Weekend Days': 2, 'Weekend Hours': 4.5}\n",
      "Weekday Days     5.0\n",
      "Weekday Hours    8.0\n",
      "Weekend Days     2.0\n",
      "Weekend Hours    4.5\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def extract_work_summary(w_or_h):\n",
    "    text = str(w_or_h)\n",
    "    result = {}\n",
    "\n",
    "    # Pattern for Weekdays - 5 days, 0.00 hours\n",
    "    match_wd = re.search(r'Weekdays\\s*-\\s*(\\d+)\\s+days,\\s*([\\d.]+)\\s+hours', text)\n",
    "    match_we = re.search(r'Weekends/Holidays\\s*-\\s*(\\d+)\\s+days,\\s*([\\d.]+)\\s+hours', text)\n",
    "\n",
    "    if match_wd:\n",
    "        result['Weekday Days'] = int(match_wd.group(1))\n",
    "        result['Weekday Hours'] = float(match_wd.group(2))\n",
    "\n",
    "    if match_we:\n",
    "        result['Weekend Days'] = int(match_we.group(1))\n",
    "        result['Weekend Hours'] = float(match_we.group(2))\n",
    "\n",
    "    print(f\"Parsed: {result}\")\n",
    "    return pd.Series(result)\n",
    "\n",
    "# Call the function with a sample input:\n",
    "output = extract_work_summary(\"Weekdays - 5 days, 8.00 hours\\nWeekends/Holidays - 2 days, 4.50 hours\")\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a30e466b-98c7-4214-835a-525c2306a990",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Weekday Days', 'Weekday Hours', 'Weekend Days', 'Weekend Hours'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m df_summary \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df, weekday_data, weekend_data], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Optional: Summarize total by name or email\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m summary \u001b[38;5;241m=\u001b[39m (df[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWeekday Days\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWeekday Hours\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWeekend Days\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWeekend Hours\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mreset_index())\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Display result\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(summary)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[0;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[1;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['Weekday Days', 'Weekday Hours', 'Weekend Days', 'Weekend Hours'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file\n",
    "df = pd.read_excel(\"C:/Users/HP/Desktop/Copy of Final_Oncall_Data_Feb (1).xlsx\")\n",
    "\n",
    "# Adjust the column name based on your sheet (e.g., \"W\" or \"H\")\n",
    "# Let's assume column \"W\" has the required text\n",
    "weekday_data = df[\"W or H\"].str.extract(r'Weekdays\\s*-\\s*(\\d+)\\s*days,\\s*([\\d.]+)\\s*hours')\n",
    "weekend_data = df[\"W or H\"].str.extract(r'Weekends/Holidays\\s*-\\s*(\\d+)\\s*days,\\s*([\\d.]+)\\s*hours')\n",
    "\n",
    "# Convert to numeric\n",
    "weekday_data.columns = ['Weekday Days', 'Weekday Hours']\n",
    "weekend_data.columns = ['Weekend Days', 'Weekend Hours']\n",
    "weekday_data = weekday_data.apply(pd.to_numeric, errors='coerce')\n",
    "weekend_data = weekend_data.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Combine with original dataframe\n",
    "df_summary = pd.concat([df, weekday_data, weekend_data], axis=1)\n",
    "\n",
    "# Optional: Summarize total by name or email\n",
    "summary = (df[[\"Weekday Days\", \"Weekday Hours\", \"Weekend Days\", \"Weekend Hours\"]].sum().reset_index())\n",
    "\n",
    "# Display result\n",
    "print(summary)\n",
    "\n",
    "# Optional: Save to Excel\n",
    "# summary.to_excel(\"OnCall_Weekday_Weekend_Summary.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa46c441-4f13-477b-a5ea-5c87a64d829b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "22",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:2606\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:2630\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 22",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/HP/Desktop/Copy of Final_Oncall_Data_Feb (1).xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Use column W = 22 (0-based index), skip first row which contains headers\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m column_data \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;241m22\u001b[39m]\u001b[38;5;241m.\u001b[39mdropna()\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Extract weekday and weekend info using regex\u001b[39;00m\n\u001b[0;32m     10\u001b[0m weekday_data \u001b[38;5;241m=\u001b[39m column_data\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mextract(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWeekdays\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*-\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+)\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*days,\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*([\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md.]+)\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*hours\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 22"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file with NO header, since real data is in row 1\n",
    "df = pd.read_excel(\"C:/Users/HP/Desktop/Copy of Final_Oncall_Data_Feb (1).xlsx\", header=None)\n",
    "\n",
    "# Use column W = 22 (0-based index), skip first row which contains headers\n",
    "column_data = df[22].dropna().astype(str).iloc[1:]\n",
    "\n",
    "# Extract weekday and weekend info using regex\n",
    "weekday_data = column_data.str.extract(r'Weekdays\\s*-\\s*(\\d+)\\s*days,\\s*([\\d.]+)\\s*hours')\n",
    "weekend_data = column_data.str.extract(r'Weekends/Holidays\\s*-\\s*(\\d+)\\s*days,\\s*([\\d.]+)\\s*hours')\n",
    "\n",
    "# Assign column names\n",
    "weekday_data.columns = ['Weekday_Days', 'Weekday_Hours']\n",
    "weekend_data.columns = ['Weekend_Days', 'Weekend_Hours']\n",
    "\n",
    "# Convert to numeric values\n",
    "weekday_data = weekday_data.apply(pd.to_numeric, errors='coerce')\n",
    "weekend_data = weekend_data.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Combine both into one DataFrame\n",
    "result = pd.concat([weekday_data, weekend_data], axis=1)\n",
    "\n",
    "# Print row-wise data\n",
    "print(\"Parsed Data:\")\n",
    "print(result)\n",
    "\n",
    "# Optional: total summary\n",
    "print(\"\\nTotal Summary:\")\n",
    "print(result.sum(numeric_only=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ce30c8f-b225-4083-9e79-35a28ba64875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Name  Weekday_Days  Weekday_Hours  Weekend_Days  \\\n",
      "0   Keerthivasan Kannan             5            0.0             1   \n",
      "1         Ankit Thakkar             5            0.0             2   \n",
      "2          Ayush Rajeev             5            0.0             2   \n",
      "3    Muthumani Gurusamy             4           18.5             0   \n",
      "4      Durai Ramalingam            10            0.0             4   \n",
      "5        Jithin Johnson            10            0.0             4   \n",
      "6          Ahalya Hegde             4            0.0             2   \n",
      "7   Basudev Singh Munda             6            0.0             2   \n",
      "8          Dolly Chahar             5            0.0             2   \n",
      "9     Prakash Rajendran             0            9.0             2   \n",
      "10        Vamshi Bandla             4           15.0             0   \n",
      "11            Akash Dey             0            4.5             2   \n",
      "12          Kapil Jugnu             5            0.0             2   \n",
      "13    Nirmalraja Selvam             5            0.0             2   \n",
      "14        Sahil Kanojia             5            0.0             2   \n",
      "\n",
      "    Weekend_Hours  \n",
      "0           13.97  \n",
      "1            0.00  \n",
      "2            0.00  \n",
      "3            0.00  \n",
      "4            0.00  \n",
      "5            0.00  \n",
      "6            0.00  \n",
      "7            0.00  \n",
      "8            0.00  \n",
      "9            0.00  \n",
      "10           0.00  \n",
      "11           0.00  \n",
      "12           0.00  \n",
      "13           0.00  \n",
      "14           0.00  \n",
      "\n",
      "Total Summary:\n",
      "Weekday_Days     73.00\n",
      "Weekday_Hours    47.00\n",
      "Weekend_Days     29.00\n",
      "Weekend_Hours    13.97\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load file with no header\n",
    "df = pd.read_excel(\"C:/Users/HP/Desktop/Copy of Final_Oncall_Data_Feb (1).xlsx\", header=None)\n",
    "\n",
    "# Skip header row, use column index 13 (Excel column N = \"W or H\")\n",
    "column_data = df[13].iloc[1:].dropna().astype(str)\n",
    "\n",
    "# Extract weekday and weekend info using regex\n",
    "weekday_data = column_data.str.extract(r'Weekdays\\s*-\\s*(\\d+)\\s*days,\\s*([\\d.]+)\\s*hours')\n",
    "weekend_data = column_data.str.extract(r'Weekends/Holidays\\s*-\\s*(\\d+)\\s*days,\\s*([\\d.]+)\\s*hours')\n",
    "\n",
    "# Name the columns\n",
    "weekday_data.columns = ['Weekday_Days', 'Weekday_Hours']\n",
    "weekend_data.columns = ['Weekend_Days', 'Weekend_Hours']\n",
    "\n",
    "# Convert to numeric\n",
    "weekday_data = weekday_data.apply(pd.to_numeric, errors='coerce')\n",
    "weekend_data = weekend_data.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Combine results and reset index\n",
    "result = pd.concat([weekday_data, weekend_data], axis=1).reset_index(drop=True)\n",
    "\n",
    "# Add employee names (column 0) from the original dataframe\n",
    "names = df[0].iloc[1:].reset_index(drop=True)\n",
    "result.insert(0, 'Name', names)\n",
    "\n",
    "# Display the final result\n",
    "print(result)\n",
    "\n",
    "# Optional: Total summary\n",
    "print(\"\\nTotal Summary:\")\n",
    "print(result[['Weekday_Days', 'Weekday_Hours', 'Weekend_Days', 'Weekend_Hours']].sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7ea8796-368c-453f-8313-7fe6fc00f93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Name  Weekday_Days  Weekday_Hours  Weekend_Days  \\\n",
      "0         Ankit Thakkar             5            0.0             2   \n",
      "1          Ayush Rajeev             5            0.0             2   \n",
      "2    Muthumani Gurusamy             4           18.5             0   \n",
      "3      Durai Ramalingam            10            0.0             4   \n",
      "4        Jithin Johnson            10            0.0             4   \n",
      "5          Ahalya Hegde             4            0.0             2   \n",
      "6   Basudev Singh Munda             6            0.0             2   \n",
      "7          Dolly Chahar             5            0.0             2   \n",
      "8     Prakash Rajendran             0            9.0             2   \n",
      "9         Vamshi Bandla             4           15.0             0   \n",
      "10            Akash Dey             0            4.5             2   \n",
      "11          Kapil Jugnu             5            0.0             2   \n",
      "12    Nirmalraja Selvam             5            0.0             2   \n",
      "13        Sahil Kanojia             5            0.0             2   \n",
      "\n",
      "    Weekend_Hours  \n",
      "0             0.0  \n",
      "1             0.0  \n",
      "2             0.0  \n",
      "3             0.0  \n",
      "4             0.0  \n",
      "5             0.0  \n",
      "6             0.0  \n",
      "7             0.0  \n",
      "8             0.0  \n",
      "9             0.0  \n",
      "10            0.0  \n",
      "11            0.0  \n",
      "12            0.0  \n",
      "13            0.0  \n",
      "\n",
      "Total Summary:\n",
      "Weekday_Days     68.0\n",
      "Weekday_Hours    47.0\n",
      "Weekend_Days     28.0\n",
      "Weekend_Hours     0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load Excel without header row\n",
    "df = pd.read_excel(\"C:/Users/HP/Desktop/Copy of Final_Oncall_Data_Feb (1).xlsx\")\n",
    "\n",
    "# Prepare lists to collect the data\n",
    "names = []\n",
    "weekday_days = []\n",
    "weekday_hours = []\n",
    "weekend_days = []\n",
    "weekend_hours = []\n",
    "\n",
    "# Iterate over the rows, skipping the header row (row 0)\n",
    "for i, row in enumerate(df.values):\n",
    "    if i == 0:\n",
    "        continue  # skip header row\n",
    "\n",
    "    name = row[0]\n",
    "    wh_col = row[13]  # column \"W or H\"\n",
    "\n",
    "    if isinstance(wh_col, str):\n",
    "        # Extract data using regex\n",
    "        weekday_match = re.search(r'Weekdays\\s*-\\s*(\\d+)\\s*days,\\s*([\\d.]+)\\s*hours', wh_col)\n",
    "        weekend_match = re.search(r'Weekends/Holidays\\s*-\\s*(\\d+)\\s*days,\\s*([\\d.]+)\\s*hours', wh_col)\n",
    "\n",
    "        if weekday_match:\n",
    "            wd_days = int(weekday_match.group(1))\n",
    "            wd_hours = float(weekday_match.group(2))\n",
    "        else:\n",
    "            wd_days = wd_hours = 0\n",
    "\n",
    "        if weekend_match:\n",
    "            we_days = int(weekend_match.group(1))\n",
    "            we_hours = float(weekend_match.group(2))\n",
    "        else:\n",
    "            we_days = we_hours = 0\n",
    "\n",
    "        names.append(name)\n",
    "        weekday_days.append(wd_days)\n",
    "        weekday_hours.append(wd_hours)\n",
    "        weekend_days.append(we_days)\n",
    "        weekend_hours.append(we_hours)\n",
    "\n",
    "# Create result DataFrame\n",
    "result = pd.DataFrame({\n",
    "    'Name': names,\n",
    "    'Weekday_Days': weekday_days,\n",
    "    'Weekday_Hours': weekday_hours,\n",
    "    'Weekend_Days': weekend_days,\n",
    "    'Weekend_Hours': weekend_hours\n",
    "})\n",
    "\n",
    "print(result)\n",
    "\n",
    "# Optional: Summary\n",
    "print(\"\\nTotal Summary:\")\n",
    "print(result[['Weekday_Days', 'Weekday_Hours', 'Weekend_Days', 'Weekend_Hours']].sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0626f92f-13d4-4d17-bebe-1dea8edc5c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Name  From Date    To Date  \\\n",
      "0        ankit thakkar 2025-02-10 2025-02-17   \n",
      "1         Ayush Rajeev 2025-02-03 2025-02-10   \n",
      "2   muthumani gurusamy 2025-02-24 2025-03-01   \n",
      "3        sahil kanojia 2025-02-03 2025-02-10   \n",
      "4    nirmalraja selvam 2025-02-10 2025-02-17   \n",
      "5          Kapil Jugnu 2025-02-17 2025-02-24   \n",
      "6            akash dey 2025-02-01 2025-02-03   \n",
      "7        vamshi bandla 2025-02-24 2025-03-01   \n",
      "8  Basudev Singh Munda 2025-02-03 2025-02-11   \n",
      "9    Prakash Rajendran 2025-02-01 2025-02-03   \n",
      "\n",
      "                                              W or H  \n",
      "0  Weekdays - 4 days, 24.00 hours\\nWeekends/Holid...  \n",
      "1  Weekdays - 4 days, 24.00 hours\\nWeekends/Holid...  \n",
      "2  Weekdays - 4 days, 18.50 hours\\nWeekends/Holid...  \n",
      "3  Weekdays - 4 days, 24.00 hours\\nWeekends/Holid...  \n",
      "4  Weekdays - 4 days, 24.00 hours\\nWeekends/Holid...  \n",
      "5  Weekdays - 4 days, 24.00 hours\\nWeekends/Holid...  \n",
      "6  Weekdays - 0 days, 4.50 hours\\nWeekends/Holida...  \n",
      "7  Weekdays - 4 days, 15.00 hours\\nWeekends/Holid...  \n",
      "8  Weekdays - 5 days, 24.00 hours\\nWeekends/Holid...  \n",
      "9  Weekdays - 0 days, 9.00 hours\\nWeekends/Holida...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import calendar\n",
    "\n",
    "# Load the Excel file\n",
    "df_log = pd.read_excel(\"C:/Users/HP/Desktop/finalCopy of PagerDutyLog - Feb.xlsx\")\n",
    "\n",
    "# Function to compute total weekday and weekend hours, split into days + hours\n",
    "def calculate_day_hour_breakdown_hours(row):\n",
    "    from_dt = datetime.combine(row['From Date'], row['From Time'])\n",
    "    to_dt = datetime.combine(row['To Date'], row['To Time'])\n",
    "\n",
    "    weekday_hours = 0.0\n",
    "    weekend_hours = 0.0\n",
    "\n",
    "    current = from_dt\n",
    "    while current <= to_dt:\n",
    "        next_day = datetime.combine(current.date(), datetime.max.time().replace(microsecond=0))\n",
    "        if next_day > to_dt:\n",
    "            next_day = to_dt\n",
    "\n",
    "        duration = (next_day - current).total_seconds() / 3600.0\n",
    "\n",
    "        if calendar.weekday(current.year, current.month, current.day) < 5:\n",
    "            weekday_hours += duration\n",
    "        else:\n",
    "            weekend_hours += duration\n",
    "\n",
    "        current = next_day + timedelta(seconds=1)\n",
    "\n",
    "    # Convert total hours into full days + remaining hours\n",
    "    weekday_days = int(weekday_hours // 24)\n",
    "    weekday_hours = round(weekday_hours % 24, 2)\n",
    "\n",
    "    weekend_days = int(weekend_hours // 24)\n",
    "    weekend_hours = round(weekend_hours % 24, 2)\n",
    "\n",
    "    return (\n",
    "        f\"Weekdays - {weekday_days} days, {weekday_hours:.2f} hours\\n\"\n",
    "        f\"Weekends/Holidays - {weekend_days} days, {weekend_hours:.2f} hours\"\n",
    "    )\n",
    "\n",
    "# Apply the function to the DataFrame\n",
    "df_log[\"W or H\"] = df_log.apply(calculate_day_hour_breakdown_hours, axis=1)\n",
    "\n",
    "# Print the top 10 rows with relevant output\n",
    "print(df_log[[\"Name\", \"From Date\", \"To Date\", \"W or H\"]].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27b12c6e-1911-4a44-8024-ce02074de51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Name  From Date    To Date  \\\n",
      "0        ankit thakkar 2025-02-10 2025-02-17   \n",
      "1         Ayush Rajeev 2025-02-03 2025-02-10   \n",
      "2   muthumani gurusamy 2025-02-24 2025-03-01   \n",
      "3        sahil kanojia 2025-02-03 2025-02-10   \n",
      "4    nirmalraja selvam 2025-02-10 2025-02-17   \n",
      "5          Kapil Jugnu 2025-02-17 2025-02-24   \n",
      "6            akash dey 2025-02-01 2025-02-03   \n",
      "7        vamshi bandla 2025-02-24 2025-03-01   \n",
      "8  Basudev Singh Munda 2025-02-03 2025-02-11   \n",
      "9    Prakash Rajendran 2025-02-01 2025-02-03   \n",
      "\n",
      "                                              W or H  \n",
      "0  Weekday - 4 days Weekhours - 24.00 hours and W...  \n",
      "1  Weekday - 4 days Weekhours - 24.00 hours and W...  \n",
      "2  Weekday - 4 days Weekhours - 18.50 hours and W...  \n",
      "3  Weekday - 4 days Weekhours - 24.00 hours and W...  \n",
      "4  Weekday - 4 days Weekhours - 24.00 hours and W...  \n",
      "5  Weekday - 4 days Weekhours - 24.00 hours and W...  \n",
      "6  Weekday - 0 days Weekhours - 4.50 hours and We...  \n",
      "7  Weekday - 4 days Weekhours - 15.00 hours and W...  \n",
      "8  Weekday - 5 days Weekhours - 24.00 hours and W...  \n",
      "9  Weekday - 0 days Weekhours - 9.00 hours and We...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import calendar\n",
    "\n",
    "# Load the Excel file\n",
    "df_log = pd.read_excel(\"C:/Users/HP/Desktop/finalCopy of PagerDutyLog - Feb.xlsx\")\n",
    "\n",
    "# Function to compute formatted weekday/weekend breakdown\n",
    "def final_format_day_hour_summary(row):\n",
    "    from_dt = datetime.combine(row['From Date'], row['From Time'])\n",
    "    to_dt = datetime.combine(row['To Date'], row['To Time'])\n",
    "\n",
    "    weekday_hours = 0.0\n",
    "    weekend_hours = 0.0\n",
    "\n",
    "    current = from_dt\n",
    "    while current <= to_dt:\n",
    "        next_day = datetime.combine(current.date(), datetime.max.time().replace(microsecond=0))\n",
    "        if next_day > to_dt:\n",
    "            next_day = to_dt\n",
    "\n",
    "        duration = (next_day - current).total_seconds() / 3600.0\n",
    "\n",
    "        if calendar.weekday(current.year, current.month, current.day) < 5:\n",
    "            weekday_hours += duration\n",
    "        else:\n",
    "            weekend_hours += duration\n",
    "\n",
    "        current = next_day + timedelta(seconds=1)\n",
    "\n",
    "    # Convert total hours into days + remaining hours\n",
    "    weekday_days = int(weekday_hours // 24)\n",
    "    weekday_rem_hours = round(weekday_hours % 24, 2)\n",
    "    weekend_days = int(weekend_hours // 24)\n",
    "\n",
    "    # Final formatted string\n",
    "    return f\"Weekday - {weekday_days} days Weekhours - {weekday_rem_hours:.2f} hours and Weekend Days - {weekend_days} days\"\n",
    "\n",
    "# Apply the function\n",
    "df_log[\"W or H\"] = df_log.apply(final_format_day_hour_summary, axis=1)\n",
    "\n",
    "# Display result\n",
    "print(df_log[[\"Name\", \"From Date\", \"To Date\", \"W or H\"]].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "807b7efa-3d65-4cbb-b4b1-b6bc8cfc09a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Name  From Date    To Date  \\\n",
      "0         ankit thakkar 2025-02-10 2025-02-17   \n",
      "1          Ayush Rajeev 2025-02-03 2025-02-10   \n",
      "2    muthumani gurusamy 2025-02-24 2025-03-01   \n",
      "3         sahil kanojia 2025-02-03 2025-02-10   \n",
      "4     nirmalraja selvam 2025-02-10 2025-02-17   \n",
      "5           Kapil Jugnu 2025-02-17 2025-02-24   \n",
      "6             akash dey 2025-02-01 2025-02-03   \n",
      "7         vamshi bandla 2025-02-24 2025-03-01   \n",
      "8   Basudev Singh Munda 2025-02-03 2025-02-11   \n",
      "9     Prakash Rajendran 2025-02-01 2025-02-03   \n",
      "10         Ahalya Hegde 2025-02-11 2025-02-17   \n",
      "11         Dolly Chahar 2025-02-17 2025-02-24   \n",
      "12     Durai Ramalingam 2025-02-24 2025-03-01   \n",
      "13       Jithin Johnson 2025-02-17 2025-02-24   \n",
      "14     Durai Ramalingam 2025-02-10 2025-02-17   \n",
      "15       Jithin Johnson 2025-02-03 2025-02-10   \n",
      "16     Durai Ramalingam 2025-02-01 2025-02-03   \n",
      "17  Keerthivasan Kannan 2025-02-11 2025-02-16   \n",
      "18  Keerthivasan Kannan 2025-02-16 2025-02-18   \n",
      "\n",
      "                                                                W or H  \n",
      "0    Weekday - 5 days Weekhours - 0.00 hours and Weekend Days - 2 days  \n",
      "1    Weekday - 5 days Weekhours - 0.00 hours and Weekend Days - 2 days  \n",
      "2   Weekday - 4 days Weekhours - 18.50 hours and Weekend Days - 0 days  \n",
      "3    Weekday - 5 days Weekhours - 0.00 hours and Weekend Days - 2 days  \n",
      "4    Weekday - 5 days Weekhours - 0.00 hours and Weekend Days - 2 days  \n",
      "5    Weekday - 5 days Weekhours - 0.00 hours and Weekend Days - 2 days  \n",
      "6    Weekday - 0 days Weekhours - 4.50 hours and Weekend Days - 2 days  \n",
      "7   Weekday - 4 days Weekhours - 15.00 hours and Weekend Days - 0 days  \n",
      "8    Weekday - 6 days Weekhours - 0.00 hours and Weekend Days - 2 days  \n",
      "9    Weekday - 0 days Weekhours - 9.00 hours and Weekend Days - 2 days  \n",
      "10   Weekday - 4 days Weekhours - 0.00 hours and Weekend Days - 2 days  \n",
      "11   Weekday - 5 days Weekhours - 0.00 hours and Weekend Days - 2 days  \n",
      "12  Weekday - 4 days Weekhours - 19.50 hours and Weekend Days - 0 days  \n",
      "13   Weekday - 5 days Weekhours - 0.00 hours and Weekend Days - 2 days  \n",
      "14   Weekday - 5 days Weekhours - 0.00 hours and Weekend Days - 2 days  \n",
      "15   Weekday - 5 days Weekhours - 0.00 hours and Weekend Days - 2 days  \n",
      "16   Weekday - 0 days Weekhours - 4.50 hours and Weekend Days - 2 days  \n",
      "17  Weekday - 3 days Weekhours - 14.00 hours and Weekend Days - 2 days  \n",
      "18  Weekday - 1 days Weekhours - 10.00 hours and Weekend Days - 1 days  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import calendar\n",
    "\n",
    "# Load the Excel file\n",
    "df_log = pd.read_excel(\"C:/Users/HP/Desktop/finalCopy of PagerDutyLog - Feb.xlsx\")\n",
    "\n",
    "def final_format_day_hour_summary_using_calendar(row):\n",
    "    from_dt = datetime.combine(row['From Date'], row['From Time'])\n",
    "    to_dt = datetime.combine(row['To Date'], row['To Time'])\n",
    "\n",
    "    weekday_hours = 0.0\n",
    "    weekend_days = 0\n",
    "\n",
    "    current = from_dt\n",
    "    while current <= to_dt:\n",
    "        next_dt = min(to_dt, datetime.combine(current.date(), datetime.max.time()))\n",
    "        duration_hours = (next_dt - current).total_seconds() / 3600.0\n",
    "\n",
    "        day_of_week = calendar.weekday(current.year, current.month, current.day)\n",
    "\n",
    "        if day_of_week < 5:  # Monday (0) to Friday (4)\n",
    "            weekday_hours += duration_hours\n",
    "        else:  # Saturday (5) or Sunday (6)\n",
    "            weekend_days += 1\n",
    "\n",
    "        current = next_dt + timedelta(seconds=1)\n",
    "\n",
    "    # Convert weekday hours into full days + remainder hours\n",
    "    weekday_days = int(weekday_hours // 24)\n",
    "    weekday_rem_hours = round(weekday_hours % 24, 2)\n",
    "\n",
    "    # Handle exact 24 hours = 1 full day\n",
    "    if weekday_rem_hours == 24.0:\n",
    "        weekday_days += 1\n",
    "        weekday_rem_hours = 0.0\n",
    "\n",
    "    return f\"Weekday - {weekday_days} days Weekhours - {weekday_rem_hours:.2f} hours and Weekend Days - {weekend_days} days\"\n",
    "\n",
    "# Apply to dataframe\n",
    "df_log[\"W or H\"] = df_log.apply(final_format_day_hour_summary_using_calendar, axis=1)\n",
    "\n",
    "# Display the result\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "print(df_log[[\"Name\", \"From Date\", \"To Date\", \"W or H\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "091c91c1-b27d-4518-8983-67ac0959ba1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Name  \\\n",
      "0          Ahalya Hegde   \n",
      "1          Ayush Rajeev   \n",
      "2   Basudev Singh Munda   \n",
      "3          Dolly Chahar   \n",
      "4      Durai Ramalingam   \n",
      "5        Jithin Johnson   \n",
      "6           Kapil Jugnu   \n",
      "7   Keerthivasan Kannan   \n",
      "8     Prakash Rajendran   \n",
      "9             akash dey   \n",
      "10        ankit thakkar   \n",
      "11   muthumani gurusamy   \n",
      "12    nirmalraja selvam   \n",
      "13        sahil kanojia   \n",
      "14        vamshi bandla   \n",
      "\n",
      "                                                               Summary  \n",
      "0    Weekday - 4 days Weekhours - 0.00 hours and Weekend Days - 2 days  \n",
      "1    Weekday - 5 days Weekhours - 0.00 hours and Weekend Days - 2 days  \n",
      "2    Weekday - 6 days Weekhours - 0.00 hours and Weekend Days - 2 days  \n",
      "3    Weekday - 5 days Weekhours - 0.00 hours and Weekend Days - 2 days  \n",
      "4   Weekday - 10 days Weekhours - 0.00 hours and Weekend Days - 4 days  \n",
      "5   Weekday - 10 days Weekhours - 0.00 hours and Weekend Days - 4 days  \n",
      "6    Weekday - 5 days Weekhours - 0.00 hours and Weekend Days - 2 days  \n",
      "7    Weekday - 5 days Weekhours - 0.00 hours and Weekend Days - 3 days  \n",
      "8    Weekday - 0 days Weekhours - 9.00 hours and Weekend Days - 2 days  \n",
      "9    Weekday - 0 days Weekhours - 4.50 hours and Weekend Days - 2 days  \n",
      "10   Weekday - 5 days Weekhours - 0.00 hours and Weekend Days - 2 days  \n",
      "11  Weekday - 4 days Weekhours - 18.50 hours and Weekend Days - 0 days  \n",
      "12   Weekday - 5 days Weekhours - 0.00 hours and Weekend Days - 2 days  \n",
      "13   Weekday - 5 days Weekhours - 0.00 hours and Weekend Days - 2 days  \n",
      "14  Weekday - 4 days Weekhours - 15.00 hours and Weekend Days - 0 days  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import calendar\n",
    "\n",
    "# Load Excel\n",
    "df_log = pd.read_excel(\"C:/Users/HP/Desktop/finalCopy of PagerDutyLog - Feb.xlsx\")\n",
    "\n",
    "# Function to calculate hours and days\n",
    "def calculate_day_hour_summary(row):\n",
    "    from_dt = datetime.combine(row['From Date'], row['From Time'])\n",
    "    to_dt = datetime.combine(row['To Date'], row['To Time'])\n",
    "\n",
    "    weekday_hours = 0.0\n",
    "    weekend_days = 0\n",
    "\n",
    "    current = from_dt\n",
    "    while current <= to_dt:\n",
    "        next_dt = min(to_dt, datetime.combine(current.date(), datetime.max.time()))\n",
    "        duration_hours = (next_dt - current).total_seconds() / 3600.0\n",
    "\n",
    "        day_of_week = calendar.weekday(current.year, current.month, current.day)\n",
    "\n",
    "        if day_of_week < 5:\n",
    "            weekday_hours += duration_hours\n",
    "        else:\n",
    "            weekend_days += 1\n",
    "\n",
    "        current = next_dt + timedelta(seconds=1)\n",
    "\n",
    "    weekday_days = int(weekday_hours // 24)\n",
    "    weekday_rem_hours = round(weekday_hours % 24, 2)\n",
    "\n",
    "    if weekday_rem_hours == 24.0:\n",
    "        weekday_days += 1\n",
    "        weekday_rem_hours = 0.0\n",
    "\n",
    "    return pd.Series([weekday_days, weekday_rem_hours, weekend_days])\n",
    "\n",
    "# Apply the function to the dataframe\n",
    "df_log[['Weekday Days', 'Weekday Hours', 'Weekend Days']] = df_log.apply(calculate_day_hour_summary, axis=1)\n",
    "\n",
    "# Group by Name and sum up the values\n",
    "grouped = df_log.groupby('Name')[['Weekday Days', 'Weekday Hours', 'Weekend Days']].sum().reset_index()\n",
    "\n",
    "# Handle hour-to-day conversion in aggregation (e.g., 48 hours = 2 days)\n",
    "def normalize_hours(row):\n",
    "    total_hours = row['Weekday Hours']\n",
    "    additional_days = int(total_hours // 24)\n",
    "    remaining_hours = round(total_hours % 24, 2)\n",
    "    row['Weekday Days'] += additional_days\n",
    "    row['Weekday Hours'] = remaining_hours\n",
    "    return row\n",
    "\n",
    "grouped = grouped.apply(normalize_hours, axis=1)\n",
    "\n",
    "# Format final string per Name\n",
    "grouped['Summary'] = grouped.apply(\n",
    "    lambda row: f\"Weekday - {int(row['Weekday Days'])} days Weekhours - {row['Weekday Hours']:.2f} hours and Weekend Days - {int(row['Weekend Days'])} days\",\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Output the final grouped dataframe\n",
    "print(grouped[['Name', 'Summary']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ca0ecbf2-5e85-49d2-93c3-b53d820a29ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Name                                           Summary\n",
      "0          Ahalya Hegde   Weekday - 4 days , 0.00 hours Weekends - 2 days\n",
      "1          Ayush Rajeev   Weekday - 5 days , 0.00 hours Weekends - 2 days\n",
      "2   Basudev Singh Munda   Weekday - 6 days , 0.00 hours Weekends - 2 days\n",
      "3          Dolly Chahar   Weekday - 5 days , 0.00 hours Weekends - 2 days\n",
      "4      Durai Ramalingam  Weekday - 10 days , 0.00 hours Weekends - 4 days\n",
      "5        Jithin Johnson  Weekday - 10 days , 0.00 hours Weekends - 4 days\n",
      "6           Kapil Jugnu   Weekday - 5 days , 0.00 hours Weekends - 2 days\n",
      "7   Keerthivasan Kannan   Weekday - 5 days , 0.00 hours Weekends - 3 days\n",
      "8     Prakash Rajendran   Weekday - 0 days , 9.00 hours Weekends - 2 days\n",
      "9             akash dey   Weekday - 0 days , 4.50 hours Weekends - 2 days\n",
      "10        ankit thakkar   Weekday - 5 days , 0.00 hours Weekends - 2 days\n",
      "11   muthumani gurusamy  Weekday - 4 days , 18.50 hours Weekends - 0 days\n",
      "12    nirmalraja selvam   Weekday - 5 days , 0.00 hours Weekends - 2 days\n",
      "13        sahil kanojia   Weekday - 5 days , 0.00 hours Weekends - 2 days\n",
      "14        vamshi bandla  Weekday - 4 days , 15.00 hours Weekends - 0 days\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import calendar\n",
    "\n",
    "# Load Excel\n",
    "df_log = pd.read_excel(\"C:/Users/HP/Desktop/finalCopy of PagerDutyLog - Feb.xlsx\")\n",
    "\n",
    "# Function to calculate hours and days\n",
    "def calculate_day_hour_summary(row):\n",
    "    from_dt = datetime.combine(row['From Date'], row['From Time'])\n",
    "    to_dt = datetime.combine(row['To Date'], row['To Time'])\n",
    "\n",
    "    weekday_hours = 0.0\n",
    "    weekend_days = 0\n",
    "    weekday_days = 0\n",
    "    current = from_dt\n",
    "    while current <= to_dt:\n",
    "        next_dt = min(to_dt, datetime.combine(current.date(), datetime.max.time()))\n",
    "        duration_hours = (next_dt - current).total_seconds() / 3600.0\n",
    "\n",
    "        day_of_week = calendar.weekday(current.year, current.month, current.day)\n",
    "\n",
    "        if day_of_week < 5:\n",
    "            weekday_hours += duration_hours\n",
    "        else:\n",
    "            weekend_days += 1\n",
    "\n",
    "        current = next_dt + timedelta(seconds=1)\n",
    "\n",
    "    weekday_days = int(weekday_hours // 24)\n",
    "    weekday_rem_hours = round(weekday_hours % 24, 2)\n",
    "\n",
    "    if weekday_rem_hours == 24.0:\n",
    "        weekday_days += 1\n",
    "        weekday_rem_hours = 0.0\n",
    "\n",
    "    return pd.Series([weekday_days, weekday_rem_hours, weekend_days])\n",
    "\n",
    "# Apply the function\n",
    "df_log[['Weekday Days', 'Weekday Hours', 'Weekend Days']] = df_log.apply(calculate_day_hour_summary, axis=1)\n",
    "\n",
    "# Group by Name and sum\n",
    "grouped = df_log.groupby('Name')[['Weekday Days', 'Weekday Hours', 'Weekend Days']].sum().reset_index()\n",
    "\n",
    "# Normalize hours into days\n",
    "def normalize_hours(row):\n",
    "    total_hours = row['Weekday Hours']\n",
    "    additional_days = int(total_hours // 24)\n",
    "    remaining_hours = round(total_hours % 24, 2)\n",
    "    row['Weekday Days'] += additional_days\n",
    "    row['Weekday Hours'] = remaining_hours\n",
    "    return row\n",
    "\n",
    "grouped = grouped.apply(normalize_hours, axis=1)\n",
    "\n",
    "# Format final summary string using .format()\n",
    "def format_summary(row):\n",
    "    return \"Weekday - {} days , {:.2f} hours Weekends - {} days\".format(\n",
    "        int(row['Weekday Days']), row['Weekday Hours'], int(row['Weekend Days'])\n",
    "    )\n",
    "\n",
    "grouped['Summary'] = grouped.apply(format_summary, axis=1)\n",
    "\n",
    "# Output result\n",
    "print(grouped[['Name','Summary']])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "01a0d155-df26-4067-a925-7fd2326b3f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Name  Weekend Days  Weekend Hours\n",
      "0             Akash Dey           0.0           0.00\n",
      "1          Ayush Rajeev           0.0           0.25\n",
      "2      Durai Ramalingam           0.0           0.00\n",
      "3        Jithin Johnson           0.0           0.00\n",
      "4           Kapil Jugnu           0.0           0.00\n",
      "5   Keerthivasan Kannan           0.0           1.17\n",
      "6    Muthumani Gurusamy           0.0           0.50\n",
      "7         Sahil Kanojia           0.0           0.00\n",
      "8         ankit thakkar           0.0           0.00\n",
      "9     nirmalraja selvam           0.0           0.00\n",
      "10    pavan kumarmantry           0.0           0.00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import calendar  # Included as per request\n",
    "\n",
    "# Load Excel file\n",
    "file_path = (\"C:/Users/HP/Desktop/finalCopy of ExtraHoursLog - Feb.xlsx\")\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Keep only relevant columns\n",
    "df = df[['Name', 'Total Minutes Weekends']].copy()\n",
    "\n",
    "# Convert total weekend minutes to calendar days and hours\n",
    "def convert_weekend_minutes(row):\n",
    "    weekend_minutes = row['Total Minutes Weekends']\n",
    "\n",
    "    # Convert to hours\n",
    "    weekend_hours = weekend_minutes / 60 if pd.notnull(weekend_minutes) else 0\n",
    "\n",
    "    # Convert to days and remaining hours\n",
    "    weekend_days = int(weekend_hours // 24)\n",
    "    weekend_remaining_hours = round(weekend_hours % 24, 2)\n",
    "\n",
    "    return pd.Series({\n",
    "        'Weekend Days': weekend_days,\n",
    "        'Weekend Hours': weekend_remaining_hours\n",
    "    })\n",
    "\n",
    "# Apply the conversion\n",
    "converted = df.apply(convert_weekend_minutes, axis=1)\n",
    "\n",
    "# Combine with names\n",
    "df_combined = pd.concat([df['Name'], converted], axis=1)\n",
    "\n",
    "# Group by name\n",
    "grouped_summary = df_combined.groupby('Name', as_index=False).sum()\n",
    "\n",
    "# Display the result\n",
    "print(grouped_summary)\n",
    "\n",
    "# Optional: save to Excel\n",
    "# grouped_summary.to_excel(\"Weekend_ExtraHours_ByName.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ce05444-685d-40de-9b2e-86be1bbf268c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Name  Weekday Days  Weekday Hours  Weekend Days  \\\n",
      "0             Akash Dey           0.0           0.00           0.0   \n",
      "1          Ayush Rajeev           0.0           1.00           0.0   \n",
      "2      Durai Ramalingam           0.0           0.50           0.0   \n",
      "3        Jithin Johnson           0.0           0.00           0.0   \n",
      "4           Kapil Jugnu           0.0           1.33           0.0   \n",
      "5   Keerthivasan Kannan           0.0           0.00           0.0   \n",
      "6    Muthumani Gurusamy           0.0           0.00           0.0   \n",
      "7         Sahil Kanojia           0.0           0.00           0.0   \n",
      "8         ankit thakkar           0.0           0.33           0.0   \n",
      "9     nirmalraja selvam           0.0           0.00           0.0   \n",
      "10    pavan kumarmantry           0.0           0.00           0.0   \n",
      "\n",
      "    Weekend Hours  \n",
      "0            0.00  \n",
      "1            0.25  \n",
      "2            0.00  \n",
      "3            0.00  \n",
      "4            0.00  \n",
      "5            1.17  \n",
      "6            0.50  \n",
      "7            0.00  \n",
      "8            0.00  \n",
      "9            0.00  \n",
      "10           0.00  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import calendar  # Included per your request\n",
    "\n",
    "# Load Excel file\n",
    "file_path = (\"C:/Users/HP/Desktop/finalCopy of ExtraHoursLog - Feb.xlsx\")\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Keep only relevant columns\n",
    "df = df[['Name', 'Total Minutes Weekdays', 'Total Minutes Weekends']].copy()\n",
    "\n",
    "# Convert total minutes to calendar days and hours (1 day = 24 hours)\n",
    "def convert_to_calendar_time(row):\n",
    "    weekday_minutes = row['Total Minutes Weekdays']\n",
    "    weekend_minutes = row['Total Minutes Weekends']\n",
    "\n",
    "    # Convert minutes to hours\n",
    "    weekday_hours = weekday_minutes / 60 if pd.notnull(weekday_minutes) else 0\n",
    "    weekend_hours = weekend_minutes / 60 if pd.notnull(weekend_minutes) else 0\n",
    "\n",
    "    # Convert to days and remaining hours\n",
    "    weekday_days = int(weekday_hours // 24)\n",
    "    weekday_remaining_hours = round(weekday_hours % 24, 2)\n",
    "\n",
    "    weekend_days = int(weekend_hours // 24)\n",
    "    weekend_remaining_hours = round(weekend_hours % 24, 2)\n",
    "\n",
    "    return pd.Series({\n",
    "        'Weekday Days': weekday_days,\n",
    "        'Weekday Hours': weekday_remaining_hours,\n",
    "        'Weekend Days': weekend_days,\n",
    "        'Weekend Hours': weekend_remaining_hours\n",
    "    })\n",
    "\n",
    "# Apply the conversion\n",
    "converted = df.apply(convert_to_calendar_time, axis=1)\n",
    "\n",
    "# Combine with names\n",
    "df_combined = pd.concat([df['Name'], converted], axis=1)\n",
    "\n",
    "# Group by name\n",
    "grouped_summary = df_combined.groupby('Name', as_index=False).sum()\n",
    "\n",
    "# Display the result\n",
    "print(grouped_summary)\n",
    "\n",
    "# Optional: Save to Excel\n",
    "# grouped_summary.to_excel(\"ExtraHoursSummary_ByName.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b8576447-7a7c-4f5f-8562-d07fadf6b52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Name  \\\n",
      "0          Ahalya Hegde   \n",
      "1          Ayush Rajeev   \n",
      "2   Basudev Singh Munda   \n",
      "3          Dolly Chahar   \n",
      "4      Durai Ramalingam   \n",
      "5        Jithin Johnson   \n",
      "6           Kapil Jugnu   \n",
      "7   Keerthivasan Kannan   \n",
      "8     Prakash Rajendran   \n",
      "9             akash dey   \n",
      "10        ankit thakkar   \n",
      "11   muthumani gurusamy   \n",
      "12    nirmalraja selvam   \n",
      "13        sahil kanojia   \n",
      "14        vamshi bandla   \n",
      "\n",
      "                                                                                                                         Formatted Range  \n",
      "0                                                                                           [Tue, Feb 11 @ 09:00 To Mon, Feb 17 @ 09:00]  \n",
      "1                                                                                           [Mon, Feb 03 @ 05:30 To Mon, Feb 10 @ 05:30]  \n",
      "2                                                                                           [Mon, Feb 03 @ 09:00 To Tue, Feb 11 @ 09:00]  \n",
      "3                                                                                           [Mon, Feb 17 @ 09:00 To Mon, Feb 24 @ 09:00]  \n",
      "4   [Mon, Feb 24 @ 04:30 To Sat, Mar 01 @ 00:00, Mon, Feb 10 @ 04:30 To Mon, Feb 17 @ 04:30, Sat, Feb 01 @ 00:00 To Mon, Feb 03 @ 04:30]  \n",
      "5                                               [Mon, Feb 17 @ 04:30 To Mon, Feb 24 @ 04:30, Mon, Feb 03 @ 04:30 To Mon, Feb 10 @ 04:30]  \n",
      "6                                                                                           [Mon, Feb 17 @ 04:30 To Mon, Feb 24 @ 04:30]  \n",
      "7                                               [Tue, Feb 11 @ 10:00 To Sun, Feb 16 @ 01:43, Sun, Feb 16 @ 11:45 To Tue, Feb 18 @ 10:00]  \n",
      "8                                                                                           [Sat, Feb 01 @ 00:00 To Mon, Feb 03 @ 09:00]  \n",
      "9                                                                                           [Sat, Feb 01 @ 00:00 To Mon, Feb 03 @ 04:30]  \n",
      "10                                                                                          [Mon, Feb 10 @ 05:30 To Mon, Feb 17 @ 05:30]  \n",
      "11                                                                                          [Mon, Feb 24 @ 05:30 To Sat, Mar 01 @ 00:00]  \n",
      "12                                                                                          [Mon, Feb 10 @ 04:30 To Mon, Feb 17 @ 04:30]  \n",
      "13                                                                                          [Mon, Feb 03 @ 04:30 To Mon, Feb 10 @ 04:30]  \n",
      "14                                                                                          [Mon, Feb 24 @ 09:00 To Sat, Mar 01 @ 00:00]  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file\n",
    "file_path = (\"C:/Users/HP/Desktop/finalCopy of PagerDutyLog - Feb.xlsx\") # Update path if needed\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Combine From Date and Time, and To Date and Time into datetime objects\n",
    "df['From DateTime'] = pd.to_datetime(df['From Date'].astype(str) + ' ' + df['From Time'].astype(str))\n",
    "df['To DateTime'] = pd.to_datetime(df['To Date'].astype(str) + ' ' + df['To Time'].astype(str))\n",
    "\n",
    "# Format into \"Mon, Feb 10 @ 05:30 To Mon, Feb 17 @ 05:30\"\n",
    "df['Formatted Range'] = df['From DateTime'].dt.strftime('%a, %b %d @ %H:%M') + \" To \" + df['To DateTime'].dt.strftime('%a, %b %d @ %H:%M')\n",
    "\n",
    "# Group by Name and aggregate the formatted ranges\n",
    "grouped = df.groupby('Name')['Formatted Range'].apply(list).reset_index()\n",
    "\n",
    "# Optional: Export to Excel\n",
    "grouped.to_excel(\"Grouped_Formatted_Ranges.xlsx\", index=False)\n",
    "\n",
    "print(grouped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b3dfb159-db79-4137-b333-20971f18d0f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .str accessor with string values!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 18\u001b[0m\n\u001b[0;32m     14\u001b[0m location_column \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMindera Bangalore\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Filter confirmed holidays\u001b[39;00m\n\u001b[0;32m     17\u001b[0m confirmed_holidays \u001b[38;5;241m=\u001b[39m df[\n\u001b[1;32m---> 18\u001b[0m     (df[location_column]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mholiday\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     19\u001b[0m ]\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Filter optional holidays\u001b[39;00m\n\u001b[0;32m     22\u001b[0m optional_holidays \u001b[38;5;241m=\u001b[39m df[\n\u001b[0;32m     23\u001b[0m     (df[location_column]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptional holiday\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     24\u001b[0m ]\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:6299\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   6293\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   6294\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   6295\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   6296\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   6297\u001b[0m ):\n\u001b[0;32m   6298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 6299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\accessor.py:224\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[1;34m(self, obj, cls)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor\n\u001b[1;32m--> 224\u001b[0m accessor_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor(obj)\n\u001b[0;32m    225\u001b[0m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\strings\\accessor.py:191\u001b[0m, in \u001b[0;36mStringMethods.__init__\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstring_\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StringDtype\n\u001b[1;32m--> 191\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate(data)\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_categorical \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype)\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, StringDtype)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\strings\\accessor.py:245\u001b[0m, in \u001b[0;36mStringMethods._validate\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    242\u001b[0m inferred_dtype \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39minfer_dtype(values, skipna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inferred_dtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed_types:\n\u001b[1;32m--> 245\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only use .str accessor with string values!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inferred_dtype\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can only use .str accessor with string values!"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file\n",
    "file_path = \"C:/Users/HP/Desktop/Mindera India - Holiday List 2025.xlsx\"\n",
    "df = pd.read_excel(file_path, skiprows=1)\n",
    "\n",
    "# Convert 'Date' column to datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "\n",
    "# Filter out rows with valid dates only\n",
    "df = df.dropna(subset=['Date'])\n",
    "\n",
    "# Choose location - either \"Mindera Bangalore\" or \"Mindera Chennai\"\n",
    "location_column = \"Mindera Bangalore\"\n",
    "\n",
    "# Filter confirmed holidays\n",
    "confirmed_holidays = df[\n",
    "    (df[location_column].str.strip().str.lower() == 'holiday')\n",
    "]\n",
    "\n",
    "# Filter optional holidays\n",
    "optional_holidays = df[\n",
    "    (df[location_column].str.strip().str.lower() == 'optional holiday')\n",
    "]\n",
    "\n",
    "# Output\n",
    "print(\" Confirmed Holidays for Bangalore:\")\n",
    "print(confirmed_holidays[['Holiday for', 'Date', 'Day']].to_string(index=False))\n",
    "\n",
    "print(\"\\n Optional Holidays (Choose limited number as per company policy):\")\n",
    "print(optional_holidays[['Holiday for', 'Date', 'Day']].to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e9f083af-9f7e-473f-ac21-c8bce6c4f6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Name  From Date    To Date  Actual_Working_Days\n",
      "0         ankit thakkar 2025-02-10 2025-02-17                    6\n",
      "1          Ayush Rajeev 2025-02-03 2025-02-10                    6\n",
      "2    muthumani gurusamy 2025-02-24 2025-03-01                    5\n",
      "3         sahil kanojia 2025-02-03 2025-02-10                    6\n",
      "4     nirmalraja selvam 2025-02-10 2025-02-17                    6\n",
      "5           Kapil Jugnu 2025-02-17 2025-02-24                    6\n",
      "6             akash dey 2025-02-01 2025-02-03                    1\n",
      "7         vamshi bandla 2025-02-24 2025-03-01                    5\n",
      "8   Basudev Singh Munda 2025-02-03 2025-02-11                    7\n",
      "9     Prakash Rajendran 2025-02-01 2025-02-03                    1\n",
      "10         Ahalya Hegde 2025-02-11 2025-02-17                    5\n",
      "11         Dolly Chahar 2025-02-17 2025-02-24                    6\n",
      "12     Durai Ramalingam 2025-02-24 2025-03-01                    5\n",
      "13       Jithin Johnson 2025-02-17 2025-02-24                    6\n",
      "14     Durai Ramalingam 2025-02-10 2025-02-17                    6\n",
      "15       Jithin Johnson 2025-02-03 2025-02-10                    6\n",
      "16     Durai Ramalingam 2025-02-01 2025-02-03                    1\n",
      "17  Keerthivasan Kannan 2025-02-11 2025-02-16                    4\n",
      "18  Keerthivasan Kannan 2025-02-16 2025-02-18                    2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Load the Excel files\n",
    "holiday_df = pd.read_excel(\"C:/Users/HP/Desktop/Mindera India - Holiday List 2025.xlsx\")\n",
    "log_df = pd.read_excel(\"C:/Users/HP/Desktop/finalCopy of PagerDutyLog - Feb.xlsx\")\n",
    "\n",
    "# Extract valid mandatory holidays\n",
    "holiday_df.columns = holiday_df.iloc[0]\n",
    "holiday_df = holiday_df.drop(index=0)\n",
    "holiday_df = holiday_df.rename(columns={pd.NaT: \"Misc\"})\n",
    "holiday_df['Date'] = pd.to_datetime(holiday_df['Date'], errors='coerce')\n",
    "mandatory_holidays = holiday_df[~holiday_df['Holiday Type'].str.contains(\"Optional\", na=False)]['Date'].dropna().dt.date.tolist()\n",
    "\n",
    "# Convert From Date and To Date in log data\n",
    "log_df['From Date'] = pd.to_datetime(log_df['From Date'])\n",
    "log_df['To Date'] = pd.to_datetime(log_df['To Date'])\n",
    "\n",
    "# Function to count actual working days excluding holidays\n",
    "def count_working_days_excluding_holidays(start_date, end_date, holidays):\n",
    "    working_days = 0\n",
    "    current = start_date\n",
    "    while current <= end_date:\n",
    "        if current.weekday() < 5 and current.date() not in holidays:\n",
    "            working_days += 1\n",
    "        current += timedelta(days=1)\n",
    "    return working_days\n",
    "\n",
    "# Apply the function row-wise\n",
    "log_df['Actual_Working_Days'] = log_df.apply(\n",
    "    lambda row: count_working_days_excluding_holidays(row['From Date'], row['To Date'], mandatory_holidays),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Display relevant columns\n",
    "print(log_df[['Name', 'From Date', 'To Date', 'Actual_Working_Days']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dcf2556c-160b-4a5d-b376-16ec898fc494",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'From Date'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:191\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:234\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine._get_loc_duplicates\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:242\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine._maybe_get_bool_indexer\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:134\u001b[0m, in \u001b[0;36mpandas._libs.index._unpack_bool_indexer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'From Date'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Convert date columns\u001b[39;00m\n\u001b[0;32m     17\u001b[0m holiday_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(holiday_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m log_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrom Date\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(log_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrom Date\u001b[39m\u001b[38;5;124m'\u001b[39m], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     19\u001b[0m log_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTo Date\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(log_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTo Date\u001b[39m\u001b[38;5;124m'\u001b[39m], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Extract valid mandatory holidays that are on weekdays only\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'From Date'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "# Read files\n",
    "holiday_df = pd.read_excel(\"C:/Users/HP/Desktop/Mindera India - Holiday List 2025.xlsx\")\n",
    "log_df = pd.read_excel(\"C:/Users/HP/Desktop/finalCopy of PagerDutyLog - Feb.xlsx\")\n",
    "\n",
    "# Fix headers\n",
    "holiday_df.columns = holiday_df.iloc[0]\n",
    "holiday_df = holiday_df.drop(index=0)\n",
    "holiday_df = holiday_df.rename(columns={pd.NaT: \"Misc\"})\n",
    "\n",
    "log_df.columns = log_df.iloc[0]\n",
    "log_df = log_df.drop(index=0)\n",
    "\n",
    "# Convert date columns\n",
    "holiday_df['Date'] = pd.to_datetime(holiday_df['Date'], errors='coerce')\n",
    "log_df['From Date'] = pd.to_datetime(log_df['From Date'], errors='coerce')\n",
    "log_df['To Date'] = pd.to_datetime(log_df['To Date'], errors='coerce')\n",
    "\n",
    "# Extract valid mandatory holidays that are on weekdays only\n",
    "mandatory_holidays = holiday_df[\n",
    "    (~holiday_df['Holiday Type'].str.contains(\"Optional\", na=False)) &\n",
    "    (holiday_df['Date'].dt.weekday < 5)\n",
    "]['Date'].dropna().dt.date.tolist()\n",
    "\n",
    "# Function to count working days excluding holidays\n",
    "def count_working_days_excluding_holidays(start_date, end_date, holidays):\n",
    "    working_days = 0\n",
    "    current = start_date\n",
    "    while current <= end_date:\n",
    "        if current.weekday() < 5 and current.date() not in holidays:\n",
    "            working_days += 1\n",
    "        current += timedelta(days=1)\n",
    "    return working_days\n",
    "\n",
    "# Apply the function row-wise\n",
    "log_df['Actual_Working_Days'] = log_df.apply(\n",
    "    lambda row: count_working_days_excluding_holidays(row['From Date'], row['To Date'], mandatory_holidays),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Show the results\n",
    "print(log_df[['Name', 'From Date', 'To Date', 'Actual_Working_Days']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3d9860a0-08f4-4eda-803f-59c31e98f261",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 84\u001b[0m\n\u001b[0;32m     81\u001b[0m final_df \u001b[38;5;241m=\u001b[39m final_df\u001b[38;5;241m.\u001b[39mmerge(extra_grouped, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mouter\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# Display\u001b[39;00m\n\u001b[1;32m---> 84\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m df_final\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;66;03m# Handle NaNs safely\u001b[39;00m\n\u001b[0;32m     86\u001b[0m     wd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(row\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWeekday Days\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     87\u001b[0m     wh \u001b[38;5;241m=\u001b[39m row\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWeekday Hours\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_final' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import calendar\n",
    "\n",
    "# Load files\n",
    "df_ranges = pd.read_excel(\"C:/Users/HP/Desktop/finalCopy of PagerDutyLog - Feb.xlsx\")\n",
    "df_log = pd.read_excel(\"C:/Users/HP/Desktop/finalCopy of PagerDutyLog - Feb.xlsx\")\n",
    "df_extra = pd.read_excel(\"C:/Users/HP/Desktop/finalCopy of ExtraHoursLog - Feb.xlsx\")\n",
    "\n",
    "# === 1. DATE RANGE FORMATTING ===\n",
    "df_ranges['From DateTime'] = pd.to_datetime(df_ranges['From Date'].astype(str) + ' ' + df_ranges['From Time'].astype(str))\n",
    "df_ranges['To DateTime'] = pd.to_datetime(df_ranges['To Date'].astype(str) + ' ' + df_ranges['To Time'].astype(str))\n",
    "df_ranges['Formatted Range'] = df_ranges['From DateTime'].dt.strftime('%a, %b %d @ %H:%M') + \" To \" + df_ranges['To DateTime'].dt.strftime('%a, %b %d @ %H:%M')\n",
    "date_ranges_grouped = df_ranges.groupby('Name')['Formatted Range'].apply(list).reset_index()\n",
    "\n",
    "\n",
    "# === 2. TOTAL WORKED HOURS / DAYS (Weekday & Weekend Split) ===\n",
    "def calculate_day_hour_summary(row):\n",
    "    from_dt = datetime.combine(row['From Date'], row['From Time'])\n",
    "    to_dt = datetime.combine(row['To Date'], row['To Time'])\n",
    "\n",
    "    weekday_hours = 0.0\n",
    "    weekend_days = 0\n",
    "    weekday_days = 0\n",
    "    current = from_dt\n",
    "    while current <= to_dt:\n",
    "        next_dt = min(to_dt, datetime.combine(current.date(), datetime.max.time()))\n",
    "        duration_hours = (next_dt - current).total_seconds() / 3600.0\n",
    "        if current.weekday() < 5:\n",
    "            weekday_hours += duration_hours\n",
    "        else:\n",
    "            weekend_days += 1\n",
    "        current = next_dt + timedelta(seconds=1)\n",
    "\n",
    "    weekday_days = int(weekday_hours // 24)\n",
    "    weekday_rem_hours = round(weekday_hours % 24, 2)\n",
    "    if weekday_rem_hours == 24.0:\n",
    "        weekday_days += 1\n",
    "        weekday_rem_hours = 0.0\n",
    "\n",
    "    return pd.Series([weekday_days, weekday_rem_hours, weekend_days])\n",
    "\n",
    "df_log[['Weekday Days', 'Weekday Hours', 'Weekend Days']] = df_log.apply(calculate_day_hour_summary, axis=1)\n",
    "\n",
    "grouped_log = df_log.groupby('Name')[['Weekday Days', 'Weekday Hours', 'Weekend Days']].sum().reset_index()\n",
    "\n",
    "# Normalize weekday hours to days\n",
    "def normalize_hours(row):\n",
    "    total_hours = row['Weekday Hours']\n",
    "    row['Weekday Days'] += int(total_hours // 24)\n",
    "    row['Weekday Hours'] = round(total_hours % 24, 2)\n",
    "    return row\n",
    "\n",
    "grouped_log = grouped_log.apply(normalize_hours, axis=1)\n",
    "\n",
    "\n",
    "# === 3. EXTRA HOURS WORKED (Using Total Minutes Columns) ===\n",
    "df_extra = df_extra[['Name', 'Total Minutes Weekdays', 'Total Minutes Weekends']].copy()\n",
    "\n",
    "def convert_to_calendar_time(row):\n",
    "    weekday_minutes = row['Total Minutes Weekdays'] if pd.notnull(row['Total Minutes Weekdays']) else 0\n",
    "    weekend_minutes = row['Total Minutes Weekends'] if pd.notnull(row['Total Minutes Weekends']) else 0\n",
    "\n",
    "    weekday_hours = weekday_minutes / 60\n",
    "    weekend_hours = weekend_minutes / 60\n",
    "\n",
    "    return pd.Series({\n",
    "        'Extra Weekday Days': int(weekday_hours // 24),\n",
    "        'Extra Weekday Hours': round(weekday_hours % 24, 2),\n",
    "        'Extra Weekend Days': int(weekend_hours // 24),\n",
    "        'Extra Weekend Hours': round(weekend_hours % 24, 2)\n",
    "    })\n",
    "\n",
    "converted_extra = df_extra.apply(convert_to_calendar_time, axis=1)\n",
    "extra_grouped = pd.concat([df_extra['Name'], converted_extra], axis=1).groupby('Name', as_index=False).sum()\n",
    "\n",
    "\n",
    "# === FINAL MERGE & DISPLAY ===\n",
    "# Merge all three\n",
    "final_df = date_ranges_grouped.merge(grouped_log, on='Name', how='outer')\n",
    "final_df = final_df.merge(extra_grouped, on='Name', how='outer')\n",
    "\n",
    "# Display\n",
    "for idx, row in df_final.iterrows():\n",
    "    # Handle NaNs safely\n",
    "    wd = int(row.get('Weekday Days', 0) or 0)\n",
    "    wh = row.get('Weekday Hours', 0) or 0.0\n",
    "    we_d = int(row.get('Weekend Days', 0) or 0)\n",
    "    ewd = int(row.get('Extra Weekday Days', 0) or 0)\n",
    "    ewh = row.get('Extra Weekday Hours', 0) or 0.0\n",
    "    ewed = int(row.get('Extra Weekend Days', 0) or 0)\n",
    "    eweh = row.get('Extra Weekend Hours', 0) or 0.0\n",
    "\n",
    "    # 1. Duration\n",
    "    print(\"Name: {}\".format(row['Name']))\n",
    "    print(\"Date Range  {} To {}\".format(row['From Date'].strftime('%Y-%m-%d'), row['To Date'].strftime('%Y-%m-%d')))\n",
    "\n",
    "    # 2. Total Worked\n",
    "    print(\"Total Worked  Weekdays: {} days, {:.2f} hrs | Weekends: {} days\".format(wd, wh, we_d))\n",
    "\n",
    "    # 3. Extra Time\n",
    "    print(\"Extra Hours  Weekdays: {} days, {:.2f} hrs | Weekends: {} days, {:.2f} hrs\".format(ewd, ewh, ewed, eweh))\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5acaa710-96b5-4cc4-813e-854378ae74cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: ankit thakkar\n",
      "Date Range  2025-02-10 To 2025-02-17\n",
      "Total Worked  Weekdays: 5 days, 0.00 hrs | Weekends: 2 days\n",
      "Extra Hours  Weekdays: 0 days, 0.00 hrs | Weekends: 0 days, 0.00 hrs\n",
      "--------------------------------------------------------------------------------\n",
      "Name: Ayush Rajeev\n",
      "Date Range  2025-02-03 To 2025-02-10\n",
      "Total Worked  Weekdays: 5 days, 0.00 hrs | Weekends: 2 days\n",
      "Extra Hours  Weekdays: 0 days, 0.00 hrs | Weekends: 0 days, 0.00 hrs\n",
      "--------------------------------------------------------------------------------\n",
      "Name: muthumani gurusamy\n",
      "Date Range  2025-02-24 To 2025-03-01\n",
      "Total Worked  Weekdays: 4 days, 18.50 hrs | Weekends: 0 days\n",
      "Extra Hours  Weekdays: 0 days, 0.00 hrs | Weekends: 0 days, 0.00 hrs\n",
      "--------------------------------------------------------------------------------\n",
      "Name: sahil kanojia\n",
      "Date Range  2025-02-03 To 2025-02-10\n",
      "Total Worked  Weekdays: 5 days, 0.00 hrs | Weekends: 2 days\n",
      "Extra Hours  Weekdays: 0 days, 0.00 hrs | Weekends: 0 days, 0.00 hrs\n",
      "--------------------------------------------------------------------------------\n",
      "Name: nirmalraja selvam\n",
      "Date Range  2025-02-10 To 2025-02-17\n",
      "Total Worked  Weekdays: 5 days, 0.00 hrs | Weekends: 2 days\n",
      "Extra Hours  Weekdays: 0 days, 0.00 hrs | Weekends: 0 days, 0.00 hrs\n",
      "--------------------------------------------------------------------------------\n",
      "Name: Kapil Jugnu\n",
      "Date Range  2025-02-17 To 2025-02-24\n",
      "Total Worked  Weekdays: 5 days, 0.00 hrs | Weekends: 2 days\n",
      "Extra Hours  Weekdays: 0 days, 0.00 hrs | Weekends: 0 days, 0.00 hrs\n",
      "--------------------------------------------------------------------------------\n",
      "Name: akash dey\n",
      "Date Range  2025-02-01 To 2025-02-03\n",
      "Total Worked  Weekdays: 0 days, 4.50 hrs | Weekends: 2 days\n",
      "Extra Hours  Weekdays: 0 days, 0.00 hrs | Weekends: 0 days, 0.00 hrs\n",
      "--------------------------------------------------------------------------------\n",
      "Name: vamshi bandla\n",
      "Date Range  2025-02-24 To 2025-03-01\n",
      "Total Worked  Weekdays: 4 days, 15.00 hrs | Weekends: 0 days\n",
      "Extra Hours  Weekdays: 0 days, 0.00 hrs | Weekends: 0 days, 0.00 hrs\n",
      "--------------------------------------------------------------------------------\n",
      "Name: Basudev Singh Munda\n",
      "Date Range  2025-02-03 To 2025-02-11\n",
      "Total Worked  Weekdays: 6 days, 0.00 hrs | Weekends: 2 days\n",
      "Extra Hours  Weekdays: 0 days, 0.00 hrs | Weekends: 0 days, 0.00 hrs\n",
      "--------------------------------------------------------------------------------\n",
      "Name: Prakash Rajendran\n",
      "Date Range  2025-02-01 To 2025-02-03\n",
      "Total Worked  Weekdays: 0 days, 9.00 hrs | Weekends: 2 days\n",
      "Extra Hours  Weekdays: 0 days, 0.00 hrs | Weekends: 0 days, 0.00 hrs\n",
      "--------------------------------------------------------------------------------\n",
      "Name: Ahalya Hegde\n",
      "Date Range  2025-02-11 To 2025-02-17\n",
      "Total Worked  Weekdays: 4 days, 0.00 hrs | Weekends: 2 days\n",
      "Extra Hours  Weekdays: 0 days, 0.00 hrs | Weekends: 0 days, 0.00 hrs\n",
      "--------------------------------------------------------------------------------\n",
      "Name: Dolly Chahar\n",
      "Date Range  2025-02-17 To 2025-02-24\n",
      "Total Worked  Weekdays: 5 days, 0.00 hrs | Weekends: 2 days\n",
      "Extra Hours  Weekdays: 0 days, 0.00 hrs | Weekends: 0 days, 0.00 hrs\n",
      "--------------------------------------------------------------------------------\n",
      "Name: Durai Ramalingam\n",
      "Date Range  2025-02-24 To 2025-03-01\n",
      "Total Worked  Weekdays: 4 days, 19.50 hrs | Weekends: 0 days\n",
      "Extra Hours  Weekdays: 0 days, 0.00 hrs | Weekends: 0 days, 0.00 hrs\n",
      "--------------------------------------------------------------------------------\n",
      "Name: Jithin Johnson\n",
      "Date Range  2025-02-17 To 2025-02-24\n",
      "Total Worked  Weekdays: 5 days, 0.00 hrs | Weekends: 2 days\n",
      "Extra Hours  Weekdays: 0 days, 0.00 hrs | Weekends: 0 days, 0.00 hrs\n",
      "--------------------------------------------------------------------------------\n",
      "Name: Durai Ramalingam\n",
      "Date Range  2025-02-10 To 2025-02-17\n",
      "Total Worked  Weekdays: 5 days, 0.00 hrs | Weekends: 2 days\n",
      "Extra Hours  Weekdays: 0 days, 0.00 hrs | Weekends: 0 days, 0.00 hrs\n",
      "--------------------------------------------------------------------------------\n",
      "Name: Jithin Johnson\n",
      "Date Range  2025-02-03 To 2025-02-10\n",
      "Total Worked  Weekdays: 5 days, 0.00 hrs | Weekends: 2 days\n",
      "Extra Hours  Weekdays: 0 days, 0.00 hrs | Weekends: 0 days, 0.00 hrs\n",
      "--------------------------------------------------------------------------------\n",
      "Name: Durai Ramalingam\n",
      "Date Range  2025-02-01 To 2025-02-03\n",
      "Total Worked  Weekdays: 0 days, 4.50 hrs | Weekends: 2 days\n",
      "Extra Hours  Weekdays: 0 days, 0.00 hrs | Weekends: 0 days, 0.00 hrs\n",
      "--------------------------------------------------------------------------------\n",
      "Name: Keerthivasan Kannan\n",
      "Date Range  2025-02-11 To 2025-02-16\n",
      "Total Worked  Weekdays: 3 days, 14.00 hrs | Weekends: 2 days\n",
      "Extra Hours  Weekdays: 0 days, 0.00 hrs | Weekends: 0 days, 0.00 hrs\n",
      "--------------------------------------------------------------------------------\n",
      "Name: Keerthivasan Kannan\n",
      "Date Range  2025-02-16 To 2025-02-18\n",
      "Total Worked  Weekdays: 1 days, 10.00 hrs | Weekends: 1 days\n",
      "Extra Hours  Weekdays: 0 days, 0.00 hrs | Weekends: 0 days, 0.00 hrs\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import calendar\n",
    "\n",
    "# Read your logs\n",
    "df_log = pd.read_excel(\"C:/Users/HP/Desktop/finalCopy of PagerDutyLog - Feb.xlsx\")\n",
    "df_log['From Date'] = pd.to_datetime(df_log['From Date'])\n",
    "df_log['To Date'] = pd.to_datetime(df_log['To Date'])\n",
    "\n",
    "# Optional: read holiday list and extract valid holiday dates\n",
    "holiday_df = pd.read_excel(\"C:/Users/HP/Desktop/Mindera India - Holiday List 2025.xlsx\")\n",
    "holiday_df.columns = holiday_df.iloc[0]\n",
    "holiday_df = holiday_df.drop(index=0)\n",
    "holiday_df = holiday_df.rename(columns={pd.NaT: \"Misc\"})\n",
    "holiday_df['Date'] = pd.to_datetime(holiday_df['Date'], errors='coerce')\n",
    "mandatory_holidays = holiday_df[~holiday_df['Holiday Type'].str.contains(\"Optional\", na=False)]['Date'].dropna().dt.date.tolist()\n",
    "\n",
    "# -------------------- STEP 1: Calculate base worked days --------------------\n",
    "\n",
    "def calculate_day_hour_summary(row):\n",
    "    from_dt = datetime.combine(row['From Date'], row['From Time'])\n",
    "    to_dt = datetime.combine(row['To Date'], row['To Time'])\n",
    "\n",
    "    weekday_hours = 0.0\n",
    "    weekend_days = 0\n",
    "    weekday_days = 0\n",
    "    current = from_dt\n",
    "    while current <= to_dt:\n",
    "        next_dt = min(to_dt, datetime.combine(current.date(), datetime.max.time()))\n",
    "        duration_hours = (next_dt - current).total_seconds() / 3600.0\n",
    "\n",
    "        day_of_week = calendar.weekday(current.year, current.month, current.day)\n",
    "\n",
    "        if day_of_week < 5:\n",
    "            weekday_hours += duration_hours\n",
    "        else:\n",
    "            weekend_days += 1\n",
    "\n",
    "        current = next_dt + timedelta(seconds=1)\n",
    "\n",
    "    weekday_days = int(weekday_hours // 24)\n",
    "    weekday_rem_hours = round(weekday_hours % 24, 2)\n",
    "\n",
    "    if weekday_rem_hours == 24.0:\n",
    "        weekday_days += 1\n",
    "        weekday_rem_hours = 0.0\n",
    "\n",
    "    return pd.Series([weekday_days, weekday_rem_hours, weekend_days])\n",
    "\n",
    "df_log[['Weekday Days', 'Weekday Hours', 'Weekend Days']] = df_log.apply(calculate_day_hour_summary, axis=1)\n",
    "\n",
    "# -------------------- STEP 2: Handle holidays --------------------\n",
    "\n",
    "def count_holidays(start_date, end_date, holidays):\n",
    "    current = start_date\n",
    "    count = 0\n",
    "    while current <= end_date:\n",
    "        if current.weekday() < 5 and current.date() in holidays:\n",
    "            count += 1\n",
    "        current += timedelta(days=1)\n",
    "    return count\n",
    "\n",
    "df_log['Holiday Weekdays'] = df_log.apply(lambda row: count_holidays(row['From Date'], row['To Date'], mandatory_holidays), axis=1)\n",
    "\n",
    "# -------------------- STEP 3: Compute Extra --------------------\n",
    "\n",
    "df_log['Extra Weekday Days'] = df_log['Holiday Weekdays']\n",
    "df_log['Extra Weekday Hours'] = 0.0\n",
    "df_log['Extra Weekend Days'] = 0\n",
    "df_log['Extra Weekend Hours'] = 0.0\n",
    "\n",
    "df_final = df_log.copy()\n",
    "\n",
    "# -------------------- STEP 4: Print Summary --------------------\n",
    "\n",
    "for idx, row in df_final.iterrows():\n",
    "    wd = int(row.get('Weekday Days', 0) or 0)\n",
    "    wh = row.get('Weekday Hours', 0) or 0.0\n",
    "    we_d = int(row.get('Weekend Days', 0) or 0)\n",
    "    ewd = int(row.get('Extra Weekday Days', 0) or 0)\n",
    "    ewh = row.get('Extra Weekday Hours', 0) or 0.0\n",
    "    ewed = int(row.get('Extra Weekend Days', 0) or 0)\n",
    "    eweh = row.get('Extra Weekend Hours', 0) or 0.0\n",
    "\n",
    "    print(\"Name: {}\".format(row['Name']))\n",
    "    print(\"Date Range  {} To {}\".format(row['From Date'].strftime('%Y-%m-%d'), row['To Date'].strftime('%Y-%m-%d')))\n",
    "    print(\"Total Worked  Weekdays: {} days, {:.2f} hrs | Weekends: {} days\".format(wd, wh, we_d))\n",
    "    print(\"Extra Hours  Weekdays: {} days, {:.2f} hrs | Weekends: {} days, {:.2f} hrs\".format(ewd, ewh, ewed, eweh))\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de3453e-85dc-4c7b-b86f-f3df03785c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import calendar\n",
    "\n",
    "# Load data\n",
    "holiday_df = pd.read_excel(\"Mindera India - Holiday List 2025.xlsx\")\n",
    "log_df = pd.read_excel(\"finalCopy of PagerDutyLog - Feb.xlsx\")\n",
    "\n",
    "# --- Process Holiday Sheet ---\n",
    "holiday_df.columns = holiday_df.iloc[0]\n",
    "holiday_df = holiday_df.drop(index=0)\n",
    "holiday_df = holiday_df.rename(columns={pd.NaT: \"Misc\"})\n",
    "holiday_df['Date'] = pd.to_datetime(holiday_df['Date'], errors='coerce')\n",
    "mandatory_holidays = holiday_df[~holiday_df['Holiday Type'].str.contains(\"Optional\", na=False)]['Date'].dropna().dt.date.tolist()\n",
    "\n",
    "# --- Convert From and To DateTime ---\n",
    "log_df['From DateTime'] = pd.to_datetime(log_df['From Date'].astype(str) + ' ' + log_df['From Time'].astype(str))\n",
    "log_df['To DateTime'] = pd.to_datetime(log_df['To Date'].astype(str) + ' ' + log_df['To Time'].astype(str))\n",
    "\n",
    "# Format readable range\n",
    "log_df['Formatted Range'] = log_df['From DateTime'].dt.strftime('%a, %b %d @ %H:%M') + \" To \" + log_df['To DateTime'].dt.strftime('%a, %b %d @ %H:%M')\n",
    "\n",
    "# Group date ranges by name (handles multiple entries)\n",
    "date_ranges_grouped = log_df.groupby('Name')['Formatted Range'].apply(list).reset_index(name='Date Ranges')\n",
    "\n",
    "# --- Time Breakdown Function ---\n",
    "def compute_days_hours(row):\n",
    "    from_dt = row['From DateTime']\n",
    "    to_dt = row['To DateTime']\n",
    "\n",
    "    weekday_hours = 0.0\n",
    "    weekend_days = 0\n",
    "    holiday_weekday_days = 0\n",
    "\n",
    "    current = from_dt\n",
    "    while current <= to_dt:\n",
    "        next_dt = min(to_dt, datetime.combine(current.date(), datetime.max.time()))\n",
    "        duration_hours = (next_dt - current).total_seconds() / 3600.0\n",
    "        is_weekend = current.weekday() >= 5\n",
    "        is_holiday = current.date() in mandatory_holidays\n",
    "\n",
    "        if is_weekend:\n",
    "            weekend_days += 1\n",
    "        elif is_holiday:\n",
    "            holiday_weekday_days += 1\n",
    "        else:\n",
    "            weekday_hours += duration_hours\n",
    "\n",
    "        current = next_dt + timedelta(seconds=1)\n",
    "\n",
    "    weekday_days = int(weekday_hours // 24)\n",
    "    weekday_rem_hours = round(weekday_hours % 24, 2)\n",
    "    return pd.Series([weekday_days, weekday_rem_hours, weekend_days, holiday_weekday_days])\n",
    "\n",
    "# Apply breakdown\n",
    "log_df[['Weekday Days', 'Weekday Hours', 'Weekend Days', 'Holiday Weekday Days']] = log_df.apply(compute_days_hours, axis=1)\n",
    "\n",
    "# --- Group and Normalize for Multiple Entries ---\n",
    "summary_grouped = log_df.groupby('Name')[['Weekday Days', 'Weekday Hours', 'Weekend Days', 'Holiday Weekday Days']].sum().reset_index()\n",
    "\n",
    "# Normalize weekday hours > 24\n",
    "def normalize_hours(row):\n",
    "    additional_days = int(row['Weekday Hours'] // 24)\n",
    "    row['Weekday Days'] += additional_days\n",
    "    row['Weekday Hours'] = round(row['Weekday Hours'] % 24, 2)\n",
    "    return row\n",
    "\n",
    "summary_grouped = summary_grouped.apply(normalize_hours, axis=1)\n",
    "\n",
    "# --- Merge and Print ---\n",
    "final_summary = pd.merge(summary_grouped, date_ranges_grouped, on='Name', how='left')\n",
    "\n",
    "# Pretty print for each person\n",
    "for _, row in final_summary.iterrows():\n",
    "    print(\"=== Name:\", row['Name'], \"===\")\n",
    "    print(\"Date Ranges Worked:\")\n",
    "    for rng in row['Date Ranges']:\n",
    "        print(\"  \", rng)\n",
    "    print(\"Total Worked  Weekdays:\", int(row['Weekday Days']), \"days,\", \"%.2f\" % row['Weekday Hours'], \"hrs | Weekends:\", int(row['Weekend Days']), \"days\")\n",
    "    print(\"Extra Holiday Deduction \", int(row['Holiday Weekday Days']), \"weekday holidays\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8ce77450-844a-4a66-95b3-936fd93ae354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Name: Ahalya Hegde ===\n",
      "Date Ranges Worked:\n",
      "   Tue, Feb 11 @ 09:00 To Mon, Feb 17 @ 09:00\n",
      "Total Worked  Weekdays: 4 days, 0.00 hrs | Weekends: 2 days\n",
      "Extra Holiday Deduction  0 weekday holidays\n",
      "\n",
      "=== Name: Ayush Rajeev ===\n",
      "Date Ranges Worked:\n",
      "   Mon, Feb 03 @ 05:30 To Mon, Feb 10 @ 05:30\n",
      "Total Worked  Weekdays: 5 days, 0.00 hrs | Weekends: 2 days\n",
      "Extra Holiday Deduction  0 weekday holidays\n",
      "\n",
      "=== Name: Basudev Singh Munda ===\n",
      "Date Ranges Worked:\n",
      "   Mon, Feb 03 @ 09:00 To Tue, Feb 11 @ 09:00\n",
      "Total Worked  Weekdays: 6 days, 0.00 hrs | Weekends: 2 days\n",
      "Extra Holiday Deduction  0 weekday holidays\n",
      "\n",
      "=== Name: Dolly Chahar ===\n",
      "Date Ranges Worked:\n",
      "   Mon, Feb 17 @ 09:00 To Mon, Feb 24 @ 09:00\n",
      "Total Worked  Weekdays: 5 days, 0.00 hrs | Weekends: 2 days\n",
      "Extra Holiday Deduction  0 weekday holidays\n",
      "\n",
      "=== Name: Durai Ramalingam ===\n",
      "Date Ranges Worked:\n",
      "   Mon, Feb 24 @ 04:30 To Sat, Mar 01 @ 00:00\n",
      "   Mon, Feb 10 @ 04:30 To Mon, Feb 17 @ 04:30\n",
      "   Sat, Feb 01 @ 00:00 To Mon, Feb 03 @ 04:30\n",
      "Total Worked  Weekdays: 10 days, 0.00 hrs | Weekends: 4 days\n",
      "Extra Holiday Deduction  0 weekday holidays\n",
      "\n",
      "=== Name: Jithin Johnson ===\n",
      "Date Ranges Worked:\n",
      "   Mon, Feb 17 @ 04:30 To Mon, Feb 24 @ 04:30\n",
      "   Mon, Feb 03 @ 04:30 To Mon, Feb 10 @ 04:30\n",
      "Total Worked  Weekdays: 10 days, 0.00 hrs | Weekends: 4 days\n",
      "Extra Holiday Deduction  0 weekday holidays\n",
      "\n",
      "=== Name: Kapil Jugnu ===\n",
      "Date Ranges Worked:\n",
      "   Mon, Feb 17 @ 04:30 To Mon, Feb 24 @ 04:30\n",
      "Total Worked  Weekdays: 5 days, 0.00 hrs | Weekends: 2 days\n",
      "Extra Holiday Deduction  0 weekday holidays\n",
      "\n",
      "=== Name: Keerthivasan Kannan ===\n",
      "Date Ranges Worked:\n",
      "   Tue, Feb 11 @ 10:00 To Sun, Feb 16 @ 01:43\n",
      "   Sun, Feb 16 @ 11:45 To Tue, Feb 18 @ 10:00\n",
      "Total Worked  Weekdays: 5 days, 0.00 hrs | Weekends: 3 days\n",
      "Extra Holiday Deduction  0 weekday holidays\n",
      "\n",
      "=== Name: Prakash Rajendran ===\n",
      "Date Ranges Worked:\n",
      "   Sat, Feb 01 @ 00:00 To Mon, Feb 03 @ 09:00\n",
      "Total Worked  Weekdays: 0 days, 9.00 hrs | Weekends: 2 days\n",
      "Extra Holiday Deduction  0 weekday holidays\n",
      "\n",
      "=== Name: akash dey ===\n",
      "Date Ranges Worked:\n",
      "   Sat, Feb 01 @ 00:00 To Mon, Feb 03 @ 04:30\n",
      "Total Worked  Weekdays: 0 days, 4.50 hrs | Weekends: 2 days\n",
      "Extra Holiday Deduction  0 weekday holidays\n",
      "\n",
      "=== Name: ankit thakkar ===\n",
      "Date Ranges Worked:\n",
      "   Mon, Feb 10 @ 05:30 To Mon, Feb 17 @ 05:30\n",
      "Total Worked  Weekdays: 5 days, 0.00 hrs | Weekends: 2 days\n",
      "Extra Holiday Deduction  0 weekday holidays\n",
      "\n",
      "=== Name: muthumani gurusamy ===\n",
      "Date Ranges Worked:\n",
      "   Mon, Feb 24 @ 05:30 To Sat, Mar 01 @ 00:00\n",
      "Total Worked  Weekdays: 4 days, 18.50 hrs | Weekends: 0 days\n",
      "Extra Holiday Deduction  0 weekday holidays\n",
      "\n",
      "=== Name: nirmalraja selvam ===\n",
      "Date Ranges Worked:\n",
      "   Mon, Feb 10 @ 04:30 To Mon, Feb 17 @ 04:30\n",
      "Total Worked  Weekdays: 5 days, 0.00 hrs | Weekends: 2 days\n",
      "Extra Holiday Deduction  0 weekday holidays\n",
      "\n",
      "=== Name: sahil kanojia ===\n",
      "Date Ranges Worked:\n",
      "   Mon, Feb 03 @ 04:30 To Mon, Feb 10 @ 04:30\n",
      "Total Worked  Weekdays: 5 days, 0.00 hrs | Weekends: 2 days\n",
      "Extra Holiday Deduction  0 weekday holidays\n",
      "\n",
      "=== Name: vamshi bandla ===\n",
      "Date Ranges Worked:\n",
      "   Mon, Feb 24 @ 09:00 To Sat, Mar 01 @ 00:00\n",
      "Total Worked  Weekdays: 4 days, 15.00 hrs | Weekends: 0 days\n",
      "Extra Holiday Deduction  0 weekday holidays\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Load data\n",
    "holiday_df = pd.read_excel(\"C:/Users/HP/Desktop/Mindera India - Holiday List 2025.xlsx\")\n",
    "log_df = pd.read_excel(\"C:/Users/HP/Desktop/finalCopy of PagerDutyLog - Feb.xlsx\")\n",
    "\n",
    "# --- Process Holiday Sheet ---\n",
    "holiday_df.columns = holiday_df.iloc[0]\n",
    "holiday_df = holiday_df.drop(index=0)\n",
    "holiday_df = holiday_df.rename(columns={pd.NaT: \"Misc\"})\n",
    "holiday_df['Date'] = pd.to_datetime(holiday_df['Date'], errors='coerce')\n",
    "mandatory_holidays = holiday_df[~holiday_df['Holiday Type'].str.contains(\"Optional\", na=False)]['Date'].dropna().dt.date.tolist()\n",
    "\n",
    "# --- Convert From and To DateTime ---\n",
    "log_df['From DateTime'] = pd.to_datetime(log_df['From Date'].astype(str) + ' ' + log_df['From Time'].astype(str))\n",
    "log_df['To DateTime'] = pd.to_datetime(log_df['To Date'].astype(str) + ' ' + log_df['To Time'].astype(str))\n",
    "\n",
    "# Format readable range (24-hour format)\n",
    "log_df['Formatted Range'] = log_df['From DateTime'].dt.strftime('%a, %b %d @ %H:%M') + \" To \" + log_df['To DateTime'].dt.strftime('%a, %b %d @ %H:%M')\n",
    "\n",
    "# --- Time Breakdown Function ---\n",
    "def compute_days_hours(row):\n",
    "    from_dt = row['From DateTime']\n",
    "    to_dt = row['To DateTime']\n",
    "\n",
    "    weekday_hours = 0.0\n",
    "    weekend_days = 0\n",
    "    holiday_weekday_days = 0\n",
    "\n",
    "    current = from_dt\n",
    "    while current <= to_dt:\n",
    "        # End of current day or to_dt, whichever is earlier\n",
    "        next_dt = min(to_dt, datetime.combine(current.date(), datetime.max.time()))\n",
    "        duration_hours = (next_dt - current).total_seconds() / 3600.0\n",
    "        is_weekend = current.weekday() >= 5\n",
    "        is_holiday = current.date() in mandatory_holidays\n",
    "\n",
    "        if is_weekend:\n",
    "            weekend_days += 1\n",
    "        elif is_holiday:\n",
    "            holiday_weekday_days += 1\n",
    "        else:\n",
    "            weekday_hours += duration_hours\n",
    "\n",
    "        # Move to next day's start (add 1 second to avoid overlap)\n",
    "        current = next_dt + timedelta(seconds=1)\n",
    "\n",
    "    weekday_days = int(weekday_hours // 24)\n",
    "    weekday_rem_hours = round(weekday_hours % 24, 2)\n",
    "    return pd.Series([weekday_days, weekday_rem_hours, weekend_days, holiday_weekday_days])\n",
    "\n",
    "# Apply breakdown\n",
    "log_df[['Weekday Days', 'Weekday Hours', 'Weekend Days', 'Holiday Weekday Days']] = log_df.apply(compute_days_hours, axis=1)\n",
    "\n",
    "# --- Group and Normalize for Multiple Entries ---\n",
    "summary_grouped = log_df.groupby('Name')[['Weekday Days', 'Weekday Hours', 'Weekend Days', 'Holiday Weekday Days']].sum().reset_index()\n",
    "\n",
    "# Normalize weekday hours > 24 into days\n",
    "def normalize_hours(row):\n",
    "    additional_days = int(row['Weekday Hours'] // 24)\n",
    "    row['Weekday Days'] += additional_days\n",
    "    row['Weekday Hours'] = round(row['Weekday Hours'] % 24, 2)\n",
    "    return row\n",
    "\n",
    "summary_grouped = summary_grouped.apply(normalize_hours, axis=1)\n",
    "\n",
    "# Group date ranges by name (handles multiple entries)\n",
    "date_ranges_grouped = log_df.groupby('Name')['Formatted Range'].apply(list).reset_index(name='Date Ranges')\n",
    "\n",
    "# --- Merge summary and date ranges ---\n",
    "final_summary = pd.merge(summary_grouped, date_ranges_grouped, on='Name', how='left')\n",
    "\n",
    "# --- Print the summary ---\n",
    "for _, row in final_summary.iterrows():\n",
    "    print(\"=== Name:\", row['Name'], \"===\")\n",
    "    print(\"Date Ranges Worked:\")\n",
    "    for rng in row['Date Ranges']:\n",
    "        print(\"  \", rng)\n",
    "    print(\"Total Worked  Weekdays:\", int(row['Weekday Days']), \"days,\", \"%.2f\" % row['Weekday Hours'], \"hrs | Weekends:\", int(row['Weekend Days']), \"days\")\n",
    "    print(\"Extra Holiday Deduction \", int(row['Holiday Weekday Days']), \"weekday holidays\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbe3ef91-dd2b-44a2-bb38-1e256f107706",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Date'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Date'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# === Clean Holiday Data ===\u001b[39;00m\n\u001b[0;32m     10\u001b[0m holiday_df \u001b[38;5;241m=\u001b[39m holiday_df\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{pd\u001b[38;5;241m.\u001b[39mNaT: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMisc\u001b[39m\u001b[38;5;124m\"\u001b[39m})  \u001b[38;5;66;03m# Only if needed\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m holiday_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(holiday_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Extract only mandatory holidays (non-optional)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m mandatory_holidays \u001b[38;5;241m=\u001b[39m holiday_df[\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;241m~\u001b[39mholiday_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHoliday Type\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcontains(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptional\u001b[39m\u001b[38;5;124m\"\u001b[39m, na\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     16\u001b[0m ][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdropna()\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mdate\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Date'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# === Load Files ===\n",
    "# === Load Files ===\n",
    "pager_df = pd.read_excel(\"C:/Users/HP/Desktop/finalCopy of PagerDutyLog - Feb.xlsx\")\n",
    "holiday_df = pd.read_excel(\"C:/Users/HP/Desktop/Mindera India - Holiday List 2025.xlsx\")\n",
    "\n",
    "\n",
    "\n",
    "# === Clean Holiday Data ===\n",
    "holiday_df = holiday_df.rename(columns={pd.NaT: \"Misc\"})  # Only if needed\n",
    "holiday_df['Date'] = pd.to_datetime(holiday_df['Date'], errors='coerce')\n",
    "\n",
    "# Extract only mandatory holidays (non-optional)\n",
    "mandatory_holidays = holiday_df[\n",
    "    ~holiday_df['Holiday Type'].str.contains(\"Optional\", na=False)\n",
    "]['Date'].dropna().dt.date.tolist()\n",
    "\n",
    "# === Clean PagerDuty Data ===\n",
    "pager_df['Start'] = pd.to_datetime(\n",
    "    pager_df['From Date'].astype(str) + ' ' + pager_df['From Time'].astype(str),\n",
    "    errors='coerce'\n",
    ")\n",
    "pager_df['End'] = pd.to_datetime(\n",
    "    pager_df['To Date'].astype(str) + ' ' + pager_df['To Time'].astype(str),\n",
    "    errors='coerce'\n",
    ")\n",
    "\n",
    "# === Calculate Total Duration in Hours ===\n",
    "pager_df['Total Duration (hrs)'] = (pager_df['End'] - pager_df['Start']).dt.total_seconds() / 3600\n",
    "\n",
    "# === Handle Holiday Counting with Warnings ===\n",
    "warnings = []\n",
    "\n",
    "def count_holidays(start, end, holiday_list):\n",
    "    if pd.isna(start) or pd.isna(end):\n",
    "        return 0\n",
    "    days = pd.date_range(start=start.date(), end=end.date(), freq='D')\n",
    "    holiday_count = sum(day.date() in holiday_list for day in days)\n",
    "    total_days = len(days)\n",
    "    \n",
    "    if holiday_count > total_days:\n",
    "        warnings.append(f\" More holidays ({holiday_count}) than total days ({total_days}) from {start} to {end}. Please recheck.\")\n",
    "        holiday_count = total_days  # Cap it to avoid negative durations\n",
    "\n",
    "    return holiday_count\n",
    "\n",
    "pager_df['Holidays Count'] = pager_df.apply(\n",
    "    lambda row: count_holidays(row['Start'], row['End'], mandatory_holidays),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# === Subtract Holiday Hours (assuming 24 hrs per holiday) ===\n",
    "pager_df['Actual Duration (hrs)'] = pager_df['Total Duration (hrs)'] - pager_df['Holidays Count'] * 24\n",
    "\n",
    "# === Format Duration to \"days, hours\" string ===\n",
    "def convert_to_days_hours(hours):\n",
    "    if pd.isna(hours):\n",
    "        return \"0 days, 0.00 hrs\"\n",
    "    days = int(hours // 24)\n",
    "    rem_hours = round(hours % 24, 2)\n",
    "    return f\"{days} days, {rem_hours:.2f} hrs\"\n",
    "\n",
    "# Apply readable duration format\n",
    "pager_df['Total Duration (days and hours)'] = pager_df['Total Duration (hrs)'].apply(convert_to_days_hours)\n",
    "pager_df['Actual Duration (days and hours)'] = pager_df['Actual Duration (hrs)'].apply(convert_to_days_hours)\n",
    "\n",
    "# === Group by Name and Include Start/End ===\n",
    "grouped_df = pager_df.groupby('Name').agg({\n",
    "    'Start': 'min',   # First on-call shift\n",
    "    'End': 'max',     # Last on-call shift\n",
    "    'Total Duration (hrs)': 'sum',\n",
    "    'Actual Duration (hrs)': 'sum',\n",
    "    'Holidays Count': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Convert timestamps and durations\n",
    "grouped_df['Start'] = grouped_df['Start'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "grouped_df['End'] = grouped_df['End'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "grouped_df['Total Duration (days and hours)'] = grouped_df['Total Duration (hrs)'].apply(convert_to_days_hours)\n",
    "grouped_df['Actual Duration (days and hours)'] = grouped_df['Actual Duration (hrs)'].apply(convert_to_days_hours)\n",
    "\n",
    "# Final Column Order\n",
    "grouped_df = grouped_df[['Name', 'Start', 'End', 'Holidays Count',\n",
    "                         'Total Duration (days and hours)',\n",
    "                         'Actual Duration (days and hours)']]\n",
    "\n",
    "# === Print Output Summary ===\n",
    "print(\"\\n===== Adjusted PagerDuty Duration Summary (Grouped by Name) =====\\n\")\n",
    "print(grouped_df.to_string(index=False))\n",
    "\n",
    "# === Print Any Holiday Warnings ===\n",
    "if warnings:\n",
    "    print(\"\\n=====  Holiday Warnings =====\")\n",
    "    for w in warnings:\n",
    "        print(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f1d3cfbe-511c-4f96-8d5a-a294318410c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Holidays Count'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Holidays Count'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 41\u001b[0m\n\u001b[0;32m     37\u001b[0m     total_days \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(days)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# === Subtract Holiday Hours ===\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m pager_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActual Duration (hrs)\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pager_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal Duration (hrs)\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m pager_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHolidays Count\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m24\u001b[39m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# === Convert Hours to \"Days, Hours\" Format ===\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_to_days_hours\u001b[39m(hours):\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Holidays Count'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === Load Excel Files ===\n",
    "pager_df = pd.read_excel(\"C:/Users/HP/Desktop/finalCopy of PagerDutyLog - Feb.xlsx\")\n",
    "holiday_df = pd.read_excel(\"C:/Users/HP/Desktop/Mindera India - Holiday List 2025.xlsx\", skiprows=1)\n",
    "\n",
    "# === Clean Holiday Data ===\n",
    "holiday_df = holiday_df.rename(columns={\"Unnamed: 3\": \"Date\", \"Unnamed: 4\": \"Holiday Type\"})\n",
    "holiday_df['Date'] = pd.to_datetime(holiday_df['Date'], errors='coerce')\n",
    "\n",
    "# Extract mandatory holidays (i.e., not containing \"Optional\")\n",
    "mandatory_holidays = holiday_df[\n",
    "    ~holiday_df['Holiday Type'].str.contains(\"Optional\", na=False)\n",
    "]['Date'].dropna().dt.date.tolist()\n",
    "\n",
    "# === Clean PagerDuty Data ===\n",
    "pager_df['Start'] = pd.to_datetime(\n",
    "    pager_df['From Date'].astype(str) + ' ' + pager_df['From Time'].astype(str),\n",
    "    errors='coerce'\n",
    ")\n",
    "pager_df['End'] = pd.to_datetime(\n",
    "    pager_df['To Date'].astype(str) + ' ' + pager_df['To Time'].astype(str),\n",
    "    errors='coerce'\n",
    ")\n",
    "\n",
    "# === Calculate Total Duration in Hours ===\n",
    "pager_df['Total Duration (hrs)'] = (pager_df['End'] - pager_df['Start']).dt.total_seconds() / 3600\n",
    "\n",
    "# === Count Holidays with Warning if Over Limit ===\n",
    "warnings = []\n",
    "\n",
    "def count_holidays(start, end, holiday_list):\n",
    "    if pd.isna(start) or pd.isna(end):\n",
    "        return 0\n",
    "    days = pd.date_range(start=start.date(), end=end.date(), freq='D')\n",
    "    holiday_count = sum(day.date() in holiday_list for day in days)\n",
    "    total_days = len(days)\n",
    "    \n",
    "   \n",
    "# === Subtract Holiday Hours ===\n",
    "pager_df['Actual Duration (hrs)'] = pager_df['Total Duration (hrs)'] - pager_df['Holidays Count'] * 24\n",
    "\n",
    "# === Convert Hours to \"Days, Hours\" Format ===\n",
    "def convert_to_days_hours(hours):\n",
    "    if pd.isna(hours):\n",
    "        return \"0 days, 0.00 hrs\"\n",
    "    days = int(hours // 24)\n",
    "    rem_hours = round(hours % 24, 2)\n",
    "    return f\"{days} days, {rem_hours:.2f} hrs\"\n",
    "\n",
    "pager_df['Total Duration (days and hours)'] = pager_df['Total Duration (hrs)'].apply(convert_to_days_hours)\n",
    "pager_df['Actual Duration (days and hours)'] = pager_df['Actual Duration (hrs)'].apply(convert_to_days_hours)\n",
    "\n",
    "# === Group by Name and Include Start/End ===\n",
    "grouped_df = pager_df.groupby('Name').agg({\n",
    "    'Start': 'min',\n",
    "    'End': 'max',\n",
    "    'Total Duration (hrs)': 'sum',\n",
    "    'Actual Duration (hrs)': 'sum',\n",
    "    'Holidays Count': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "grouped_df['Start'] = grouped_df['Start'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "grouped_df['End'] = grouped_df['End'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "grouped_df['Total Duration (days and hours)'] = grouped_df['Total Duration (hrs)'].apply(convert_to_days_hours)\n",
    "grouped_df['Actual Duration (days and hours)'] = grouped_df['Actual Duration (hrs)'].apply(convert_to_days_hours)\n",
    "\n",
    "# Final Column Order\n",
    "grouped_df = grouped_df[['Name', 'Start', 'End', 'Holidays Count',\n",
    "                         'Total Duration (days and hours)',\n",
    "                         'Actual Duration (days and hours)']]\n",
    "\n",
    "# === Print Final Output ===\n",
    "print(\"\\n===== Adjusted PagerDuty Duration Summary (Grouped by Name) =====\\n\")\n",
    "print(grouped_df.to_string(index=False))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "51744bfe-8f50-4e69-abd8-35d8cbaf5cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====  Adjusted PagerDuty Duration Summary (Grouped by Name) =====\n",
      "\n",
      "               Name            Start              End  Holidays Count Total Duration (days and hours) Actual Duration (days and hours)\n",
      "       Ahalya Hegde 2025-02-11 09:00 2025-02-17 09:00               0                6 days, 0.00 hrs                 6 days, 0.00 hrs\n",
      "       Ayush Rajeev 2025-02-03 05:30 2025-02-10 05:30               0                7 days, 0.00 hrs                 7 days, 0.00 hrs\n",
      "Basudev Singh Munda 2025-02-03 09:00 2025-02-11 09:00               0                8 days, 0.00 hrs                 8 days, 0.00 hrs\n",
      "       Dolly Chahar 2025-02-17 09:00 2025-02-24 09:00               1                7 days, 0.00 hrs                 6 days, 0.00 hrs\n",
      "   Durai Ramalingam 2025-02-01 00:00 2025-03-01 00:00               3               14 days, 0.00 hrs                11 days, 0.00 hrs\n",
      "     Jithin Johnson 2025-02-03 04:30 2025-02-24 04:30               1               14 days, 0.00 hrs                13 days, 0.00 hrs\n",
      "        Kapil Jugnu 2025-02-17 04:30 2025-02-24 04:30               1                7 days, 0.00 hrs                 6 days, 0.00 hrs\n",
      "Keerthivasan Kannan 2025-02-11 10:00 2025-02-18 10:00               0               6 days, 13.97 hrs                6 days, 13.97 hrs\n",
      "  Prakash Rajendran 2025-02-01 00:00 2025-02-03 09:00               0                2 days, 9.00 hrs                 2 days, 9.00 hrs\n",
      "       Saumya Sinha 2025-02-26 09:00 2025-02-27 18:00               2                1 days, 9.00 hrs                -1 days, 9.00 hrs\n",
      "          akash dey 2025-02-01 00:00 2025-02-03 04:30               0                2 days, 4.50 hrs                 2 days, 4.50 hrs\n",
      "      ankit thakkar 2025-02-10 05:30 2025-02-17 05:30               0                7 days, 0.00 hrs                 7 days, 0.00 hrs\n",
      " muthumani gurusamy 2025-02-24 05:30 2025-03-01 00:00               3               4 days, 18.50 hrs                1 days, 18.50 hrs\n",
      "  nirmalraja selvam 2025-02-10 04:30 2025-02-17 04:30               0                7 days, 0.00 hrs                 7 days, 0.00 hrs\n",
      "      sahil kanojia 2025-02-03 04:30 2025-02-10 04:30               0                7 days, 0.00 hrs                 7 days, 0.00 hrs\n",
      "      vamshi bandla 2025-02-24 09:00 2025-03-01 00:00               3               4 days, 15.00 hrs                1 days, 15.00 hrs\n",
      "\n",
      "=====  Holiday Warnings Detected =====\n",
      " Saumya Sinha has more holidays (2) than total days (2) from 2025-02-26 09:00 to 2025-02-27 18:00. Please recheck.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === Load Files ===\n",
    "pager_df = pd.read_excel(\"C:/Users/HP/Desktop/finalCopy of PagerDutyLog - Feb.xlsx\")\n",
    "holiday_df = pd.read_excel(\"C:/Users/HP/Desktop/Mindera India - Holiday List 2025.xlsx\")\n",
    "\n",
    "# === Clean Holiday Data ===\n",
    "# Use first row as header if needed\n",
    "if not 'Date' in holiday_df.columns:\n",
    "    holiday_df.columns = holiday_df.iloc[0]\n",
    "    holiday_df = holiday_df.drop(index=0)\n",
    "\n",
    "# Rename any NaN column (if present)\n",
    "holiday_df = holiday_df.rename(columns={pd.NaT: \"Misc\"})\n",
    "\n",
    "# Ensure 'Date' column exists\n",
    "if 'Date' not in holiday_df.columns:\n",
    "    raise KeyError(\"Column 'Date' not found in holiday_df. Please check your Excel headers.\")\n",
    "\n",
    "holiday_df['Date'] = pd.to_datetime(holiday_df['Date'], errors='coerce')\n",
    "\n",
    "# Extract only mandatory holidays\n",
    "mandatory_holidays = holiday_df[\n",
    "    ~holiday_df['Holiday Type'].str.contains(\"Optional\", na=False)\n",
    "]['Date'].dropna().dt.date.tolist()\n",
    "\n",
    "# === Clean PagerDuty Data ===\n",
    "pager_df['Start'] = pd.to_datetime(\n",
    "    pager_df['From Date'].astype(str) + ' ' + pager_df['From Time'].astype(str),\n",
    "    errors='coerce'\n",
    ")\n",
    "pager_df['End'] = pd.to_datetime(\n",
    "    pager_df['To Date'].astype(str) + ' ' + pager_df['To Time'].astype(str),\n",
    "    errors='coerce'\n",
    ")\n",
    "\n",
    "# === Calculate Total Duration in Hours ===\n",
    "pager_df['Total Duration (hrs)'] = (pager_df['End'] - pager_df['Start']).dt.total_seconds() / 3600\n",
    "\n",
    "# === Handle Holiday Counting with Warnings ===\n",
    "warnings = []\n",
    "\n",
    "def count_holidays(start, end, holiday_list, name):\n",
    "    if pd.isna(start) or pd.isna(end):\n",
    "        return 0\n",
    "    days = pd.date_range(start=start.date(), end=end.date(), freq='D')\n",
    "    holiday_count = sum(day.date() in holiday_list for day in days)\n",
    "    total_days = len(days)\n",
    "\n",
    "    if holiday_count >= total_days:\n",
    "        warnings.append(\n",
    "            f\" {name} has more holidays ({holiday_count}) than total days ({total_days}) \"\n",
    "            f\"from {start.strftime('%Y-%m-%d %H:%M')} to {end.strftime('%Y-%m-%d %H:%M')}. Please recheck.\"\n",
    "        )\n",
    "        holiday_count = total_days  # Cap to avoid negative actual durations\n",
    "\n",
    "    return holiday_count\n",
    "\n",
    "pager_df['Holidays Count'] = pager_df.apply(\n",
    "    lambda row: count_holidays(row['Start'], row['End'], mandatory_holidays, row['Name']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# === Subtract Holiday Hours (assuming 24 hrs per holiday) ===\n",
    "pager_df['Actual Duration (hrs)'] = pager_df['Total Duration (hrs)'] - pager_df['Holidays Count'] * 24\n",
    "\n",
    "# === Format Duration to \"days, hours\" string ===\n",
    "def convert_to_days_hours(hours):\n",
    "    if pd.isna(hours):\n",
    "        return \"0 days, 0.00 hrs\"\n",
    "    days = int(hours // 24)\n",
    "    rem_hours = round(hours % 24, 2)\n",
    "    return f\"{days} days, {rem_hours:.2f} hrs\"\n",
    "\n",
    "pager_df['Total Duration (days and hours)'] = pager_df['Total Duration (hrs)'].apply(convert_to_days_hours)\n",
    "pager_df['Actual Duration (days and hours)'] = pager_df['Actual Duration (hrs)'].apply(convert_to_days_hours)\n",
    "\n",
    "# === Group by Name and Include First/Last Shift Times ===\n",
    "grouped_df = pager_df.groupby('Name').agg({\n",
    "    'Start': 'min',\n",
    "    'End': 'max',\n",
    "    'Total Duration (hrs)': 'sum',\n",
    "    'Actual Duration (hrs)': 'sum',\n",
    "    'Holidays Count': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "grouped_df['Start'] = grouped_df['Start'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "grouped_df['End'] = grouped_df['End'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "grouped_df['Total Duration (days and hours)'] = grouped_df['Total Duration (hrs)'].apply(convert_to_days_hours)\n",
    "grouped_df['Actual Duration (days and hours)'] = grouped_df['Actual Duration (hrs)'].apply(convert_to_days_hours)\n",
    "\n",
    "# Final Output Columns\n",
    "grouped_df = grouped_df[['Name', 'Start', 'End', 'Holidays Count',\n",
    "                         'Total Duration (days and hours)',\n",
    "                         'Actual Duration (days and hours)']]\n",
    "\n",
    "# === Print Summary ===\n",
    "print(\"\\n=====  Adjusted PagerDuty Duration Summary (Grouped by Name) =====\\n\")\n",
    "print(grouped_df.to_string(index=False))\n",
    "\n",
    "# === Print Any Holiday Warnings ===\n",
    "if warnings:\n",
    "    print(\"\\n=====  Holiday Warnings Detected =====\")\n",
    "    for w in warnings:\n",
    "        print(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "db8d3816-b5d9-4ee3-b86d-4f4f0fae4dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Adjusted PagerDuty Duration Summary (Grouped by Name) =====\n",
      "\n",
      "               Name            Start              End  Holidays Count Total Duration (days and hours) Actual Duration (days and hours)\n",
      "       Ahalya Hegde 2025-02-11 09:00 2025-02-17 09:00               2                6 days, 0.00 hrs                 4 days, 0.00 hrs\n",
      "       Ayush Rajeev 2025-02-03 05:30 2025-02-10 05:30               1                7 days, 0.00 hrs                 6 days, 0.00 hrs\n",
      "Basudev Singh Munda 2025-02-03 09:00 2025-02-11 09:00               1                8 days, 0.00 hrs                 7 days, 0.00 hrs\n",
      "       Dolly Chahar 2025-02-17 09:00 2025-02-24 09:00               1                7 days, 0.00 hrs                 6 days, 0.00 hrs\n",
      "   Durai Ramalingam 2025-02-01 00:00 2025-03-01 00:00               5               14 days, 0.00 hrs                 9 days, 0.00 hrs\n",
      "     Jithin Johnson 2025-02-03 04:30 2025-02-24 04:30               2               14 days, 0.00 hrs                12 days, 0.00 hrs\n",
      "        Kapil Jugnu 2025-02-17 04:30 2025-02-24 04:30               1                7 days, 0.00 hrs                 6 days, 0.00 hrs\n",
      "Keerthivasan Kannan 2025-02-11 10:00 2025-02-18 10:00               2               6 days, 13.97 hrs                4 days, 13.97 hrs\n",
      "  Prakash Rajendran 2025-02-01 00:00 2025-02-03 09:00               0                2 days, 9.00 hrs                 2 days, 9.00 hrs\n",
      "       Saumya Sinha 2025-02-26 09:00 2025-02-27 18:00               2                1 days, 9.00 hrs                -1 days, 9.00 hrs\n",
      "          akash dey 2025-02-01 00:00 2025-02-03 04:30               0                2 days, 4.50 hrs                 2 days, 4.50 hrs\n",
      "      ankit thakkar 2025-02-10 05:30 2025-02-17 05:30               2                7 days, 0.00 hrs                 5 days, 0.00 hrs\n",
      " muthumani gurusamy 2025-02-24 05:30 2025-03-01 00:00               3               4 days, 18.50 hrs                1 days, 18.50 hrs\n",
      "  nirmalraja selvam 2025-02-10 04:30 2025-02-17 04:30               2                7 days, 0.00 hrs                 5 days, 0.00 hrs\n",
      "      sahil kanojia 2025-02-03 04:30 2025-02-10 04:30               1                7 days, 0.00 hrs                 6 days, 0.00 hrs\n",
      "      vamshi bandla 2025-02-24 09:00 2025-03-01 00:00               3               4 days, 15.00 hrs                1 days, 15.00 hrs\n",
      "\n",
      "=====  Holiday Warnings =====\n",
      " ankit thakkar has a holiday on a weekend (Saturday - 2025-02-15) during on-call from 2025-02-10 05:30 to 2025-02-17 05:30.\n",
      " nirmalraja selvam has a holiday on a weekend (Saturday - 2025-02-15) during on-call from 2025-02-10 04:30 to 2025-02-17 04:30.\n",
      " Ahalya Hegde has a holiday on a weekend (Saturday - 2025-02-15) during on-call from 2025-02-11 09:00 to 2025-02-17 09:00.\n",
      " Durai Ramalingam has a holiday on a weekend (Saturday - 2025-02-15) during on-call from 2025-02-10 04:30 to 2025-02-17 04:30.\n",
      " Keerthivasan Kannan has a holiday on a weekend (Saturday - 2025-02-15) during on-call from 2025-02-11 10:00 to 2025-02-16 01:43.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === Load Files ===\n",
    "pager_df = pd.read_excel(\"C:/Users/HP/Desktop/finalCopy of PagerDutyLog - Feb.xlsx\")\n",
    "holiday_df = pd.read_excel(\"C:/Users/HP/Desktop/Mindera India - Holiday List 2025.xlsx\")\n",
    "\n",
    "# === Clean Holiday Data ===\n",
    "# Use first row as header if not already\n",
    "if 'Date' not in holiday_df.columns:\n",
    "    holiday_df.columns = holiday_df.iloc[0]\n",
    "    holiday_df = holiday_df.drop(index=0)\n",
    "\n",
    "# Fix unnamed column header if any\n",
    "holiday_df = holiday_df.rename(columns={pd.NaT: \"Misc\"})\n",
    "\n",
    "# Convert date column to datetime\n",
    "holiday_df['Date'] = pd.to_datetime(holiday_df['Date'], errors='coerce')\n",
    "\n",
    "# Extract only mandatory (non-optional) holidays\n",
    "mandatory_holidays = holiday_df[\n",
    "    ~holiday_df['Holiday Type'].str.contains(\"Optional\", na=False)\n",
    "]['Date'].dropna().dt.date.tolist()\n",
    "\n",
    "# === Clean PagerDuty Data ===\n",
    "pager_df['Start'] = pd.to_datetime(\n",
    "    pager_df['From Date'].astype(str) + ' ' + pager_df['From Time'].astype(str),\n",
    "    errors='coerce'\n",
    ")\n",
    "pager_df['End'] = pd.to_datetime(\n",
    "    pager_df['To Date'].astype(str) + ' ' + pager_df['To Time'].astype(str),\n",
    "    errors='coerce'\n",
    ")\n",
    "\n",
    "# === Calculate Total Duration in Hours ===\n",
    "pager_df['Total Duration (hrs)'] = (pager_df['End'] - pager_df['Start']).dt.total_seconds() / 3600\n",
    "\n",
    "# === Holiday Handling with Warnings ===\n",
    "warnings = []\n",
    "\n",
    "def count_holidays(start, end, holiday_list, name):\n",
    "    if pd.isna(start) or pd.isna(end):\n",
    "        return 0\n",
    "\n",
    "    days = pd.date_range(start=start.date(), end=end.date(), freq='D')\n",
    "    holiday_count = 0\n",
    "    total_days = len(days)\n",
    "\n",
    "    for day in days:\n",
    "        date_only = day.date()\n",
    "        if date_only in holiday_list:\n",
    "            holiday_count += 1\n",
    "            if day.weekday() >= 5:  # 5 = Saturday, 6 = Sunday\n",
    "                warnings.append(\n",
    "                    f\" {name} has a holiday on a weekend ({day.strftime('%A')} - {day.strftime('%Y-%m-%d')}) \"\n",
    "                    f\"during on-call from {start.strftime('%Y-%m-%d %H:%M')} to {end.strftime('%Y-%m-%d %H:%M')}.\"\n",
    "                )\n",
    "\n",
    "    if holiday_count > total_days:\n",
    "        warnings.append(\n",
    "            f\" {name} has more holidays ({holiday_count}) than total days ({total_days}) \"\n",
    "            f\"from {start.strftime('%Y-%m-%d')} to {end.strftime('%Y-%m-%d')}. Please recheck.\"\n",
    "        )\n",
    "        holiday_count = total_days  # Cap to total days\n",
    "\n",
    "    return holiday_count\n",
    "\n",
    "# Apply holiday counting\n",
    "pager_df['Holidays Count'] = pager_df.apply(\n",
    "    lambda row: count_holidays(row['Start'], row['End'], mandatory_holidays, row['Name']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Subtract holiday hours (24 hrs per holiday)\n",
    "pager_df['Actual Duration (hrs)'] = pager_df['Total Duration (hrs)'] - pager_df['Holidays Count'] * 24\n",
    "\n",
    "# === Format Duration to \"days, hours\" ===\n",
    "def convert_to_days_hours(hours):\n",
    "    if pd.isna(hours):\n",
    "        return \"0 days, 0.00 hrs\"\n",
    "    days = int(hours // 24)\n",
    "    rem_hours = round(hours % 24, 2)\n",
    "    return f\"{days} days, {rem_hours:.2f} hrs\"\n",
    "\n",
    "pager_df['Total Duration (days and hours)'] = pager_df['Total Duration (hrs)'].apply(convert_to_days_hours)\n",
    "pager_df['Actual Duration (days and hours)'] = pager_df['Actual Duration (hrs)'].apply(convert_to_days_hours)\n",
    "\n",
    "# === Group by Name and Aggregate ===\n",
    "grouped_df = pager_df.groupby('Name').agg({\n",
    "    'Start': 'min',\n",
    "    'End': 'max',\n",
    "    'Total Duration (hrs)': 'sum',\n",
    "    'Actual Duration (hrs)': 'sum',\n",
    "    'Holidays Count': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "grouped_df['Start'] = grouped_df['Start'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "grouped_df['End'] = grouped_df['End'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "grouped_df['Total Duration (days and hours)'] = grouped_df['Total Duration (hrs)'].apply(convert_to_days_hours)\n",
    "grouped_df['Actual Duration (days and hours)'] = grouped_df['Actual Duration (hrs)'].apply(convert_to_days_hours)\n",
    "\n",
    "# Final Output Columns\n",
    "grouped_df = grouped_df[['Name', 'Start', 'End', 'Holidays Count',\n",
    "                         'Total Duration (days and hours)',\n",
    "                         'Actual Duration (days and hours)']]\n",
    "\n",
    "# === Output ===\n",
    "print(\"\\n===== Adjusted PagerDuty Duration Summary (Grouped by Name) =====\\n\")\n",
    "print(grouped_df.to_string(index=False))\n",
    "\n",
    "# === Warnings ===\n",
    "if warnings:\n",
    "    print(\"\\n=====  Holiday Warnings =====\")\n",
    "    for w in warnings:\n",
    "        print(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a3594b18-ffcb-45f8-acec-3f73c7c3e8d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'From Date'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'From Date'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 60\u001b[0m\n\u001b[0;32m     56\u001b[0m pager_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRange\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pager_df\u001b[38;5;241m.\u001b[39mapply(format_range, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# === Clean Extra Hours Data ===\u001b[39;00m\n\u001b[0;32m     59\u001b[0m extra_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStart\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\n\u001b[1;32m---> 60\u001b[0m     extra_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrom Date\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m extra_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrom Time\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m),\n\u001b[0;32m     61\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     62\u001b[0m )\n\u001b[0;32m     63\u001b[0m extra_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEnd\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\n\u001b[0;32m     64\u001b[0m     extra_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTo Date\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m extra_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTo Time\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m),\n\u001b[0;32m     65\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     66\u001b[0m )\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# === Calculate Duration Splits ===\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'From Date'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# === Load Excel Files ===\n",
    "pager_df = pd.read_excel(\"C:/Users/HP/Desktop/finalCopy of PagerDutyLog - Feb.xlsx\")\n",
    "extra_df = pd.read_excel(\"C:/Users/HP/Desktop/finalCopy of ExtraHoursLog - Feb.xlsx\")\n",
    "holiday_df = pd.read_excel(\"C:/Users/HP/Desktop/Mindera India - Holiday List 2025.xlsx\")\n",
    "\n",
    "# === Clean Holiday Data ===\n",
    "if 'Date' not in holiday_df.columns:\n",
    "    holiday_df.columns = holiday_df.iloc[0]\n",
    "    holiday_df = holiday_df.drop(index=0)\n",
    "\n",
    "holiday_df['Date'] = pd.to_datetime(holiday_df['Date'], errors='coerce')\n",
    "mandatory_holidays = holiday_df[\n",
    "    ~holiday_df['Holiday Type'].str.contains(\"Optional\", na=False)\n",
    "]['Date'].dropna().dt.date.tolist()\n",
    "\n",
    "# === Helper Functions ===\n",
    "def calculate_week_parts(start, end, holidays):\n",
    "    total_weekday_hours = 0\n",
    "    total_weekend_holiday_hours = 0\n",
    "    current = start\n",
    "    while current < end:\n",
    "        next_hour = current + timedelta(hours=1)\n",
    "        is_weekend = current.weekday() >= 5\n",
    "        is_holiday = current.date() in holidays\n",
    "        if is_weekend or is_holiday:\n",
    "            total_weekend_holiday_hours += 1\n",
    "        else:\n",
    "            total_weekday_hours += 1\n",
    "        current = next_hour\n",
    "    return total_weekday_hours, total_weekend_holiday_hours\n",
    "\n",
    "def format_range(row):\n",
    "    start = row['Start']\n",
    "    end = row['End']\n",
    "    return f\"{start.strftime('%a, %b %d @ %H:%M')} To {end.strftime('%a, %b %d @ %H:%M')}\"\n",
    "\n",
    "def convert_to_days_hours(hours):\n",
    "    if pd.isna(hours) or hours == 0:\n",
    "        return \"0 days, 0.00 hours\"\n",
    "    days = int(hours // 24)\n",
    "    rem_hours = round(hours % 24, 2)\n",
    "    return f\"{days} days, {rem_hours:.2f} hours\"\n",
    "\n",
    "# === Clean PagerDuty Data ===\n",
    "pager_df['Start'] = pd.to_datetime(\n",
    "    pager_df['From Date'].astype(str) + ' ' + pager_df['From Time'].astype(str),\n",
    "    errors='coerce'\n",
    ")\n",
    "pager_df['End'] = pd.to_datetime(\n",
    "    pager_df['To Date'].astype(str) + ' ' + pager_df['To Time'].astype(str),\n",
    "    errors='coerce'\n",
    ")\n",
    "pager_df['Range'] = pager_df.apply(format_range, axis=1)\n",
    "\n",
    "# === Clean Extra Hours Data ===\n",
    "extra_df['Start'] = pd.to_datetime(\n",
    "    extra_df['From Date'].astype(str) + ' ' + extra_df['From Time'].astype(str),\n",
    "    errors='coerce'\n",
    ")\n",
    "extra_df['End'] = pd.to_datetime(\n",
    "    extra_df['To Date'].astype(str) + ' ' + extra_df['To Time'].astype(str),\n",
    "    errors='coerce'\n",
    ")\n",
    "\n",
    "# === Calculate Duration Splits ===\n",
    "pager_df[['Weekday Hours', 'Weekend/Holiday Hours']] = pager_df.apply(\n",
    "    lambda row: pd.Series(calculate_week_parts(row['Start'], row['End'], mandatory_holidays)),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "extra_df[['Extra Weekday Hours', 'Extra Weekend/Holiday Hours']] = extra_df.apply(\n",
    "    lambda row: pd.Series(calculate_week_parts(row['Start'], row['End'], mandatory_holidays)),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# === Aggregate by Name ===\n",
    "pager_summary = pager_df.groupby('Name')[['Weekday Hours', 'Weekend/Holiday Hours']].sum().reset_index()\n",
    "extra_summary = extra_df.groupby('Name')[['Extra Weekday Hours', 'Extra Weekend/Holiday Hours']].sum().reset_index()\n",
    "\n",
    "# === Merge Summaries ===\n",
    "final_df = pd.merge(pager_summary, extra_summary, on='Name', how='outer').fillna(0)\n",
    "\n",
    "# === Compute Totals and Display ===\n",
    "final_df['Actual Weekday Hours'] = final_df['Weekday Hours'] + final_df['Extra Weekday Hours']\n",
    "final_df['Actual Weekend/Holiday Hours'] = final_df['Weekend/Holiday Hours'] + final_df['Extra Weekend/Holiday Hours']\n",
    "\n",
    "# Add readable format\n",
    "final_df['Weekdays'] = final_df['Actual Weekday Hours'].apply(convert_to_days_hours)\n",
    "final_df['Weekends/Holidays'] = final_df['Actual Weekend/Holiday Hours'].apply(convert_to_days_hours)\n",
    "\n",
    "# Final Output\n",
    "final_df = final_df[['Name', 'Weekdays', 'Weekends/Holidays']]\n",
    "print(final_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87331106-0f9d-4cd0-988a-23a41de4b075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Name                                   Formatted Ranges  \\\n",
      "0          Ahalya Hegde         Tue, Feb 11 @ 09:00 To Mon, Feb 17 @ 09:00   \n",
      "1          Ayush Rajeev         Mon, Feb 03 @ 05:30 To Mon, Feb 10 @ 05:30   \n",
      "2   Basudev Singh Munda         Mon, Feb 03 @ 09:00 To Tue, Feb 11 @ 09:00   \n",
      "3          Dolly Chahar         Mon, Feb 17 @ 09:00 To Mon, Feb 24 @ 09:00   \n",
      "4      Durai Ramalingam  Mon, Feb 24 @ 04:30 To Sat, Mar 01 @ 00:00 . M...   \n",
      "5        Jithin Johnson  Mon, Feb 17 @ 04:30 To Mon, Feb 24 @ 04:30 . M...   \n",
      "6           Kapil Jugnu         Mon, Feb 17 @ 04:30 To Mon, Feb 24 @ 04:30   \n",
      "7   Keerthivasan Kannan  Tue, Feb 11 @ 10:00 To Sun, Feb 16 @ 01:43 . S...   \n",
      "8    Muthumani Gurusamy                                                      \n",
      "9     Prakash Rajendran         Sat, Feb 01 @ 00:00 To Mon, Feb 03 @ 09:00   \n",
      "10         Saumya Sinha         Wed, Feb 26 @ 09:00 To Thu, Feb 27 @ 18:00   \n",
      "11            akash dey         Sat, Feb 01 @ 00:00 To Mon, Feb 03 @ 04:30   \n",
      "12        ankit thakkar         Mon, Feb 10 @ 05:30 To Mon, Feb 17 @ 05:30   \n",
      "13   muthumani gurusamy         Mon, Feb 24 @ 05:30 To Sat, Mar 01 @ 00:00   \n",
      "14    nirmalraja selvam         Mon, Feb 10 @ 04:30 To Mon, Feb 17 @ 04:30   \n",
      "15        sahil kanojia         Mon, Feb 03 @ 04:30 To Mon, Feb 10 @ 04:30   \n",
      "16        vamshi bandla         Mon, Feb 24 @ 09:00 To Sat, Mar 01 @ 00:00   \n",
      "\n",
      "    Weekday Count  Weekend/Holiday Count  ExtraWeekday  ExtraWeekendHoliday  \n",
      "0               4                      3             0                    0  \n",
      "1               5                      3             2                    1  \n",
      "2               6                      3             0                    0  \n",
      "3               5                      3             0                    0  \n",
      "4               8                      9             1                    0  \n",
      "5              10                      6             0                    0  \n",
      "6               5                      3             1                    1  \n",
      "7               5                      4             1                    0  \n",
      "8               0                      0             0                    1  \n",
      "9               1                      2             0                    0  \n",
      "10              0                      2             0                    0  \n",
      "11              1                      2             0                    0  \n",
      "12              5                      3             1                    0  \n",
      "13              2                      4             0                    0  \n",
      "14              5                      3             0                    0  \n",
      "15              5                      3             0                    0  \n",
      "16              2                      4             0                    0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# === Step 1: Load Files ===\n",
    "pagerduty_path = \"C:/Users/HP/Desktop/finalCopy of PagerDutyLog - Feb.xlsx\"\n",
    "extrahours_path = \"C:/Users/HP/Desktop/finalCopy of ExtraHoursLog - Feb.xlsx\"\n",
    "holidays_path = \"C:/Users/HP/Desktop/Mindera India - Holiday List 2025.xlsx\"\n",
    "\n",
    "pagerduty_df = pd.read_excel(pagerduty_path)\n",
    "extrahours_df = pd.read_excel(extrahours_path)\n",
    "holidays_df = pd.read_excel(holidays_path)\n",
    "\n",
    "# === Step 2: Clean Holidays ===\n",
    "holiday_col = holidays_df.columns[3]  # typically 'Unnamed: 3'\n",
    "valid_holidays = holidays_df[holiday_col].dropna()\n",
    "valid_holidays = valid_holidays[valid_holidays != \"Date\"]\n",
    "holiday_dates = pd.to_datetime(valid_holidays, errors='coerce').dropna().dt.date.unique()\n",
    "\n",
    "# === Step 3: Process PagerDuty Log ===\n",
    "pagerduty_df['Start'] = pd.to_datetime(pagerduty_df['From Date'].astype(str) + ' ' + pagerduty_df['From Time'].astype(str), errors='coerce')\n",
    "pagerduty_df['End'] = pd.to_datetime(pagerduty_df['To Date'].astype(str) + ' ' + pagerduty_df['To Time'].astype(str), errors='coerce')\n",
    "pagerduty_df = pagerduty_df.dropna(subset=['Start', 'End'])\n",
    "\n",
    "def format_range(start_dt, end_dt):\n",
    "    return f\"{start_dt.strftime('%a, %b %d @ %H:%M')} To {end_dt.strftime('%a, %b %d @ %H:%M')}\"\n",
    "\n",
    "def compute_durations(df):\n",
    "    result = []\n",
    "    for name, group in df.groupby('Name'):\n",
    "        durations = []\n",
    "        weekday_count = 0\n",
    "        weekend_holiday_count = 0\n",
    "\n",
    "        for _, row in group.iterrows():\n",
    "            start, end = row['Start'], row['End']\n",
    "            durations.append(format_range(start, end))\n",
    "\n",
    "            current_day = start.date()\n",
    "            while current_day <= end.date():\n",
    "                is_weekend = current_day.weekday() >= 5\n",
    "                is_holiday = current_day in holiday_dates\n",
    "                if is_weekend or is_holiday:\n",
    "                    weekend_holiday_count += 1\n",
    "                else:\n",
    "                    weekday_count += 1\n",
    "                current_day += timedelta(days=1)\n",
    "\n",
    "        result.append({\n",
    "            'Name': name,\n",
    "            'Formatted Ranges': ' . '.join(durations),\n",
    "            'Weekday Count': weekday_count,\n",
    "            'Weekend/Holiday Count': weekend_holiday_count\n",
    "        })\n",
    "    return pd.DataFrame(result)\n",
    "\n",
    "pagerduty_summary = compute_durations(pagerduty_df)\n",
    "\n",
    "# === Step 4: Process Extra Hours Sheet ===\n",
    "# Identify columns that are day numbers (e.g., 128)\n",
    "day_cols = [col for col in extrahours_df.columns if isinstance(col, (int, float)) or (isinstance(col, str) and col.isdigit())]\n",
    "extra_long = extrahours_df.melt(id_vars=['Name'], value_vars=day_cols, var_name='Day', value_name='Minutes')\n",
    "extra_long = extra_long.dropna(subset=['Minutes'])\n",
    "extra_long['Day'] = extra_long['Day'].astype(int)\n",
    "\n",
    "# Construct date from day and check type\n",
    "extra_long['Date'] = pd.to_datetime({'year': 2025, 'month': 2, 'day': extra_long['Day']})\n",
    "extra_long['IsWeekend'] = extra_long['Date'].dt.weekday >= 5\n",
    "extra_long['IsHoliday'] = extra_long['Date'].dt.date.isin(holiday_dates)\n",
    "extra_long['IsWeekendOrHoliday'] = extra_long['IsWeekend'] | extra_long['IsHoliday']\n",
    "\n",
    "# Count extra work on weekdays vs weekend/holidays\n",
    "extra_summary = extra_long.groupby(['Name']).agg(\n",
    "    ExtraWeekday=('IsWeekendOrHoliday', lambda x: (~x).sum()),\n",
    "    ExtraWeekendHoliday=('IsWeekendOrHoliday', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# === Step 5: Merge Both Summaries ===\n",
    "final_summary = pd.merge(pagerduty_summary, extra_summary, on='Name', how='outer')\n",
    "\n",
    "# Clean up and convert missing values\n",
    "numeric_cols = ['Weekday Count', 'Weekend/Holiday Count', 'ExtraWeekday', 'ExtraWeekendHoliday']\n",
    "final_summary[numeric_cols] = final_summary[numeric_cols].fillna(0).astype(int)\n",
    "final_summary['Formatted Ranges'] = final_summary['Formatted Ranges'].fillna('')\n",
    "\n",
    "# Optional: Sort by Name\n",
    "final_summary.sort_values('Name', inplace=True)\n",
    "final_summary.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# === Optional: Save Output to Excel ===\n",
    "final_summary.to_excel(\"Final_Summary_Output.xlsx\", index=False)\n",
    "\n",
    "# === View First Few Rows ===\n",
    "print(final_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0b341e82-903e-432f-a45a-c218578b7b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Name                                   Formatted Ranges  \\\n",
      "0          Ahalya Hegde  Wed, Mar 05 @ 09:19 To Mon, Mar 10 @ 09:00 . M...   \n",
      "1          Ayush Rajeev         Mon, Mar 17 @ 05:30 To Mon, Mar 24 @ 05:30   \n",
      "2   Basudev Singh Munda  Mon, Mar 10 @ 09:00 To Mon, Mar 10 @ 13:06 . W...   \n",
      "3      Durai Ramalingam  Sat, Mar 01 @ 00:00 To Mon, Mar 03 @ 04:30 . M...   \n",
      "4        Jithin Johnson  Mon, Mar 03 @ 04:30 To Mon, Mar 10 @ 04:30 . M...   \n",
      "5     Prakash Rajendran         Mon, Mar 17 @ 09:00 To Mon, Mar 24 @ 09:00   \n",
      "6          Rony Abraham  Fri, Mar 14 @ 07:06 To Mon, Mar 17 @ 09:00 . M...   \n",
      "7        Upal mukherjee         Mon, Mar 31 @ 09:00 To Tue, Apr 01 @ 00:00   \n",
      "8         ankit thakkar         Mon, Mar 10 @ 05:30 To Mon, Mar 17 @ 05:30   \n",
      "9    muthumani gurusamy  Sat, Mar 01 @ 00:00 To Mon, Mar 03 @ 05:30 . M...   \n",
      "10    nirmalraja selvam  Mon, Mar 03 @ 11:30 To Mon, Mar 10 @ 04:30 . M...   \n",
      "11         pavan mantry         Mon, Mar 03 @ 05:30 To Mon, Mar 10 @ 05:30   \n",
      "12        vamshi bandla         Sat, Mar 01 @ 00:00 To Wed, Mar 05 @ 09:19   \n",
      "\n",
      "          Weekday Count Weekend/Holiday Count ExtraWeekday Hours  \\\n",
      "0   4 days, 23.58 hours    2 days, 0.00 hours         0.00 hours   \n",
      "1    5 days, 0.00 hours    2 days, 0.00 hours         9.17 hours   \n",
      "2   1 days, 22.20 hours    0 days, 0.00 hours         0.00 hours   \n",
      "3   10 days, 0.00 hours    6 days, 4.50 hours         0.00 hours   \n",
      "4   10 days, 0.00 hours   4 days, 19.50 hours         0.00 hours   \n",
      "5    5 days, 0.00 hours    2 days, 0.00 hours         0.00 hours   \n",
      "6   5 days, 16.90 hours    4 days, 9.00 hours         0.00 hours   \n",
      "7    0 days, 0.00 hours   0 days, 15.00 hours         0.00 hours   \n",
      "8    5 days, 0.00 hours    2 days, 0.00 hours         0.00 hours   \n",
      "9    0 days, 5.50 hours   2 days, 18.50 hours         0.00 hours   \n",
      "10  9 days, 17.00 hours    4 days, 0.00 hours          4.0 hours   \n",
      "11   5 days, 0.00 hours    2 days, 0.00 hours          2.0 hours   \n",
      "12   2 days, 9.32 hours    2 days, 0.00 hours         0.00 hours   \n",
      "\n",
      "   ExtraWeekendHoliday Hours  \n",
      "0                 0.00 hours  \n",
      "1                  0.0 hours  \n",
      "2                 0.00 hours  \n",
      "3                 0.00 hours  \n",
      "4                 0.00 hours  \n",
      "5                 0.00 hours  \n",
      "6                 0.00 hours  \n",
      "7                 0.00 hours  \n",
      "8                 0.00 hours  \n",
      "9                 0.00 hours  \n",
      "10                 0.0 hours  \n",
      "11                1.17 hours  \n",
      "12                0.00 hours  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# === Step 1: Load Files ===\n",
    "pagerduty_df = pd.read_excel(\"C:/Users/HP/Desktop/PAGER DUTY/Copy of PagerDutyLog - Mar.xlsx\")\n",
    "extrahours_df = pd.read_excel(\"C:/Users/HP/Desktop/EXTRA HOURS/Copy of Mar-2025-ExtraHours.xlsx\")\n",
    "holidays_df = pd.read_excel(\"C:/Users/HP/Downloads/Mindera India - Holiday List 2025.xlsx\")\n",
    "\n",
    "# === Step 2: Clean Holiday Dates ===\n",
    "holiday_col = holidays_df.columns[3]\n",
    "valid_holidays = holidays_df[holiday_col].dropna()\n",
    "valid_holidays = valid_holidays[valid_holidays != \"Date\"]\n",
    "holiday_dates = pd.to_datetime(valid_holidays, errors='coerce').dropna().dt.date.unique()\n",
    "\n",
    "# === Step 3: Process PagerDuty Log ===\n",
    "pagerduty_df['Start'] = pd.to_datetime(pagerduty_df['From Date'].astype(str) + ' ' + pagerduty_df['From Time'].astype(str), errors='coerce')\n",
    "pagerduty_df['End'] = pd.to_datetime(pagerduty_df['To Date'].astype(str) + ' ' + pagerduty_df['To Time'].astype(str), errors='coerce')\n",
    "pagerduty_df = pagerduty_df.dropna(subset=['Start', 'End'])\n",
    "\n",
    "def format_range(start_dt, end_dt):\n",
    "    return f\"{start_dt.strftime('%a, %b %d @ %H:%M')} To {end_dt.strftime('%a, %b %d @ %H:%M')}\"\n",
    "def compute_durations(df):\n",
    "    result = []\n",
    "\n",
    "    for name, group in df.groupby('Name'):\n",
    "        durations = []\n",
    "        weekday_minutes = 0\n",
    "        weekend_holiday_minutes = 0\n",
    "\n",
    "        for _, row in group.iterrows():\n",
    "            start, end = row['Start'], row['End']\n",
    "            durations.append(format_range(start, end))\n",
    "\n",
    "            current_time = start\n",
    "            while current_time < end:\n",
    "                next_time = min(current_time + timedelta(minutes=30), end)\n",
    "                current_day = current_time.date()\n",
    "                minutes = (next_time - current_time).total_seconds() / 60\n",
    "\n",
    "                is_weekend = current_day.weekday() >= 5\n",
    "                is_holiday = current_day in holiday_dates\n",
    "\n",
    "                if is_weekend or is_holiday:\n",
    "                    weekend_holiday_minutes += minutes\n",
    "                else:\n",
    "                    weekday_minutes += minutes\n",
    "\n",
    "                current_time = next_time\n",
    "\n",
    "        # Convert total minutes to days and remaining hours (24h = 1 day)\n",
    "        weekday_total_hours = weekday_minutes / 60\n",
    "        weekday_days = int(weekday_total_hours // 24)\n",
    "        weekday_rem_hours = round(weekday_total_hours % 24, 2)\n",
    "\n",
    "        weekend_total_hours = weekend_holiday_minutes / 60\n",
    "        weekend_days = int(weekend_total_hours // 24)\n",
    "        weekend_rem_hours = round(weekend_total_hours % 24, 2)\n",
    "\n",
    "        result.append({\n",
    "            'Name': name,\n",
    "            'Formatted Ranges': ' . '.join(durations),\n",
    "            'Weekday Count': f\"{weekday_days} days, {weekday_rem_hours:.2f} hours\",\n",
    "            'Weekend/Holiday Count': f\"{weekend_days} days, {weekend_rem_hours:.2f} hours\"\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(result)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "pagerduty_summary = compute_durations(pagerduty_df)\n",
    "\n",
    "# === Step 4: Process Extra Hours ===\n",
    "day_cols = [col for col in extrahours_df.columns if isinstance(col, (int, float)) or (isinstance(col, str) and col.isdigit())]\n",
    "extra_long = extrahours_df.melt(id_vars=['Name'], value_vars=day_cols, var_name='Day', value_name='Minutes')\n",
    "extra_long = extra_long.dropna(subset=['Minutes'])\n",
    "extra_long['Day'] = extra_long['Day'].astype(int)\n",
    "\n",
    "extra_long['Date'] = pd.to_datetime({'year': 2025, 'month': 2, 'day': extra_long['Day']})\n",
    "extra_long['IsWeekend'] = extra_long['Date'].dt.weekday >= 5\n",
    "extra_long['IsHoliday'] = extra_long['Date'].dt.date.isin(holiday_dates)\n",
    "extra_long['IsWeekendOrHoliday'] = extra_long['IsWeekend'] | extra_long['IsHoliday']\n",
    "\n",
    "extra_summary = extra_long.groupby(['Name']).agg(\n",
    "    ExtraWeekdayMinutes=('Minutes', lambda x: x[~extra_long.loc[x.index, 'IsWeekendOrHoliday']].sum()),\n",
    "    ExtraWeekendHolidayMinutes=('Minutes', lambda x: x[extra_long.loc[x.index, 'IsWeekendOrHoliday']].sum())\n",
    ").reset_index()\n",
    "\n",
    "extra_summary['ExtraWeekday Hours'] = (extra_summary['ExtraWeekdayMinutes'] / 60).round(2).astype(str) + ' hours'\n",
    "extra_summary['ExtraWeekendHoliday Hours'] = (extra_summary['ExtraWeekendHolidayMinutes'] / 60).round(2).astype(str) + ' hours'\n",
    "extra_summary = extra_summary.drop(columns=['ExtraWeekdayMinutes', 'ExtraWeekendHolidayMinutes'])\n",
    "\n",
    "# === Step 5: Merge and Clean ===\n",
    "final_summary = pd.merge(pagerduty_summary, extra_summary, on='Name', how='outer')\n",
    "final_summary = final_summary.fillna({\n",
    "    'Formatted Ranges': '',\n",
    "    'Weekday Count': '0 days, 0.00 hours',\n",
    "    'Weekend/Holiday Count': '0 days, 0.00 hours',\n",
    "    'ExtraWeekday Hours': '0.00 hours',\n",
    "    'ExtraWeekendHoliday Hours': '0.00 hours'\n",
    "})\n",
    "\n",
    "final_summary = final_summary.sort_values('Name').reset_index(drop=True)\n",
    "\n",
    "# === Save or View Output ===\n",
    "final_summary.to_excel(\"Final_Summary_Output.xlsx\", index=False)\n",
    "print(final_summary)\n",
    "\n",
    "final_summary.to_excel(\n",
    "    r\"C:\\Users\\HP\\Desktop\\Final_Summary_Output_MARCH.xlsx\",  # < absolute path\n",
    "    index=False,                                       # do NOT write the row index\n",
    "    engine=\"openpyxl\"                                  # openpyxl is the modern default\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4f688d8a-6de0-4994-b945-e1e0740cf384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Name                                   Formatted Ranges  \\\n",
      "0          Ahalya Hegde         Tue, May 27 @ 09:15 To Sun, Jun 01 @ 00:00   \n",
      "1          Ayush Rajeev         Mon, May 12 @ 05:30 To Mon, May 19 @ 05:30   \n",
      "2   Basudev Singh Munda         Mon, May 05 @ 09:00 To Mon, May 12 @ 09:00   \n",
      "3      Durai Ramalingam  Mon, May 05 @ 05:30 To Mon, May 12 @ 05:30 . M...   \n",
      "4        Jithin Johnson  Thu, May 01 @ 00:00 To Mon, May 05 @ 05:30 . M...   \n",
      "5     Prakash Rajendran         Mon, May 12 @ 09:00 To Mon, May 19 @ 09:00   \n",
      "6          Rony Abraham         Mon, May 19 @ 09:00 To Mon, May 26 @ 09:00   \n",
      "7        Upal mukherjee         Mon, May 26 @ 09:00 To Tue, May 27 @ 09:12   \n",
      "8         ankit thakkar         Mon, May 05 @ 05:30 To Mon, May 12 @ 05:30   \n",
      "9    muthumani gurusamy  Thu, May 01 @ 00:00 To Mon, May 05 @ 05:30 . M...   \n",
      "10    nirmalraja selvam         Mon, May 12 @ 05:30 To Mon, May 19 @ 05:30   \n",
      "11        vamshi bandla         Thu, May 01 @ 00:00 To Mon, May 05 @ 09:00   \n",
      "\n",
      "          Weekday Count Weekend/Holiday Count ExtraWeekday Hours  \\\n",
      "0   3 days, 15.00 hours   0 days, 23.75 hours         0.00 hours   \n",
      "1    5 days, 0.00 hours    2 days, 0.00 hours         0.00 hours   \n",
      "2    5 days, 0.00 hours    2 days, 0.00 hours         0.00 hours   \n",
      "3   10 days, 0.00 hours    4 days, 0.00 hours          3.0 hours   \n",
      "4   11 days, 0.00 hours    6 days, 0.00 hours         0.00 hours   \n",
      "5    5 days, 0.00 hours    2 days, 0.00 hours         0.00 hours   \n",
      "6    5 days, 0.00 hours    2 days, 0.00 hours         0.00 hours   \n",
      "7    1 days, 0.20 hours    0 days, 0.00 hours         0.00 hours   \n",
      "8    5 days, 0.00 hours    2 days, 0.00 hours         0.33 hours   \n",
      "9    6 days, 0.00 hours    4 days, 0.00 hours         1.58 hours   \n",
      "10   5 days, 0.00 hours    2 days, 0.00 hours         0.00 hours   \n",
      "11   1 days, 9.00 hours    3 days, 0.00 hours         0.00 hours   \n",
      "\n",
      "   ExtraWeekendHoliday Hours  \n",
      "0                 0.00 hours  \n",
      "1                 0.00 hours  \n",
      "2                 0.00 hours  \n",
      "3                  0.0 hours  \n",
      "4                 0.00 hours  \n",
      "5                 0.00 hours  \n",
      "6                 0.00 hours  \n",
      "7                 0.00 hours  \n",
      "8                  0.0 hours  \n",
      "9                  0.5 hours  \n",
      "10                0.00 hours  \n",
      "11                0.00 hours  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# === Step 1: Load Files ===\n",
    "pagerduty_df = pd.read_excel(\"C:/Users/HP/Desktop/PAGER DUTY/Copy of PagerDuty_May_2025.xlsx\")\n",
    "extrahours_df = pd.read_excel(\"C:/Users/HP/Desktop/EXTRA HOURS/Copy of Extra_hours.xlsx\")\n",
    "holidays_df = pd.read_excel(\"C:/Users/HP/Downloads/Mindera India - Holiday List 2025.xlsx\")\n",
    "\n",
    "# === Step 2: Clean Holiday Dates ===\n",
    "holiday_col = holidays_df.columns[3]\n",
    "valid_holidays = holidays_df[holiday_col].dropna()\n",
    "valid_holidays = valid_holidays[valid_holidays != \"Date\"]\n",
    "holiday_dates = pd.to_datetime(valid_holidays, errors='coerce').dropna().dt.date.unique()\n",
    "\n",
    "# === Step 3: Process PagerDuty Log ===\n",
    "pagerduty_df['Start'] = pd.to_datetime(pagerduty_df['From Date'].astype(str) + ' ' + pagerduty_df['From Time'].astype(str), errors='coerce')\n",
    "pagerduty_df['End'] = pd.to_datetime(pagerduty_df['To Date'].astype(str) + ' ' + pagerduty_df['To Time'].astype(str), errors='coerce')\n",
    "pagerduty_df = pagerduty_df.dropna(subset=['Start', 'End'])\n",
    "\n",
    "def format_range(start_dt, end_dt):\n",
    "    return f\"{start_dt.strftime('%a, %b %d @ %H:%M')} To {end_dt.strftime('%a, %b %d @ %H:%M')}\"\n",
    "def compute_durations(df):\n",
    "    result = []\n",
    "\n",
    "    for name, group in df.groupby('Name'):\n",
    "        durations = []\n",
    "        weekday_minutes = 0\n",
    "        weekend_holiday_minutes = 0\n",
    "\n",
    "        for _, row in group.iterrows():\n",
    "            start, end = row['Start'], row['End']\n",
    "            durations.append(format_range(start, end))\n",
    "\n",
    "            current_time = start\n",
    "            while current_time < end:\n",
    "                next_time = min(current_time + timedelta(minutes=30), end)\n",
    "                current_day = current_time.date()\n",
    "                minutes = (next_time - current_time).total_seconds() / 60\n",
    "\n",
    "                is_weekend = current_day.weekday() >= 5\n",
    "                is_holiday = current_day in holiday_dates\n",
    "\n",
    "                if is_weekend or is_holiday:\n",
    "                    weekend_holiday_minutes += minutes\n",
    "                else:\n",
    "                    weekday_minutes += minutes\n",
    "\n",
    "                current_time = next_time\n",
    "\n",
    "        # Convert total minutes to days and remaining hours (24h = 1 day)\n",
    "        weekday_total_hours = weekday_minutes / 60\n",
    "        weekday_days = int(weekday_total_hours // 24)\n",
    "        weekday_rem_hours = round(weekday_total_hours % 24, 2)\n",
    "\n",
    "        weekend_total_hours = weekend_holiday_minutes / 60\n",
    "        weekend_days = int(weekend_total_hours // 24)\n",
    "        weekend_rem_hours = round(weekend_total_hours % 24, 2)\n",
    "\n",
    "        result.append({\n",
    "            'Name': name,\n",
    "            'Formatted Ranges': ' . '.join(durations),\n",
    "            'Weekday Count': f\"{weekday_days} days, {weekday_rem_hours:.2f} hours\",\n",
    "            'Weekend/Holiday Count': f\"{weekend_days} days, {weekend_rem_hours:.2f} hours\"\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(result)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "pagerduty_summary = compute_durations(pagerduty_df)\n",
    "\n",
    "# === Step 4: Process Extra Hours ===\n",
    "day_cols = [col for col in extrahours_df.columns if isinstance(col, (int, float)) or (isinstance(col, str) and col.isdigit())]\n",
    "extra_long = extrahours_df.melt(id_vars=['Name'], value_vars=day_cols, var_name='Day', value_name='Minutes')\n",
    "extra_long = extra_long.dropna(subset=['Minutes'])\n",
    "extra_long['Day'] = extra_long['Day'].astype(int)\n",
    "\n",
    "extra_long['Date'] = pd.to_datetime({'year': 2025, 'month': 5, 'day': extra_long['Day']})\n",
    "extra_long['IsWeekend'] = extra_long['Date'].dt.weekday >= 5\n",
    "extra_long['IsHoliday'] = extra_long['Date'].dt.date.isin(holiday_dates)\n",
    "extra_long['IsWeekendOrHoliday'] = extra_long['IsWeekend'] | extra_long['IsHoliday']\n",
    "\n",
    "extra_summary = extra_long.groupby(['Name']).agg(\n",
    "    ExtraWeekdayMinutes=('Minutes', lambda x: x[~extra_long.loc[x.index, 'IsWeekendOrHoliday']].sum()),\n",
    "    ExtraWeekendHolidayMinutes=('Minutes', lambda x: x[extra_long.loc[x.index, 'IsWeekendOrHoliday']].sum())\n",
    ").reset_index()\n",
    "\n",
    "extra_summary['ExtraWeekday Hours'] = (extra_summary['ExtraWeekdayMinutes'] / 60).round(2).astype(str) + ' hours'\n",
    "extra_summary['ExtraWeekendHoliday Hours'] = (extra_summary['ExtraWeekendHolidayMinutes'] / 60).round(2).astype(str) + ' hours'\n",
    "extra_summary = extra_summary.drop(columns=['ExtraWeekdayMinutes', 'ExtraWeekendHolidayMinutes'])\n",
    "\n",
    "# === Step 5: Merge and Clean ===\n",
    "final_summary = pd.merge(pagerduty_summary, extra_summary, on='Name', how='outer')\n",
    "final_summary = final_summary.fillna({\n",
    "    'Formatted Ranges': '',\n",
    "    'Weekday Count': '0 days, 0.00 hours',\n",
    "    'Weekend/Holiday Count': '0 days, 0.00 hours',\n",
    "    'ExtraWeekday Hours': '0.00 hours',\n",
    "    'ExtraWeekendHoliday Hours': '0.00 hours'\n",
    "})\n",
    "\n",
    "final_summary = final_summary.sort_values('Name').reset_index(drop=True)\n",
    "\n",
    "# === Save or View Output ===\n",
    "final_summary.to_excel(\"Final_Summary_Output.xlsx\", index=False)\n",
    "print(final_summary)\n",
    "\n",
    "final_summary.to_excel(\n",
    "    r\"C:\\Users\\HP\\Desktop\\Final_Summary_Output_MAY.xlsx\",  # < absolute path\n",
    "    index=False,                                       # do NOT write the row index\n",
    "    engine=\"openpyxl\"                                  # openpyxl is the modern default\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bf651a9f-f664-41e8-8e48-653afdac97b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Name                                   Formatted Ranges  \\\n",
      "0         Ahalya Hegde         Mon, Apr 07 @ 09:00 To Mon, Apr 14 @ 09:00   \n",
      "1         Ayush Rajeev         Mon, Apr 14 @ 05:30 To Mon, Apr 21 @ 05:30   \n",
      "2         Dolly Chahar  Fri, Apr 04 @ 11:30 To Mon, Apr 07 @ 09:00 . M...   \n",
      "3     Durai Ramalingam  Mon, Apr 07 @ 05:30 To Mon, Apr 14 @ 05:30 . M...   \n",
      "4       Jithin Johnson  Tue, Apr 01 @ 00:00 To Mon, Apr 07 @ 05:30 . M...   \n",
      "5         Rony Abraham         Mon, Apr 21 @ 09:00 To Mon, Apr 28 @ 09:00   \n",
      "6       Upal mukherjee         Tue, Apr 01 @ 00:00 To Fri, Apr 04 @ 11:30   \n",
      "7        ankit thakkar         Mon, Apr 07 @ 05:30 To Mon, Apr 14 @ 05:30   \n",
      "8   muthumani gurusamy  Tue, Apr 01 @ 00:00 To Mon, Apr 07 @ 05:30 . M...   \n",
      "9    nirmalraja selvam         Mon, Apr 14 @ 05:30 To Mon, Apr 21 @ 05:30   \n",
      "10       vamshi bandla         Mon, Apr 28 @ 09:00 To Thu, May 01 @ 00:00   \n",
      "\n",
      "          Weekday Count Weekend/Holiday Count ExtraWeekday Hours  \\\n",
      "0   4 days, 15.00 hours    2 days, 9.00 hours         0.00 hours   \n",
      "1    3 days, 5.50 hours   3 days, 18.50 hours          0.0 hours   \n",
      "2    4 days, 6.50 hours   5 days, 15.00 hours         0.00 hours   \n",
      "3   9 days, 18.50 hours    4 days, 5.50 hours         0.00 hours   \n",
      "4    9 days, 5.50 hours   6 days, 18.50 hours         0.00 hours   \n",
      "5    5 days, 0.00 hours    2 days, 0.00 hours         0.00 hours   \n",
      "6   3 days, 11.50 hours    0 days, 0.00 hours         0.00 hours   \n",
      "7   4 days, 18.50 hours    2 days, 5.50 hours          1.5 hours   \n",
      "8    6 days, 0.00 hours    3 days, 0.00 hours          3.0 hours   \n",
      "9    3 days, 5.50 hours   3 days, 18.50 hours         0.00 hours   \n",
      "10  1 days, 15.00 hours    1 days, 0.00 hours         0.00 hours   \n",
      "\n",
      "   ExtraWeekendHoliday Hours  \n",
      "0                 0.00 hours  \n",
      "1                 1.25 hours  \n",
      "2                 0.00 hours  \n",
      "3                 0.00 hours  \n",
      "4                 0.00 hours  \n",
      "5                 0.00 hours  \n",
      "6                 0.00 hours  \n",
      "7                  0.0 hours  \n",
      "8                  0.0 hours  \n",
      "9                 0.00 hours  \n",
      "10                0.00 hours  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# === Step 1: Load Files ===\n",
    "pagerduty_df = pd.read_excel(\"C:/Users/HP/Desktop/PAGER DUTY/Copy of PagerDutyLog -Apr-2025.xlsx\")\n",
    "extrahours_df = pd.read_excel(\"C:/Users/HP/Desktop/EXTRA HOURS/Copy of ExtraHours-apr-2025.xlsx\")\n",
    "holidays_df = pd.read_excel(\"C:/Users/HP/Downloads/Mindera India - Holiday List 2025.xlsx\")\n",
    "\n",
    "# === Step 2: Clean Holiday Dates ===\n",
    "holiday_col = holidays_df.columns[3]\n",
    "valid_holidays = holidays_df[holiday_col].dropna()\n",
    "valid_holidays = valid_holidays[valid_holidays != \"Date\"]\n",
    "holiday_dates = pd.to_datetime(valid_holidays, errors='coerce').dropna().dt.date.unique()\n",
    "\n",
    "# === Step 3: Process PagerDuty Log ===\n",
    "pagerduty_df['Start'] = pd.to_datetime(pagerduty_df['From Date'].astype(str) + ' ' + pagerduty_df['From Time'].astype(str), errors='coerce')\n",
    "pagerduty_df['End'] = pd.to_datetime(pagerduty_df['To Date'].astype(str) + ' ' + pagerduty_df['To Time'].astype(str), errors='coerce')\n",
    "pagerduty_df = pagerduty_df.dropna(subset=['Start', 'End'])\n",
    "\n",
    "def format_range(start_dt, end_dt):\n",
    "    return f\"{start_dt.strftime('%a, %b %d @ %H:%M')} To {end_dt.strftime('%a, %b %d @ %H:%M')}\"\n",
    "def compute_durations(df):\n",
    "    result = []\n",
    "\n",
    "    for name, group in df.groupby('Name'):\n",
    "        durations = []\n",
    "        weekday_minutes = 0\n",
    "        weekend_holiday_minutes = 0\n",
    "\n",
    "        for _, row in group.iterrows():\n",
    "            start, end = row['Start'], row['End']\n",
    "            durations.append(format_range(start, end))\n",
    "\n",
    "            current_time = start\n",
    "            while current_time < end:\n",
    "                next_time = min(current_time + timedelta(minutes=30), end)\n",
    "                current_day = current_time.date()\n",
    "                minutes = (next_time - current_time).total_seconds() / 60\n",
    "\n",
    "                is_weekend = current_day.weekday() >= 5\n",
    "                is_holiday = current_day in holiday_dates\n",
    "\n",
    "                if is_weekend or is_holiday:\n",
    "                    weekend_holiday_minutes += minutes\n",
    "                else:\n",
    "                    weekday_minutes += minutes\n",
    "\n",
    "                current_time = next_time\n",
    "\n",
    "        # Convert total minutes to days and remaining hours (24h = 1 day)\n",
    "        weekday_total_hours = weekday_minutes / 60\n",
    "        weekday_days = int(weekday_total_hours // 24)\n",
    "        weekday_rem_hours = round(weekday_total_hours % 24, 2)\n",
    "\n",
    "        weekend_total_hours = weekend_holiday_minutes / 60\n",
    "        weekend_days = int(weekend_total_hours // 24)\n",
    "        weekend_rem_hours = round(weekend_total_hours % 24, 2)\n",
    "\n",
    "        result.append({\n",
    "            'Name': name,\n",
    "            'Formatted Ranges': ' . '.join(durations),\n",
    "            'Weekday Count': f\"{weekday_days} days, {weekday_rem_hours:.2f} hours\",\n",
    "            'Weekend/Holiday Count': f\"{weekend_days} days, {weekend_rem_hours:.2f} hours\"\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(result)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "pagerduty_summary = compute_durations(pagerduty_df)\n",
    "\n",
    "# === Step 4: Process Extra Hours ===\n",
    "day_cols = [col for col in extrahours_df.columns if isinstance(col, (int, float)) or (isinstance(col, str) and col.isdigit())]\n",
    "extra_long = extrahours_df.melt(id_vars=['Name'], value_vars=day_cols, var_name='Day', value_name='Minutes')\n",
    "extra_long = extra_long.dropna(subset=['Minutes'])\n",
    "extra_long['Day'] = extra_long['Day'].astype(int)\n",
    "\n",
    "extra_long['Date'] = pd.to_datetime({'year': 2025, 'month': 4, 'day': extra_long['Day']})\n",
    "extra_long['IsWeekend'] = extra_long['Date'].dt.weekday >= 5\n",
    "extra_long['IsHoliday'] = extra_long['Date'].dt.date.isin(holiday_dates)\n",
    "extra_long['IsWeekendOrHoliday'] = extra_long['IsWeekend'] | extra_long['IsHoliday']\n",
    "\n",
    "extra_summary = extra_long.groupby(['Name']).agg(\n",
    "    ExtraWeekdayMinutes=('Minutes', lambda x: x[~extra_long.loc[x.index, 'IsWeekendOrHoliday']].sum()),\n",
    "    ExtraWeekendHolidayMinutes=('Minutes', lambda x: x[extra_long.loc[x.index, 'IsWeekendOrHoliday']].sum())\n",
    ").reset_index()\n",
    "\n",
    "extra_summary['ExtraWeekday Hours'] = (extra_summary['ExtraWeekdayMinutes'] / 60).round(2).astype(str) + ' hours'\n",
    "extra_summary['ExtraWeekendHoliday Hours'] = (extra_summary['ExtraWeekendHolidayMinutes'] / 60).round(2).astype(str) + ' hours'\n",
    "extra_summary = extra_summary.drop(columns=['ExtraWeekdayMinutes', 'ExtraWeekendHolidayMinutes'])\n",
    "\n",
    "# === Step 5: Merge and Clean ===\n",
    "final_summary = pd.merge(pagerduty_summary, extra_summary, on='Name', how='outer')\n",
    "final_summary = final_summary.fillna({\n",
    "    'Formatted Ranges': '',\n",
    "    'Weekday Count': '0 days, 0.00 hours',\n",
    "    'Weekend/Holiday Count': '0 days, 0.00 hours',\n",
    "    'ExtraWeekday Hours': '0.00 hours',\n",
    "    'ExtraWeekendHoliday Hours': '0.00 hours'\n",
    "})\n",
    "\n",
    "final_summary = final_summary.sort_values('Name').reset_index(drop=True)\n",
    "\n",
    "# === Save or View Output ===\n",
    "final_summary.to_excel(\"Final_Summary_Output.xlsx\", index=False)\n",
    "print(final_summary)\n",
    "\n",
    "final_summary.to_excel(\n",
    "    r\"C:\\Users\\HP\\Desktop\\Final_Summary_Output_APRIL.xlsx\",  # < absolute path\n",
    "    index=False,                                       # do NOT write the row index\n",
    "    engine=\"openpyxl\"                                  # openpyxl is the modern default\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b44ec698-fc44-424a-997e-4248e966d8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Name                                   Formatted Ranges  \\\n",
      "0          Ahalya Hegde         Tue, Feb 11 @ 09:00 To Mon, Feb 17 @ 09:00   \n",
      "1          Ayush Rajeev         Mon, Feb 03 @ 05:30 To Mon, Feb 10 @ 05:30   \n",
      "2   Basudev Singh Munda         Mon, Feb 03 @ 09:00 To Tue, Feb 11 @ 09:00   \n",
      "3          Dolly Chahar         Mon, Feb 17 @ 09:00 To Mon, Feb 24 @ 09:00   \n",
      "4      Durai Ramalingam  Mon, Feb 24 @ 04:30 To Sat, Mar 01 @ 00:00 . M...   \n",
      "5        Jithin Johnson  Mon, Feb 17 @ 04:30 To Mon, Feb 24 @ 04:30 . M...   \n",
      "6           Kapil Jugnu         Mon, Feb 17 @ 04:30 To Mon, Feb 24 @ 04:30   \n",
      "7   Keerthivasan Kannan  Tue, Feb 11 @ 10:00 To Sun, Feb 16 @ 01:43 . S...   \n",
      "8    Muthumani Gurusamy                                                      \n",
      "9     Prakash Rajendran         Sat, Feb 01 @ 00:00 To Mon, Feb 03 @ 09:00   \n",
      "10         Saumya Sinha         Wed, Feb 26 @ 09:00 To Thu, Feb 27 @ 18:00   \n",
      "11            akash dey         Sat, Feb 01 @ 00:00 To Mon, Feb 03 @ 04:30   \n",
      "12        ankit thakkar         Mon, Feb 10 @ 05:30 To Mon, Feb 17 @ 05:30   \n",
      "13   muthumani gurusamy         Mon, Feb 24 @ 05:30 To Sat, Mar 01 @ 00:00   \n",
      "14    nirmalraja selvam         Mon, Feb 10 @ 04:30 To Mon, Feb 17 @ 04:30   \n",
      "15        sahil kanojia         Mon, Feb 03 @ 04:30 To Mon, Feb 10 @ 04:30   \n",
      "16        vamshi bandla         Mon, Feb 24 @ 09:00 To Sat, Mar 01 @ 00:00   \n",
      "\n",
      "          Weekday Count Weekend/Holiday Count ExtraWeekday Hours  \\\n",
      "0    4 days, 0.00 hours    2 days, 0.00 hours         0.00 hours   \n",
      "1    5 days, 0.00 hours    2 days, 0.00 hours         0.75 hours   \n",
      "2    6 days, 0.00 hours    2 days, 0.00 hours         0.00 hours   \n",
      "3    5 days, 0.00 hours    2 days, 0.00 hours         0.00 hours   \n",
      "4    9 days, 0.00 hours    5 days, 0.00 hours          0.5 hours   \n",
      "5   10 days, 0.00 hours    4 days, 0.00 hours         0.00 hours   \n",
      "6    5 days, 0.00 hours    2 days, 0.00 hours         1.33 hours   \n",
      "7   4 days, 23.75 hours   1 days, 14.22 hours         1.17 hours   \n",
      "8    0 days, 0.00 hours    0 days, 0.00 hours          0.5 hours   \n",
      "9    0 days, 9.00 hours    2 days, 0.00 hours         0.00 hours   \n",
      "10  0 days, 18.00 hours   0 days, 15.00 hours         0.00 hours   \n",
      "11   0 days, 4.50 hours    2 days, 0.00 hours         0.00 hours   \n",
      "12   5 days, 0.00 hours    2 days, 0.00 hours         0.33 hours   \n",
      "13  3 days, 18.50 hours    1 days, 0.00 hours         0.00 hours   \n",
      "14   5 days, 0.00 hours    2 days, 0.00 hours         0.00 hours   \n",
      "15   5 days, 0.00 hours    2 days, 0.00 hours         0.00 hours   \n",
      "16  3 days, 15.00 hours    1 days, 0.00 hours         0.00 hours   \n",
      "\n",
      "   ExtraWeekendHoliday Hours  \n",
      "0                 0.00 hours  \n",
      "1                  0.5 hours  \n",
      "2                 0.00 hours  \n",
      "3                 0.00 hours  \n",
      "4                  0.0 hours  \n",
      "5                 0.00 hours  \n",
      "6                  0.0 hours  \n",
      "7                  0.0 hours  \n",
      "8                  0.0 hours  \n",
      "9                 0.00 hours  \n",
      "10                0.00 hours  \n",
      "11                0.00 hours  \n",
      "12                 0.0 hours  \n",
      "13                0.00 hours  \n",
      "14                0.00 hours  \n",
      "15                0.00 hours  \n",
      "16                0.00 hours  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# === Step 1: Load Files ===\n",
    "pagerduty_df = pd.read_excel(\"C:/Users/HP/Desktop/PAGER DUTY/finalCopy of PagerDutyLog - Feb.xlsx\")\n",
    "extrahours_df = pd.read_excel(\"C:/Users/HP/Desktop/EXTRA HOURS/finalCopy of ExtraHoursLog - Feb.xlsx\")\n",
    "holidays_df = pd.read_excel(\"C:/Users/HP/Downloads/Mindera India - Holiday List 2025.xlsx\")\n",
    "\n",
    "# === Step 2: Clean Holiday Dates ===\n",
    "holiday_col = holidays_df.columns[3]\n",
    "valid_holidays = holidays_df[holiday_col].dropna()\n",
    "valid_holidays = valid_holidays[valid_holidays != \"Date\"]\n",
    "holiday_dates = pd.to_datetime(valid_holidays, errors='coerce').dropna().dt.date.unique()\n",
    "\n",
    "# === Step 3: Process PagerDuty Log ===\n",
    "pagerduty_df['Start'] = pd.to_datetime(pagerduty_df['From Date'].astype(str) + ' ' + pagerduty_df['From Time'].astype(str), errors='coerce')\n",
    "pagerduty_df['End'] = pd.to_datetime(pagerduty_df['To Date'].astype(str) + ' ' + pagerduty_df['To Time'].astype(str), errors='coerce')\n",
    "pagerduty_df = pagerduty_df.dropna(subset=['Start', 'End'])\n",
    "\n",
    "def format_range(start_dt, end_dt):\n",
    "    return f\"{start_dt.strftime('%a, %b %d @ %H:%M')} To {end_dt.strftime('%a, %b %d @ %H:%M')}\"\n",
    "def compute_durations(df):\n",
    "    result = []\n",
    "\n",
    "    for name, group in df.groupby('Name'):\n",
    "        durations = []\n",
    "        weekday_minutes = 0\n",
    "        weekend_holiday_minutes = 0\n",
    "\n",
    "        for _, row in group.iterrows():\n",
    "            start, end = row['Start'], row['End']\n",
    "            durations.append(format_range(start, end))\n",
    "\n",
    "            current_time = start\n",
    "            while current_time < end:\n",
    "                next_time = min(current_time + timedelta(minutes=30), end)\n",
    "                current_day = current_time.date()\n",
    "                minutes = (next_time - current_time).total_seconds() / 60\n",
    "\n",
    "                is_weekend = current_day.weekday() >= 5\n",
    "                is_holiday = current_day in holiday_dates\n",
    "\n",
    "                if is_weekend or is_holiday:\n",
    "                    weekend_holiday_minutes += minutes\n",
    "                else:\n",
    "                    weekday_minutes += minutes\n",
    "\n",
    "                current_time = next_time\n",
    "\n",
    "        # Convert total minutes to days and remaining hours (24h = 1 day)\n",
    "        weekday_total_hours = weekday_minutes / 60\n",
    "        weekday_days = int(weekday_total_hours // 24)\n",
    "        weekday_rem_hours = round(weekday_total_hours % 24, 2)\n",
    "\n",
    "        weekend_total_hours = weekend_holiday_minutes / 60\n",
    "        weekend_days = int(weekend_total_hours // 24)\n",
    "        weekend_rem_hours = round(weekend_total_hours % 24, 2)\n",
    "\n",
    "        result.append({\n",
    "            'Name': name,\n",
    "            'Formatted Ranges': ' . '.join(durations),\n",
    "            'Weekday Count': f\"{weekday_days} days, {weekday_rem_hours:.2f} hours\",\n",
    "            'Weekend/Holiday Count': f\"{weekend_days} days, {weekend_rem_hours:.2f} hours\"\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(result)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "pagerduty_summary = compute_durations(pagerduty_df)\n",
    "\n",
    "# === Step 4: Process Extra Hours ===\n",
    "day_cols = [col for col in extrahours_df.columns if isinstance(col, (int, float)) or (isinstance(col, str) and col.isdigit())]\n",
    "extra_long = extrahours_df.melt(id_vars=['Name'], value_vars=day_cols, var_name='Day', value_name='Minutes')\n",
    "extra_long = extra_long.dropna(subset=['Minutes'])\n",
    "extra_long['Day'] = extra_long['Day'].astype(int)\n",
    "\n",
    "extra_long['Date'] = pd.to_datetime({'year': 2025, 'month': 2, 'day': extra_long['Day']})\n",
    "extra_long['IsWeekend'] = extra_long['Date'].dt.weekday >= 5\n",
    "extra_long['IsHoliday'] = extra_long['Date'].dt.date.isin(holiday_dates)\n",
    "extra_long['IsWeekendOrHoliday'] = extra_long['IsWeekend'] | extra_long['IsHoliday']\n",
    "\n",
    "extra_summary = extra_long.groupby(['Name']).agg(\n",
    "    ExtraWeekdayMinutes=('Minutes', lambda x: x[~extra_long.loc[x.index, 'IsWeekendOrHoliday']].sum()),\n",
    "    ExtraWeekendHolidayMinutes=('Minutes', lambda x: x[extra_long.loc[x.index, 'IsWeekendOrHoliday']].sum())\n",
    ").reset_index()\n",
    "\n",
    "extra_summary['ExtraWeekday Hours'] = (extra_summary['ExtraWeekdayMinutes'] / 60).round(2).astype(str) + ' hours'\n",
    "extra_summary['ExtraWeekendHoliday Hours'] = (extra_summary['ExtraWeekendHolidayMinutes'] / 60).round(2).astype(str) + ' hours'\n",
    "extra_summary = extra_summary.drop(columns=['ExtraWeekdayMinutes', 'ExtraWeekendHolidayMinutes'])\n",
    "\n",
    "# === Step 5: Merge and Clean ===\n",
    "final_summary = pd.merge(pagerduty_summary, extra_summary, on='Name', how='outer')\n",
    "final_summary = final_summary.fillna({\n",
    "    'Formatted Ranges': '',\n",
    "    'Weekday Count': '0 days, 0.00 hours',\n",
    "    'Weekend/Holiday Count': '0 days, 0.00 hours',\n",
    "    'ExtraWeekday Hours': '0.00 hours',\n",
    "    'ExtraWeekendHoliday Hours': '0.00 hours'\n",
    "})\n",
    "\n",
    "final_summary = final_summary.sort_values('Name').reset_index(drop=True)\n",
    "\n",
    "# === Save or View Output ===\n",
    "final_summary.to_excel(\"Final_Summary_Output.xlsx\", index=False)\n",
    "print(final_summary)\n",
    "\n",
    "final_summary.to_excel(\n",
    "    r\"C:\\Users\\HP\\Desktop\\Final_Summary_Output_FEB.xlsx\",  # < absolute path\n",
    "    index=False,                                       # do NOT write the row index\n",
    "    engine=\"openpyxl\"                                  # openpyxl is the modern default\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "574d65ec-0b3c-48d1-acf9-59168cd253b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Name                                   Formatted Ranges  \\\n",
      "0          Ahalya Hegde         Tue, May 27 @ 09:15 To Sun, Jun 01 @ 00:00   \n",
      "1          Ayush Rajeev         Mon, May 12 @ 05:30 To Mon, May 19 @ 05:30   \n",
      "2   Basudev Singh Munda         Mon, May 05 @ 09:00 To Mon, May 12 @ 09:00   \n",
      "3      Durai Ramalingam  Mon, May 05 @ 05:30 To Mon, May 12 @ 05:30 . M...   \n",
      "4        Jithin Johnson  Thu, May 01 @ 00:00 To Mon, May 05 @ 05:30 . M...   \n",
      "5     Prakash Rajendran         Mon, May 12 @ 09:00 To Mon, May 19 @ 09:00   \n",
      "6          Rony Abraham         Mon, May 19 @ 09:00 To Mon, May 26 @ 09:00   \n",
      "7        Upal mukherjee         Mon, May 26 @ 09:00 To Tue, May 27 @ 09:12   \n",
      "8         ankit thakkar         Mon, May 05 @ 05:30 To Mon, May 12 @ 05:30   \n",
      "9    muthumani gurusamy  Thu, May 01 @ 00:00 To Mon, May 05 @ 05:30 . M...   \n",
      "10    nirmalraja selvam         Mon, May 12 @ 05:30 To Mon, May 19 @ 05:30   \n",
      "11        vamshi bandla         Thu, May 01 @ 00:00 To Mon, May 05 @ 09:00   \n",
      "\n",
      "          Weekday Count Weekend/Holiday Count ExtraWeekday Hours  \\\n",
      "0   3 days, 15.00 hours   0 days, 23.75 hours         0.00 hours   \n",
      "1    5 days, 0.00 hours    2 days, 0.00 hours         0.00 hours   \n",
      "2    5 days, 0.00 hours    2 days, 0.00 hours         0.00 hours   \n",
      "3   10 days, 0.00 hours    4 days, 0.00 hours          3.0 hours   \n",
      "4   12 days, 0.00 hours    5 days, 0.00 hours         0.00 hours   \n",
      "5    5 days, 0.00 hours    2 days, 0.00 hours         0.00 hours   \n",
      "6    5 days, 0.00 hours    2 days, 0.00 hours         0.00 hours   \n",
      "7    1 days, 0.20 hours    0 days, 0.00 hours         0.00 hours   \n",
      "8    5 days, 0.00 hours    2 days, 0.00 hours         0.33 hours   \n",
      "9    7 days, 0.00 hours    3 days, 0.00 hours         2.08 hours   \n",
      "10   5 days, 0.00 hours    2 days, 0.00 hours         0.00 hours   \n",
      "11   2 days, 9.00 hours    2 days, 0.00 hours         0.00 hours   \n",
      "\n",
      "   ExtraWeekendHoliday Hours  \n",
      "0                 0.00 hours  \n",
      "1                 0.00 hours  \n",
      "2                 0.00 hours  \n",
      "3                  0.0 hours  \n",
      "4                 0.00 hours  \n",
      "5                 0.00 hours  \n",
      "6                 0.00 hours  \n",
      "7                 0.00 hours  \n",
      "8                  0.0 hours  \n",
      "9                  0.0 hours  \n",
      "10                0.00 hours  \n",
      "11                0.00 hours  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# === Step 1: Load Files ===\n",
    "pagerduty_df = pd.read_excel(\"C:/Users/HP/Desktop/Copy of PagerDuty_May_2025.xlsx\")\n",
    "extrahours_df = pd.read_excel(\"C:/Users/HP/Desktop/Copy of Extra_hours.xlsx\")\n",
    "holidays_df = pd.read_excel(\"C:/Users/HP/Desktop/Mindera India - Holiday List 2025.xlsx\")\n",
    "\n",
    "# === Step 2: Clean Holiday Dates ===\n",
    "holiday_col = holidays_df.columns[3]\n",
    "valid_holidays = holidays_df[holiday_col].dropna()\n",
    "valid_holidays = valid_holidays[valid_holidays != \"Date\"]\n",
    "holiday_dates = pd.to_datetime(valid_holidays, errors='coerce').dropna().dt.date.unique()\n",
    "\n",
    "# === Step 3: Process PagerDuty Log ===\n",
    "pagerduty_df['Start'] = pd.to_datetime(pagerduty_df['From Date'].astype(str) + ' ' + pagerduty_df['From Time'].astype(str), errors='coerce')\n",
    "pagerduty_df['End'] = pd.to_datetime(pagerduty_df['To Date'].astype(str) + ' ' + pagerduty_df['To Time'].astype(str), errors='coerce')\n",
    "pagerduty_df = pagerduty_df.dropna(subset=['Start', 'End'])\n",
    "\n",
    "def format_range(start_dt, end_dt):\n",
    "    return f\"{start_dt.strftime('%a, %b %d @ %H:%M')} To {end_dt.strftime('%a, %b %d @ %H:%M')}\"\n",
    "def compute_durations(df):\n",
    "    result = []\n",
    "\n",
    "    for name, group in df.groupby('Name'):\n",
    "        durations = []\n",
    "        weekday_minutes = 0\n",
    "        weekend_holiday_minutes = 0\n",
    "\n",
    "        for _, row in group.iterrows():\n",
    "            start, end = row['Start'], row['End']\n",
    "            durations.append(format_range(start, end))\n",
    "\n",
    "            current_time = start\n",
    "            while current_time < end:\n",
    "                next_time = min(current_time + timedelta(minutes=30), end)\n",
    "                current_day = current_time.date()\n",
    "                minutes = (next_time - current_time).total_seconds() / 60\n",
    "\n",
    "                is_weekend = current_day.weekday() >= 5\n",
    "                is_holiday = current_day in holiday_dates\n",
    "\n",
    "                if is_weekend or is_holiday:\n",
    "                    weekend_holiday_minutes += minutes\n",
    "                else:\n",
    "                    weekday_minutes += minutes\n",
    "\n",
    "                current_time = next_time\n",
    "\n",
    "        # Convert total minutes to days and remaining hours (24h = 1 day)\n",
    "        weekday_total_hours = weekday_minutes / 60\n",
    "        weekday_days = int(weekday_total_hours // 24)\n",
    "        weekday_rem_hours = round(weekday_total_hours % 24, 2)\n",
    "\n",
    "        weekend_total_hours = weekend_holiday_minutes / 60\n",
    "        weekend_days = int(weekend_total_hours // 24)\n",
    "        weekend_rem_hours = round(weekend_total_hours % 24, 2)\n",
    "\n",
    "        result.append({\n",
    "            'Name': name,\n",
    "            'Formatted Ranges': ' . '.join(durations),\n",
    "            'Weekday Count': f\"{weekday_days} days, {weekday_rem_hours:.2f} hours\",\n",
    "            'Weekend/Holiday Count': f\"{weekend_days} days, {weekend_rem_hours:.2f} hours\"\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(result)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "pagerduty_summary = compute_durations(pagerduty_df)\n",
    "\n",
    "# === Step 4: Process Extra Hours ===\n",
    "day_cols = [col for col in extrahours_df.columns if isinstance(col, (int, float)) or (isinstance(col, str) and col.isdigit())]\n",
    "extra_long = extrahours_df.melt(id_vars=['Name'], value_vars=day_cols, var_name='Day', value_name='Minutes')\n",
    "extra_long = extra_long.dropna(subset=['Minutes'])\n",
    "extra_long['Day'] = extra_long['Day'].astype(int)\n",
    "\n",
    "extra_long['Date'] = pd.to_datetime({'year': 2025, 'month': 5, 'day': extra_long['Day']})\n",
    "extra_long['IsWeekend'] = extra_long['Date'].dt.weekday >= 5\n",
    "extra_long['IsHoliday'] = extra_long['Date'].dt.date.isin(holiday_dates)\n",
    "extra_long['IsWeekendOrHoliday'] = extra_long['IsWeekend'] | extra_long['IsHoliday']\n",
    "\n",
    "extra_summary = extra_long.groupby(['Name']).agg(\n",
    "    ExtraWeekdayMinutes=('Minutes', lambda x: x[~extra_long.loc[x.index, 'IsWeekendOrHoliday']].sum()),\n",
    "    ExtraWeekendHolidayMinutes=('Minutes', lambda x: x[extra_long.loc[x.index, 'IsWeekendOrHoliday']].sum())\n",
    ").reset_index()\n",
    "\n",
    "extra_summary['ExtraWeekday Hours'] = (extra_summary['ExtraWeekdayMinutes'] / 60).round(2).astype(str) + ' hours'\n",
    "extra_summary['ExtraWeekendHoliday Hours'] = (extra_summary['ExtraWeekendHolidayMinutes'] / 60).round(2).astype(str) + ' hours'\n",
    "extra_summary = extra_summary.drop(columns=['ExtraWeekdayMinutes', 'ExtraWeekendHolidayMinutes'])\n",
    "\n",
    "# === Step 5: Merge and Clean ===\n",
    "final_summary = pd.merge(pagerduty_summary, extra_summary, on='Name', how='outer')\n",
    "final_summary = final_summary.fillna({\n",
    "    'Formatted Ranges': '',\n",
    "    'Weekday Count': '0 days, 0.00 hours',\n",
    "    'Weekend/Holiday Count': '0 days, 0.00 hours',\n",
    "    'ExtraWeekday Hours': '0.00 hours',\n",
    "    'ExtraWeekendHoliday Hours': '0.00 hours'\n",
    "})\n",
    "\n",
    "final_summary = final_summary.sort_values('Name').reset_index(drop=True)\n",
    "\n",
    "# === Save or View Output ===\n",
    "final_summary.to_excel(\"Final_Summary_Output.xlsx\", index=False)\n",
    "print(final_summary)\n",
    "\n",
    "final_summary.to_excel(\n",
    "    r\"C:\\Users\\HP\\Desktop\\Final_Summary_Output_MAY.xlsx\",  # < absolute path\n",
    "    index=False,                                       # do NOT write the row index\n",
    "    engine=\"openpyxl\"                                  # openpyxl is the modern default\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4087904f-2251-4b91-bbe5-7373e44716b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Summary saved to: C:\\Users\\HP\\Desktop\\Final_Summary_Output_2025-04.xlsx\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "from calendar import month_abbr\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# === FILE LOCATIONS ===\n",
    "PAGERDUTY_FILE  = r\"C:\\Users\\HP\\Desktop\\Copy of PagerDutyLog -Apr-2025.xlsx\"\n",
    "EXTRAHOURS_FILE = r\"C:\\Users\\HP\\Desktop\\Copy of ExtraHours-apr-2025.xlsx\"\n",
    "HOLIDAYS_FILE   = r\"C:\\Users\\HP\\Desktop\\Mindera India - Holiday List 2025.xlsx\"\n",
    "\n",
    "# === Infer YEAR and MONTH from filename ===\n",
    "def infer_year_month(path):\n",
    "    stem = Path(path).stem\n",
    "    m = re.search(r'([A-Za-z]{3})[-_]?(\\d{4})', stem)\n",
    "    if not m:\n",
    "        raise ValueError(\"Cannot find month and year in filename: {}\".format(path))\n",
    "    mon_abbr = m.group(1).title()\n",
    "    year = int(m.group(2))\n",
    "    month = list(month_abbr).index(mon_abbr)\n",
    "    return year, month\n",
    "\n",
    "YEAR, MONTH = infer_year_month(EXTRAHOURS_FILE)\n",
    "\n",
    "# === Load Excel Files ===\n",
    "pagerduty_df = pd.read_excel(PAGERDUTY_FILE)\n",
    "extrahours_df = pd.read_excel(EXTRAHOURS_FILE)\n",
    "holidays_df = pd.read_excel(HOLIDAYS_FILE)\n",
    "\n",
    "# === Clean Holiday List ===\n",
    "holiday_col = holidays_df.columns[3]\n",
    "valid_holidays = holidays_df[holiday_col].dropna()\n",
    "valid_holidays = valid_holidays[valid_holidays != \"Date\"]\n",
    "holiday_dates = pd.to_datetime(valid_holidays, errors='coerce').dropna().dt.date.unique()\n",
    "\n",
    "# === Process PagerDuty ===\n",
    "pagerduty_df['Start'] = pd.to_datetime(pagerduty_df['From Date'].astype(str) + ' ' + pagerduty_df['From Time'].astype(str), errors='coerce')\n",
    "pagerduty_df['End'] = pd.to_datetime(pagerduty_df['To Date'].astype(str) + ' ' + pagerduty_df['To Time'].astype(str), errors='coerce')\n",
    "pagerduty_df = pagerduty_df.dropna(subset=['Start', 'End'])\n",
    "\n",
    "def format_range(start_dt, end_dt):\n",
    "    return \"{} To {}\".format(\n",
    "        start_dt.strftime('%a, %b %d @ %H:%M'),\n",
    "        end_dt.strftime('%a, %b %d @ %H:%M')\n",
    "    )\n",
    "\n",
    "def compute_durations(df):\n",
    "    result = []\n",
    "    for name, group in df.groupby('Name'):\n",
    "        durations = []\n",
    "        weekday_minutes = 0\n",
    "        weekend_holiday_minutes = 0\n",
    "\n",
    "        for _, row in group.iterrows():\n",
    "            start = row['Start']\n",
    "            end = row['End']\n",
    "            durations.append(format_range(start, end))\n",
    "\n",
    "            current_time = start\n",
    "            while current_time < end:\n",
    "                next_time = min(current_time + timedelta(minutes=30), end)\n",
    "                current_day = current_time.date()\n",
    "                minutes = (next_time - current_time).total_seconds() / 60\n",
    "\n",
    "                is_weekend = current_day.weekday() >= 5\n",
    "                is_holiday = current_day in holiday_dates\n",
    "\n",
    "                if is_weekend or is_holiday:\n",
    "                    weekend_holiday_minutes += minutes\n",
    "                else:\n",
    "                    weekday_minutes += minutes\n",
    "\n",
    "                current_time = next_time\n",
    "\n",
    "        weekday_total_hours = weekday_minutes / 60\n",
    "        weekday_days = int(weekday_total_hours // 24)\n",
    "        weekday_rem_hours = round(weekday_total_hours % 24, 2)\n",
    "\n",
    "        weekend_total_hours = weekend_holiday_minutes / 60\n",
    "        weekend_days = int(weekend_total_hours // 24)\n",
    "        weekend_rem_hours = round(weekend_total_hours % 24, 2)\n",
    "\n",
    "        result.append({\n",
    "            'Name': name,\n",
    "            'Formatted Ranges': ' . '.join(durations),\n",
    "            'Weekday Count': \"{} days, {:.2f} hours\".format(weekday_days, weekday_rem_hours),\n",
    "            'Weekend/Holiday Count': \"{} days, {:.2f} hours\".format(weekend_days, weekend_rem_hours)\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(result)\n",
    "\n",
    "pagerduty_summary = compute_durations(pagerduty_df)\n",
    "\n",
    "# === Process Extra Hours ===\n",
    "day_cols = [col for col in extrahours_df.columns if isinstance(col, (int, float)) or (isinstance(col, str) and col.isdigit())]\n",
    "extra_long = extrahours_df.melt(id_vars=['Name'], value_vars=day_cols, var_name='Day', value_name='Minutes')\n",
    "extra_long = extra_long.dropna(subset=['Minutes'])\n",
    "extra_long['Day'] = extra_long['Day'].astype(int)\n",
    "extra_long['Date'] = pd.to_datetime({'year': YEAR, 'month': MONTH, 'day': extra_long['Day']}, errors='coerce')\n",
    "extra_long = extra_long.dropna(subset=['Date'])\n",
    "\n",
    "extra_long['IsWeekend'] = extra_long['Date'].dt.weekday >= 5\n",
    "extra_long['IsHoliday'] = extra_long['Date'].dt.date.isin(holiday_dates)\n",
    "extra_long['IsWeekendOrHoliday'] = extra_long['IsWeekend'] | extra_long['IsHoliday']\n",
    "\n",
    "extra_long['WeekdayMinutes'] = extra_long['Minutes'].where(~extra_long['IsWeekendOrHoliday'], 0)\n",
    "extra_long['WeekendHolidayMinutes'] = extra_long['Minutes'].where(extra_long['IsWeekendOrHoliday'], 0)\n",
    "\n",
    "extra_summary = extra_long.groupby('Name').agg(\n",
    "    ExtraWeekdayMinutes=('WeekdayMinutes', 'sum'),\n",
    "    ExtraWeekendHolidayMinutes=('WeekendHolidayMinutes', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "extra_summary['ExtraWeekday Hours'] = (extra_summary['ExtraWeekdayMinutes'] / 60).round(2).astype(str) + ' hours'\n",
    "extra_summary['ExtraWeekendHoliday Hours'] = (extra_summary['ExtraWeekendHolidayMinutes'] / 60).round(2).astype(str) + ' hours'\n",
    "extra_summary = extra_summary.drop(columns=['ExtraWeekdayMinutes', 'ExtraWeekendHolidayMinutes'])\n",
    "\n",
    "# === Merge & Output ===\n",
    "final_summary = pd.merge(pagerduty_summary, extra_summary, on='Name', how='outer')\n",
    "final_summary = final_summary.fillna({\n",
    "    'Formatted Ranges': '',\n",
    "    'Weekday Count': '0 days, 0.00 hours',\n",
    "    'Weekend/Holiday Count': '0 days, 0.00 hours',\n",
    "    'ExtraWeekday Hours': '0.00 hours',\n",
    "    'ExtraWeekendHoliday Hours': '0.00 hours'\n",
    "})\n",
    "\n",
    "final_summary = final_summary.sort_values('Name').reset_index(drop=True)\n",
    "\n",
    "output_file = Path(EXTRAHOURS_FILE).with_name(\n",
    "    \"Final_Summary_Output_{}-{:02d}.xlsx\".format(YEAR, MONTH)\n",
    ")\n",
    "\n",
    "final_summary.to_excel(output_file, index=False, engine=\"openpyxl\")\n",
    "print(\" Summary saved to:\", output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adec45d5-d65a-46b2-86f7-e42fd346736e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Name                                   Formatted Ranges  \\\n",
      "0         Ahalya Hegde         Tue, Feb 11 @ 09:00 To Mon, Feb 17 @ 09:00   \n",
      "1         Ayush Rajeev         Mon, Feb 03 @ 05:30 To Mon, Feb 10 @ 05:30   \n",
      "2  Basudev Singh Munda         Mon, Feb 03 @ 09:00 To Tue, Feb 11 @ 09:00   \n",
      "3         Dolly Chahar         Mon, Feb 17 @ 09:00 To Mon, Feb 24 @ 09:00   \n",
      "4     Durai Ramalingam  Mon, Feb 24 @ 04:30 To Sat, Mar 01 @ 00:00 . M...   \n",
      "5       Jithin Johnson  Mon, Feb 17 @ 04:30 To Mon, Feb 24 @ 04:30 . M...   \n",
      "6          Kapil Jugnu         Mon, Feb 17 @ 04:30 To Mon, Feb 24 @ 04:30   \n",
      "7  Keerthivasan Kannan  Tue, Feb 11 @ 10:00 To Sun, Feb 16 @ 01:43 . S...   \n",
      "8   Muthumani Gurusamy                                                      \n",
      "9    Prakash Rajendran         Sat, Feb 01 @ 00:00 To Mon, Feb 03 @ 09:00   \n",
      "\n",
      "         Weekday Count Weekend/Holiday Count        ExtraWeekday  \\\n",
      "0   7 days, 0.00 hours    6 days, 0.00 hours  0 days, 0.00 hours   \n",
      "1   9 days, 0.00 hours    6 days, 0.00 hours  0 days, 0.75 hours   \n",
      "2  11 days, 0.00 hours    6 days, 0.00 hours  0 days, 0.00 hours   \n",
      "3   9 days, 0.00 hours    6 days, 0.00 hours  0 days, 0.00 hours   \n",
      "4  14 days, 0.00 hours   16 days, 0.00 hours   0 days, 0.5 hours   \n",
      "5  18 days, 0.00 hours   12 days, 0.00 hours  0 days, 0.00 hours   \n",
      "6   9 days, 0.00 hours    6 days, 0.00 hours  0 days, 0.33 hours   \n",
      "7  8 days, 23.75 hours   5 days, 14.22 hours  0 days, 1.17 hours   \n",
      "8   0 days, 0.00 hours    0 days, 0.00 hours   0 days, 0.0 hours   \n",
      "9   1 days, 9.00 hours    4 days, 0.00 hours  0 days, 0.00 hours   \n",
      "\n",
      "  ExtraWeekendHoliday  \n",
      "0  0 days, 0.00 hours  \n",
      "1   0 days, 0.5 hours  \n",
      "2  0 days, 0.00 hours  \n",
      "3  0 days, 0.00 hours  \n",
      "4   0 days, 0.0 hours  \n",
      "5  0 days, 0.00 hours  \n",
      "6   0 days, 1.0 hours  \n",
      "7   0 days, 0.0 hours  \n",
      "8   0 days, 0.5 hours  \n",
      "9  0 days, 0.00 hours  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_14036\\3995614472.py:87: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  extra_summary = extra_long.groupby('Name').apply(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import calendar\n",
    "\n",
    "# === Step 1: Load Files ===\n",
    "pagerduty_df = pd.read_excel(\"C:/Users/HP/Desktop/Copy of PagerDutyLog -Apr-2025.xlsx\")\n",
    "extrahours_df = pd.read_excel(\"C:/Users/HP/Desktop/Copy of ExtraHours-apr-2025.xlsx\")\n",
    "holidays_df = pd.read_excel(\"C:/Users/HP/Desktop/Mindera India - Holiday List 2025.xlsx\")\n",
    "\n",
    "# === Step 2: Clean Holiday Dates ===\n",
    "holiday_col = holidays_df.columns[3]\n",
    "valid_holidays = holidays_df[holiday_col].dropna()\n",
    "valid_holidays = valid_holidays[valid_holidays != \"Date\"]\n",
    "holiday_dates = pd.to_datetime(valid_holidays, errors='coerce').dropna().dt.date.unique()\n",
    "\n",
    "# === Step 3: Process PagerDuty Log ===\n",
    "pagerduty_df['Start'] = pd.to_datetime(pagerduty_df['From Date'].astype(str) + ' ' + pagerduty_df['From Time'].astype(str), errors='coerce')\n",
    "pagerduty_df['End'] = pd.to_datetime(pagerduty_df['To Date'].astype(str) + ' ' + pagerduty_df['To Time'].astype(str), errors='coerce')\n",
    "pagerduty_df = pagerduty_df.dropna(subset=['Start', 'End'])\n",
    "\n",
    "def format_range(start_dt, end_dt):\n",
    "    return f\"{start_dt.strftime('%a, %b %d @ %H:%M')} To {end_dt.strftime('%a, %b %d @ %H:%M')}\"\n",
    "\n",
    "def compute_durations(df):\n",
    "    result = []\n",
    "    for name, group in df.groupby('Name'):\n",
    "        durations = []\n",
    "        weekday_minutes = 0\n",
    "        weekend_holiday_minutes = 0\n",
    "        weekday_days_set = set()\n",
    "        weekend_days_set = set()\n",
    "\n",
    "        for _, row in group.iterrows():\n",
    "            start, end = row['Start'], row['End']\n",
    "            durations.append(format_range(start, end))\n",
    "            current_time = start\n",
    "\n",
    "            while current_time < end:\n",
    "                next_time = min(current_time + timedelta(minutes=30), end)\n",
    "                current_day = current_time.date()\n",
    "                minutes = (next_time - current_time).total_seconds() / 60\n",
    "\n",
    "                is_weekend = current_day.weekday() >= 5\n",
    "                is_holiday = current_day in holiday_dates\n",
    "\n",
    "                if is_weekend or is_holiday:\n",
    "                    weekend_days_set.add(current_day)\n",
    "                    weekend_holiday_minutes += minutes\n",
    "                else:\n",
    "                    weekday_days_set.add(current_day)\n",
    "                    weekday_minutes += minutes\n",
    "\n",
    "                current_time = next_time\n",
    "\n",
    "        # Normalize weekday hours to days\n",
    "        weekday_hours = weekday_minutes / 60\n",
    "        weekday_days = int(weekday_hours // 24) + len(weekday_days_set)\n",
    "        weekday_rem_hours = round(weekday_hours % 24, 2)\n",
    "\n",
    "        # Normalize weekend/holiday hours to days\n",
    "        weekend_hours = weekend_holiday_minutes / 60\n",
    "        weekend_days = int(weekend_hours // 24) + len(weekend_days_set)\n",
    "        weekend_rem_hours = round(weekend_hours % 24, 2)\n",
    "\n",
    "        result.append({\n",
    "            'Name': name,\n",
    "            'Formatted Ranges': ' . '.join(durations),\n",
    "            'Weekday Count': f\"{weekday_days} days, {weekday_rem_hours:.2f} hours\",\n",
    "            'Weekend/Holiday Count': f\"{weekend_days} days, {weekend_rem_hours:.2f} hours\"\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(result)\n",
    "\n",
    "pagerduty_summary = compute_durations(pagerduty_df)\n",
    "\n",
    "# === Step 4: Process Extra Hours ===\n",
    "day_cols = [col for col in extrahours_df.columns if isinstance(col, (int, float)) or (isinstance(col, str) and col.isdigit())]\n",
    "extra_long = extrahours_df.melt(id_vars=['Name'], value_vars=day_cols, var_name='Day', value_name='Minutes')\n",
    "extra_long = extra_long.dropna(subset=['Minutes'])\n",
    "extra_long['Day'] = extra_long['Day'].astype(int)\n",
    "extra_long['Date'] = pd.to_datetime({'year': 2025, 'month': 2, 'day': extra_long['Day']})\n",
    "extra_long['IsWeekend'] = extra_long['Date'].dt.weekday >= 5\n",
    "extra_long['IsHoliday'] = extra_long['Date'].dt.date.isin(holiday_dates)\n",
    "extra_long['IsWeekendOrHoliday'] = extra_long['IsWeekend'] | extra_long['IsHoliday']\n",
    "\n",
    "# Group and summarize extra hours\n",
    "extra_summary = extra_long.groupby('Name').apply(\n",
    "    lambda x: pd.Series({\n",
    "        'ExtraWeekdayMinutes': x.loc[~x['IsWeekendOrHoliday'], 'Minutes'].sum(),\n",
    "        'ExtraWeekendHolidayMinutes': x.loc[x['IsWeekendOrHoliday'], 'Minutes'].sum()\n",
    "    })\n",
    ").reset_index()\n",
    "\n",
    "# Normalize hours\n",
    "extra_summary['ExtraWeekdayDays'] = (extra_summary['ExtraWeekdayMinutes'] // 1440).astype(int)\n",
    "extra_summary['ExtraWeekdayHours'] = ((extra_summary['ExtraWeekdayMinutes'] % 1440) / 60).round(2)\n",
    "extra_summary['ExtraWeekendHolidayDays'] = (extra_summary['ExtraWeekendHolidayMinutes'] // 1440).astype(int)\n",
    "extra_summary['ExtraWeekendHolidayHours'] = ((extra_summary['ExtraWeekendHolidayMinutes'] % 1440) / 60).round(2)\n",
    "\n",
    "# Format strings\n",
    "extra_summary['ExtraWeekday'] = extra_summary['ExtraWeekdayDays'].astype(str) + ' days, ' + extra_summary['ExtraWeekdayHours'].astype(str) + ' hours'\n",
    "extra_summary['ExtraWeekendHoliday'] = extra_summary['ExtraWeekendHolidayDays'].astype(str) + ' days, ' + extra_summary['ExtraWeekendHolidayHours'].astype(str) + ' hours'\n",
    "\n",
    "# Drop intermediate columns\n",
    "extra_summary = extra_summary[['Name', 'ExtraWeekday', 'ExtraWeekendHoliday']]\n",
    "\n",
    "# === Step 5: Merge and Clean ===\n",
    "final_summary = pd.merge(pagerduty_summary, extra_summary, on='Name', how='outer')\n",
    "\n",
    "final_summary = final_summary.fillna({\n",
    "    'Formatted Ranges': '',\n",
    "    'Weekday Count': '0 days, 0.00 hours',\n",
    "    'Weekend/Holiday Count': '0 days, 0.00 hours',\n",
    "    'ExtraWeekday': '0 days, 0.00 hours',\n",
    "    'ExtraWeekendHoliday': '0 days, 0.00 hours'\n",
    "})\n",
    "\n",
    "final_summary = final_summary.sort_values('Name').reset_index(drop=True)\n",
    "\n",
    "# === Save or View Output ===\n",
    "final_summary.to_excel(\"Final_Summary_Output.xlsx\", index=False)\n",
    "print(final_summary.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a6c00a2-17a2-4a27-ad3a-4d2c632ae6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Name                                   Formatted Ranges  \\\n",
      "0         Ahalya Hegde         Tue, Feb 11 @ 09:00 To Mon, Feb 17 @ 09:00   \n",
      "1         Ayush Rajeev         Mon, Feb 03 @ 05:30 To Mon, Feb 10 @ 05:30   \n",
      "2  Basudev Singh Munda         Mon, Feb 03 @ 09:00 To Tue, Feb 11 @ 09:00   \n",
      "3         Dolly Chahar         Mon, Feb 17 @ 09:00 To Mon, Feb 24 @ 09:00   \n",
      "4     Durai Ramalingam  Mon, Feb 24 @ 04:30 To Sat, Mar 01 @ 00:00 . M...   \n",
      "5       Jithin Johnson  Mon, Feb 17 @ 04:30 To Mon, Feb 24 @ 04:30 . M...   \n",
      "6          Kapil Jugnu         Mon, Feb 17 @ 04:30 To Mon, Feb 24 @ 04:30   \n",
      "7  Keerthivasan Kannan  Tue, Feb 11 @ 10:00 To Sun, Feb 16 @ 01:43 . S...   \n",
      "8   Muthumani Gurusamy                                                      \n",
      "9    Prakash Rajendran         Sat, Feb 01 @ 00:00 To Mon, Feb 03 @ 09:00   \n",
      "\n",
      "           Weekday Count Weekend/Holiday Count ExtraWeekday  \\\n",
      "0    4 days, 72.00 hours   3 days, 72.00 hours   0.00 hours   \n",
      "1    5 days, 96.00 hours   3 days, 72.00 hours   0.75 hours   \n",
      "2   6 days, 120.00 hours   3 days, 72.00 hours   0.00 hours   \n",
      "3    5 days, 96.00 hours   3 days, 72.00 hours   0.00 hours   \n",
      "4   8 days, 144.00 hours  8 days, 192.00 hours    0.5 hours   \n",
      "5  10 days, 192.00 hours  6 days, 144.00 hours   0.00 hours   \n",
      "6    5 days, 96.00 hours   3 days, 72.00 hours   0.33 hours   \n",
      "7    5 days, 95.75 hours   3 days, 62.22 hours   1.17 hours   \n",
      "8     0 days, 0.00 hours    0 days, 0.00 hours    0.0 hours   \n",
      "9     1 days, 9.00 hours   2 days, 48.00 hours   0.00 hours   \n",
      "\n",
      "  ExtraWeekendHoliday  \n",
      "0          0.00 hours  \n",
      "1           0.5 hours  \n",
      "2          0.00 hours  \n",
      "3          0.00 hours  \n",
      "4           0.0 hours  \n",
      "5          0.00 hours  \n",
      "6           1.0 hours  \n",
      "7           0.0 hours  \n",
      "8           0.5 hours  \n",
      "9          0.00 hours  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# === Step 1: Load Files ===\n",
    "pagerduty_df = pd.read_excel(\"C:/Users/HP/Desktop/finalCopy of PagerDutyLog - Feb.xlsx\")\n",
    "extrahours_df = pd.read_excel(\"C:/Users/HP/Desktop/finalCopy of ExtraHoursLog - Feb.xlsx\")\n",
    "holidays_df = pd.read_excel(\"C:/Users/HP/Desktop/Mindera India - Holiday List 2025.xlsx\")\n",
    "\n",
    "# === Step 2: Clean Holiday Dates ===\n",
    "holiday_col = holidays_df.columns[3]\n",
    "valid_holidays = holidays_df[holiday_col].dropna()\n",
    "valid_holidays = valid_holidays[valid_holidays != \"Date\"]\n",
    "holiday_dates = pd.to_datetime(valid_holidays, errors='coerce').dropna().dt.date.unique()\n",
    "\n",
    "# === Step 3: Process PagerDuty Log ===\n",
    "pagerduty_df['Start'] = pd.to_datetime(pagerduty_df['From Date'].astype(str) + ' ' + pagerduty_df['From Time'].astype(str), errors='coerce')\n",
    "pagerduty_df['End'] = pd.to_datetime(pagerduty_df['To Date'].astype(str) + ' ' + pagerduty_df['To Time'].astype(str), errors='coerce')\n",
    "pagerduty_df = pagerduty_df.dropna(subset=['Start', 'End'])\n",
    "\n",
    "def format_range(start_dt, end_dt):\n",
    "    return f\"{start_dt.strftime('%a, %b %d @ %H:%M')} To {end_dt.strftime('%a, %b %d @ %H:%M')}\"\n",
    "\n",
    "def compute_durations(df):\n",
    "    result = []\n",
    "    for name, group in df.groupby('Name'):\n",
    "        durations = []\n",
    "        weekday_days = set()\n",
    "        weekend_holiday_days = set()\n",
    "        weekday_minutes = 0\n",
    "        weekend_holiday_minutes = 0\n",
    "\n",
    "        for _, row in group.iterrows():\n",
    "            start, end = row['Start'], row['End']\n",
    "            durations.append(format_range(start, end))\n",
    "            current_time = start\n",
    "            while current_time < end:\n",
    "                next_time = min(current_time + timedelta(minutes=30), end)\n",
    "                current_day = current_time.date()\n",
    "                minutes = (next_time - current_time).total_seconds() / 60\n",
    "\n",
    "                is_weekend = current_day.weekday() >= 5\n",
    "                is_holiday = current_day in holiday_dates\n",
    "                if is_weekend or is_holiday:\n",
    "                    weekend_holiday_days.add(current_day)\n",
    "                    weekend_holiday_minutes += minutes\n",
    "                else:\n",
    "                    weekday_days.add(current_day)\n",
    "                    weekday_minutes += minutes\n",
    "\n",
    "                current_time = next_time\n",
    "\n",
    "        #  Updated logic: effective days = max(unique_days, floor(minutes / 1440))\n",
    "        total_weekday_days = max(len(weekday_days), int(weekday_minutes // 1440))\n",
    "        total_weekend_days = max(len(weekend_holiday_days), int(weekend_holiday_minutes // 1440))\n",
    "\n",
    "        result.append({\n",
    "            'Name': name,\n",
    "            'Formatted Ranges': ' . '.join(durations),\n",
    "            'Weekday Count': f\"{total_weekday_days} days, {weekday_minutes / 60:.2f} hours\",\n",
    "            'Weekend/Holiday Count': f\"{total_weekend_days} days, {weekend_holiday_minutes / 60:.2f} hours\"\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(result)\n",
    "\n",
    "pagerduty_summary = compute_durations(pagerduty_df)\n",
    "\n",
    "# === Step 4: Process Extra Hours ===\n",
    "day_cols = [col for col in extrahours_df.columns if isinstance(col, (int, float)) or (isinstance(col, str) and col.isdigit())]\n",
    "extra_long = extrahours_df.melt(id_vars=['Name'], value_vars=day_cols, var_name='Day', value_name='Minutes')\n",
    "extra_long = extra_long.dropna(subset=['Minutes'])\n",
    "extra_long['Day'] = extra_long['Day'].astype(int)\n",
    "\n",
    "extra_long['Date'] = pd.to_datetime({'year': 2025, 'month': 2, 'day': extra_long['Day']})\n",
    "extra_long['IsWeekend'] = extra_long['Date'].dt.weekday >= 5\n",
    "extra_long['IsHoliday'] = extra_long['Date'].dt.date.isin(holiday_dates)\n",
    "extra_long['IsWeekendOrHoliday'] = extra_long['IsWeekend'] | extra_long['IsHoliday']\n",
    "\n",
    "extra_summary = extra_long.groupby(['Name']).agg(\n",
    "    ExtraWeekdayMinutes=('Minutes', lambda x: x[~extra_long.loc[x.index, 'IsWeekendOrHoliday']].sum()),\n",
    "    ExtraWeekendHolidayMinutes=('Minutes', lambda x: x[extra_long.loc[x.index, 'IsWeekendOrHoliday']].sum())\n",
    ").reset_index()\n",
    "\n",
    "extra_summary['ExtraWeekday'] = (extra_summary['ExtraWeekdayMinutes'] / 60).round(2).astype(str) + ' hours'\n",
    "extra_summary['ExtraWeekendHoliday'] = (extra_summary['ExtraWeekendHolidayMinutes'] / 60).round(2).astype(str) + ' hours'\n",
    "extra_summary = extra_summary.drop(columns=['ExtraWeekdayMinutes', 'ExtraWeekendHolidayMinutes'])\n",
    "\n",
    "# === Step 5: Merge and Clean ===\n",
    "final_summary = pd.merge(pagerduty_summary, extra_summary, on='Name', how='outer')\n",
    "final_summary = final_summary.fillna({\n",
    "    'Formatted Ranges': '',\n",
    "    'Weekday Count': '0 days, 0.00 hours',\n",
    "    'Weekend/Holiday Count': '0 days, 0.00 hours',\n",
    "    'ExtraWeekday': '0.00 hours',\n",
    "    'ExtraWeekendHoliday': '0.00 hours'\n",
    "})\n",
    "\n",
    "final_summary = final_summary.sort_values('Name').reset_index(drop=True)\n",
    "\n",
    "# === Save or View Output ===\n",
    "final_summary.to_excel(\"Final_Summary_Output.xlsx\", index=False)\n",
    "print(final_summary.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ba0eb0e-c974-435f-98f6-376dc3d7342b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Mindera India List of Holidays 2025  \\\n",
      "0                                 S.No   \n",
      "1                                    1   \n",
      "2                                    2   \n",
      "3                                    3   \n",
      "4                                    4   \n",
      "5                                    5   \n",
      "6                                    6   \n",
      "7                                    7   \n",
      "8                                    8   \n",
      "9                                    9   \n",
      "10                                  10   \n",
      "11                                  11   \n",
      "12                                  12   \n",
      "13                                  13   \n",
      "14                                  14   \n",
      "15                                  15   \n",
      "16                                 NaN   \n",
      "17                                 NaN   \n",
      "18                                 NaN   \n",
      "19        Holidays falling on weekends   \n",
      "20                                S.No   \n",
      "21                                   1   \n",
      "22                                   2   \n",
      "23                                   3   \n",
      "24                                   4   \n",
      "25                                 NaN   \n",
      "26                                 NaN   \n",
      "27                                 NaN   \n",
      "28                                 NaN   \n",
      "29                                 NaN   \n",
      "30                                 NaN   \n",
      "\n",
      "                                           Unnamed: 1 Unnamed: 2  \\\n",
      "0                                         Holiday for        Day   \n",
      "1                                            New Year  Wednesday   \n",
      "2                           Pongal & Makara Sankranti    Tuesday   \n",
      "3                                   Thiruvalluvar Day  Wednesday   \n",
      "4                                     Maha Shivaratri  Wednesday   \n",
      "5                                              Ramzan     Monday   \n",
      "6                                Tamil New Year's Day     Monday   \n",
      "7                                         Good Friday     Friday   \n",
      "8                     Basava Jayanthi/Akshaya Tritiya  Wednesday   \n",
      "9                                             May Day   Thursday   \n",
      "10                                   Independence Day     Friday   \n",
      "11                               Vinayakar Chathurthi  Wednesday   \n",
      "12  Mahanavami/Ayudhapooj & (Vijayadasami for Bang...  Wednesday   \n",
      "13      Gandhi Jayanthi / (Vijaya Dasami for Chennai)   Thursday   \n",
      "14                                          Deepavali     Monday   \n",
      "15                                          Christmas   Thursday   \n",
      "16                                                NaN        NaN   \n",
      "17  Note: Only one optional holiday can be availed...        NaN   \n",
      "18                                                NaN        NaN   \n",
      "19                                                NaN        NaN   \n",
      "20                                        Holiday for        Day   \n",
      "21                                       Republic Day     Sunday   \n",
      "22                                             Bakrid   Saturday   \n",
      "23                                   Krishna Jayanthi   Saturday   \n",
      "24                                Kannada Rajyothsava   Saturday   \n",
      "25                                                NaN        NaN   \n",
      "26                                                NaN        NaN   \n",
      "27                                                NaN        NaN   \n",
      "28                                                NaN        NaN   \n",
      "29                                                NaN        NaN   \n",
      "30                                                NaN        NaN   \n",
      "\n",
      "             Unnamed: 3                               Unnamed: 4  \\\n",
      "0                  Date                             Holiday Type   \n",
      "1   2025-01-01 00:00:00                                 Regional   \n",
      "2   2025-01-14 00:00:00                                 Regional   \n",
      "3   2025-01-15 00:00:00            Reginoal - Optional - Chennai   \n",
      "4   2025-02-26 00:00:00          Regional - Optional - Bangalore   \n",
      "5   2025-03-31 00:00:00                                 Regional   \n",
      "6   2025-04-14 00:00:00            Regional - Optional - Chennai   \n",
      "7   2025-04-18 00:00:00                                 Regional   \n",
      "8   2025-04-30 00:00:00          Regional - Optional - Bangalore   \n",
      "9   2025-05-01 00:00:00                                 National   \n",
      "10  2025-08-15 00:00:00                                 National   \n",
      "11  2025-08-27 00:00:00  Regional - Optional - Bangalore/Chennai   \n",
      "12  2025-10-01 00:00:00  Regional - Optional - Bangalore/Chennai   \n",
      "13  2025-10-02 00:00:00                                 National   \n",
      "14  2025-10-20 00:00:00                                 Regional   \n",
      "15  2025-12-25 00:00:00                                 Regional   \n",
      "16                  NaN                                      NaN   \n",
      "17                  NaN                                      NaN   \n",
      "18                  NaN                                      NaN   \n",
      "19                  NaN                                      NaN   \n",
      "20                 Date                                      NaN   \n",
      "21  2025-01-26 00:00:00                                      NaN   \n",
      "22  2025-06-07 00:00:00                                      NaN   \n",
      "23  2025-08-16 00:00:00                                      NaN   \n",
      "24  2025-11-01 00:00:00                                      NaN   \n",
      "25                  NaN                                      NaN   \n",
      "26                  NaN                                      NaN   \n",
      "27                  NaN                                      NaN   \n",
      "28                  NaN                                      NaN   \n",
      "29                  NaN                                      NaN   \n",
      "30                  NaN                                      NaN   \n",
      "\n",
      "         Unnamed: 5         Unnamed: 6        Unnamed: 7  \\\n",
      "0   Mindera Chennai  Mindera Bangalore  Mindera Portugal   \n",
      "1                 1                  1               NaN   \n",
      "2                 1                  1               NaN   \n",
      "3               NaN                NaN               NaN   \n",
      "4               NaN                NaN               NaN   \n",
      "5                 1                  1               NaN   \n",
      "6               NaN                NaN               NaN   \n",
      "7                 1                  1               NaN   \n",
      "8               NaN                NaN               NaN   \n",
      "9                 1                  1               NaN   \n",
      "10                1                  1               NaN   \n",
      "11              NaN                NaN               NaN   \n",
      "12              NaN                NaN               NaN   \n",
      "13                1                  1               NaN   \n",
      "14                1                  1               NaN   \n",
      "15                1                  1               NaN   \n",
      "16              NaN                NaN               NaN   \n",
      "17              NaN                NaN               NaN   \n",
      "18              NaN                NaN               NaN   \n",
      "19              NaN                NaN               NaN   \n",
      "20              NaN                NaN               NaN   \n",
      "21              NaN                NaN               NaN   \n",
      "22              NaN                NaN               NaN   \n",
      "23              NaN                NaN               NaN   \n",
      "24              NaN                NaN               NaN   \n",
      "25              NaN                NaN               NaN   \n",
      "26              NaN                NaN               NaN   \n",
      "27              NaN                NaN               NaN   \n",
      "28              NaN                NaN               NaN   \n",
      "29              NaN                NaN               NaN   \n",
      "30                9                  9                 0   \n",
      "\n",
      "                                           Unnamed: 8  \n",
      "0                                            Comments  \n",
      "1   Only one optional holiday can be availed in a ...  \n",
      "2                                                 NaN  \n",
      "3                                                 NaN  \n",
      "4                                                 NaN  \n",
      "5                                                 NaN  \n",
      "6                                                 NaN  \n",
      "7                                                 NaN  \n",
      "8                                                 NaN  \n",
      "9                                                 NaN  \n",
      "10                                                NaN  \n",
      "11                                                NaN  \n",
      "12                                                NaN  \n",
      "13                                                NaN  \n",
      "14                                                NaN  \n",
      "15                                                NaN  \n",
      "16                                                NaN  \n",
      "17                                                NaN  \n",
      "18                                                NaN  \n",
      "19                                                NaN  \n",
      "20                                                NaN  \n",
      "21                                                NaN  \n",
      "22                                                NaN  \n",
      "23                                                NaN  \n",
      "24                                                NaN  \n",
      "25                                                NaN  \n",
      "26                                                NaN  \n",
      "27                                                NaN  \n",
      "28                                                NaN  \n",
      "29                                                NaN  \n",
      "30                                                NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === Load Files ===\n",
    "pager_df = pd.read_excel(\"C:/Users/HP/Desktop/finalCopy of PagerDutyLog - Feb.xlsx\")\n",
    "holiday_df = pd.read_excel(\"C:/Users/HP/Desktop/Mindera India - Holiday List 2025.xlsx\")\n",
    "print(holiday_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "40f65fa0-154e-4adb-a28b-2cedbc1866cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== FINAL SUMMARY ==========\n",
      "\n",
      "=== Name: Ahalya Hegde ===\n",
      "Date Ranges Worked:\n",
      "   Tue, Feb 11 @ 09:00 To Mon, Feb 17 @ 09:00\n",
      "Total Worked  Weekday - 4 days, 0.00 hours | Weekends - 2 days\n",
      "Extra Hours  nan\n",
      "\n",
      "=== Name: Akash Dey ===\n",
      "Date Ranges Worked:\n",
      "   No shift data available.\n",
      "Total Worked  nan\n",
      "Extra Hours  Extra Weekday - 0 days, 0.00 hours | Extra Weekend - 0 days, 0.00 hours\n",
      "\n",
      "=== Name: Ayush Rajeev ===\n",
      "Date Ranges Worked:\n",
      "   Mon, Feb 03 @ 05:30 To Mon, Feb 10 @ 05:30\n",
      "Total Worked  Weekday - 5 days, 0.00 hours | Weekends - 2 days\n",
      "Extra Hours  Extra Weekday - 0 days, 1.00 hours | Extra Weekend - 0 days, 0.25 hours\n",
      "\n",
      "=== Name: Basudev Singh Munda ===\n",
      "Date Ranges Worked:\n",
      "   Mon, Feb 03 @ 09:00 To Tue, Feb 11 @ 09:00\n",
      "Total Worked  Weekday - 6 days, 0.00 hours | Weekends - 2 days\n",
      "Extra Hours  nan\n",
      "\n",
      "=== Name: Dolly Chahar ===\n",
      "Date Ranges Worked:\n",
      "   Mon, Feb 17 @ 09:00 To Mon, Feb 24 @ 09:00\n",
      "Total Worked  Weekday - 5 days, 0.00 hours | Weekends - 2 days\n",
      "Extra Hours  nan\n",
      "\n",
      "=== Name: Durai Ramalingam ===\n",
      "Date Ranges Worked:\n",
      "   Mon, Feb 24 @ 04:30 To Sat, Mar 01 @ 00:00\n",
      "   Mon, Feb 10 @ 04:30 To Mon, Feb 17 @ 04:30\n",
      "   Sat, Feb 01 @ 00:00 To Mon, Feb 03 @ 04:30\n",
      "Total Worked  Weekday - 10 days, 0.00 hours | Weekends - 4 days\n",
      "Extra Hours  Extra Weekday - 0 days, 0.50 hours | Extra Weekend - 0 days, 0.00 hours\n",
      "\n",
      "=== Name: Jithin Johnson ===\n",
      "Date Ranges Worked:\n",
      "   Mon, Feb 17 @ 04:30 To Mon, Feb 24 @ 04:30\n",
      "   Mon, Feb 03 @ 04:30 To Mon, Feb 10 @ 04:30\n",
      "Total Worked  Weekday - 10 days, 0.00 hours | Weekends - 4 days\n",
      "Extra Hours  Extra Weekday - 0 days, 0.00 hours | Extra Weekend - 0 days, 0.00 hours\n",
      "\n",
      "=== Name: Kapil Jugnu ===\n",
      "Date Ranges Worked:\n",
      "   Mon, Feb 17 @ 04:30 To Mon, Feb 24 @ 04:30\n",
      "Total Worked  Weekday - 5 days, 0.00 hours | Weekends - 2 days\n",
      "Extra Hours  Extra Weekday - 0 days, 1.33 hours | Extra Weekend - 0 days, 0.00 hours\n",
      "\n",
      "=== Name: Keerthivasan Kannan ===\n",
      "Date Ranges Worked:\n",
      "   Tue, Feb 11 @ 10:00 To Sun, Feb 16 @ 01:43\n",
      "   Sun, Feb 16 @ 11:45 To Tue, Feb 18 @ 10:00\n",
      "Total Worked  Weekday - 5 days, 0.00 hours | Weekends - 3 days\n",
      "Extra Hours  Extra Weekday - 0 days, 0.00 hours | Extra Weekend - 0 days, 1.17 hours\n",
      "\n",
      "=== Name: Muthumani Gurusamy ===\n",
      "Date Ranges Worked:\n",
      "   No shift data available.\n",
      "Total Worked  nan\n",
      "Extra Hours  Extra Weekday - 0 days, 0.00 hours | Extra Weekend - 0 days, 0.50 hours\n",
      "\n",
      "=== Name: Prakash Rajendran ===\n",
      "Date Ranges Worked:\n",
      "   Sat, Feb 01 @ 00:00 To Mon, Feb 03 @ 09:00\n",
      "Total Worked  Weekday - 0 days, 9.00 hours | Weekends - 2 days\n",
      "Extra Hours  nan\n",
      "\n",
      "=== Name: Sahil Kanojia ===\n",
      "Date Ranges Worked:\n",
      "   No shift data available.\n",
      "Total Worked  nan\n",
      "Extra Hours  Extra Weekday - 0 days, 0.00 hours | Extra Weekend - 0 days, 0.00 hours\n",
      "\n",
      "=== Name: akash dey ===\n",
      "Date Ranges Worked:\n",
      "   Sat, Feb 01 @ 00:00 To Mon, Feb 03 @ 04:30\n",
      "Total Worked  Weekday - 0 days, 4.50 hours | Weekends - 2 days\n",
      "Extra Hours  nan\n",
      "\n",
      "=== Name: ankit thakkar ===\n",
      "Date Ranges Worked:\n",
      "   Mon, Feb 10 @ 05:30 To Mon, Feb 17 @ 05:30\n",
      "Total Worked  Weekday - 5 days, 0.00 hours | Weekends - 2 days\n",
      "Extra Hours  Extra Weekday - 0 days, 0.33 hours | Extra Weekend - 0 days, 0.00 hours\n",
      "\n",
      "=== Name: muthumani gurusamy ===\n",
      "Date Ranges Worked:\n",
      "   Mon, Feb 24 @ 05:30 To Sat, Mar 01 @ 00:00\n",
      "Total Worked  Weekday - 4 days, 18.50 hours | Weekends - 0 days\n",
      "Extra Hours  nan\n",
      "\n",
      "=== Name: nirmalraja selvam ===\n",
      "Date Ranges Worked:\n",
      "   Mon, Feb 10 @ 04:30 To Mon, Feb 17 @ 04:30\n",
      "Total Worked  Weekday - 5 days, 0.00 hours | Weekends - 2 days\n",
      "Extra Hours  Extra Weekday - 0 days, 0.00 hours | Extra Weekend - 0 days, 0.00 hours\n",
      "\n",
      "=== Name: pavan kumarmantry ===\n",
      "Date Ranges Worked:\n",
      "   No shift data available.\n",
      "Total Worked  nan\n",
      "Extra Hours  Extra Weekday - 0 days, 0.00 hours | Extra Weekend - 0 days, 0.00 hours\n",
      "\n",
      "=== Name: sahil kanojia ===\n",
      "Date Ranges Worked:\n",
      "   Mon, Feb 03 @ 04:30 To Mon, Feb 10 @ 04:30\n",
      "Total Worked  Weekday - 5 days, 0.00 hours | Weekends - 2 days\n",
      "Extra Hours  nan\n",
      "\n",
      "=== Name: vamshi bandla ===\n",
      "Date Ranges Worked:\n",
      "   Mon, Feb 24 @ 09:00 To Sat, Mar 01 @ 00:00\n",
      "Total Worked  Weekday - 4 days, 15.00 hours | Weekends - 0 days\n",
      "Extra Hours  nan\n",
      "\n",
      " Saved to 'Final_PagerDuty_Combined_Summary.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import calendar\n",
    "\n",
    "# === STEP 1: Load Shift Log Data ===\n",
    "df_log = pd.read_excel(\"C:/Users/HP/Desktop/finalCopy of PagerDutyLog - Feb.xlsx\")\n",
    "\n",
    "# === STEP 2: Format From-To DateTime Range ===\n",
    "df_log['From DateTime'] = pd.to_datetime(df_log['From Date'].astype(str) + ' ' + df_log['From Time'].astype(str))\n",
    "df_log['To DateTime'] = pd.to_datetime(df_log['To Date'].astype(str) + ' ' + df_log['To Time'].astype(str))\n",
    "\n",
    "df_log['Formatted Range'] = df_log['From DateTime'].dt.strftime('%a, %b %d @ %H:%M') + \" To \" + df_log['To DateTime'].dt.strftime('%a, %b %d @ %H:%M')\n",
    "\n",
    "# === STEP 3: Calculate Shift Duration in Weekdays/Weekends ===\n",
    "def calculate_day_hour_summary(row):\n",
    "    from_dt = datetime.combine(row['From Date'], row['From Time'])\n",
    "    to_dt = datetime.combine(row['To Date'], row['To Time'])\n",
    "\n",
    "    weekday_hours = 0.0\n",
    "    weekend_days = 0\n",
    "    weekday_days = 0\n",
    "    current = from_dt\n",
    "    while current <= to_dt:\n",
    "        next_dt = min(to_dt, datetime.combine(current.date(), datetime.max.time()))\n",
    "        duration_hours = (next_dt - current).total_seconds() / 3600.0\n",
    "\n",
    "        if calendar.weekday(current.year, current.month, current.day) < 5:\n",
    "            weekday_hours += duration_hours\n",
    "        else:\n",
    "            weekend_days += 1\n",
    "\n",
    "        current = next_dt + timedelta(seconds=1)\n",
    "\n",
    "    weekday_days = int(weekday_hours // 24)\n",
    "    weekday_rem_hours = round(weekday_hours % 24, 2)\n",
    "    if weekday_rem_hours == 24.0:\n",
    "        weekday_days += 1\n",
    "        weekday_rem_hours = 0.0\n",
    "\n",
    "    return pd.Series([weekday_days, weekday_rem_hours, weekend_days])\n",
    "\n",
    "df_log[['Weekday Days', 'Weekday Hours', 'Weekend Days']] = df_log.apply(calculate_day_hour_summary, axis=1)\n",
    "\n",
    "# Group by Name and summarize duration\n",
    "duration_summary = df_log.groupby('Name')[['Weekday Days', 'Weekday Hours', 'Weekend Days']].sum().reset_index()\n",
    "\n",
    "# Normalize weekday hours into days\n",
    "def normalize_hours(row):\n",
    "    additional_days = int(row['Weekday Hours'] // 24)\n",
    "    row['Weekday Days'] += additional_days\n",
    "    row['Weekday Hours'] = round(row['Weekday Hours'] % 24, 2)\n",
    "    return row\n",
    "\n",
    "duration_summary = duration_summary.apply(normalize_hours, axis=1)\n",
    "\n",
    "# Format duration summary\n",
    "def format_duration(row):\n",
    "    return \"Weekday - {} days, {:.2f} hours | Weekends - {} days\".format(\n",
    "        int(row['Weekday Days']), row['Weekday Hours'], int(row['Weekend Days'])\n",
    "    )\n",
    "\n",
    "duration_summary['Worked Summary'] = duration_summary.apply(format_duration, axis=1)\n",
    "\n",
    "# === STEP 4: Load Extra Hours File ===\n",
    "df_extra = pd.read_excel(\"C:/Users/HP/Desktop/finalCopy of ExtraHoursLog - Feb.xlsx\")  # Your second file\n",
    "\n",
    "# === STEP 5: Convert Minutes to Days/Hours ===\n",
    "def convert_to_calendar_time(row):\n",
    "    weekday_minutes = row['Total Minutes Weekdays']\n",
    "    weekend_minutes = row['Total Minutes Weekends']\n",
    "\n",
    "    weekday_hours = weekday_minutes / 60 if pd.notnull(weekday_minutes) else 0\n",
    "    weekend_hours = weekend_minutes / 60 if pd.notnull(weekend_minutes) else 0\n",
    "\n",
    "    weekday_days = int(weekday_hours // 24)\n",
    "    weekday_remaining_hours = round(weekday_hours % 24, 2)\n",
    "\n",
    "    weekend_days = int(weekend_hours // 24)\n",
    "    weekend_remaining_hours = round(weekend_hours % 24, 2)\n",
    "\n",
    "    return pd.Series({\n",
    "        'Extra Weekday Days': weekday_days,\n",
    "        'Extra Weekday Hours': weekday_remaining_hours,\n",
    "        'Extra Weekend Days': weekend_days,\n",
    "        'Extra Weekend Hours': weekend_remaining_hours\n",
    "    })\n",
    "\n",
    "converted_extra = df_extra.apply(convert_to_calendar_time, axis=1)\n",
    "df_extra_combined = pd.concat([df_extra['Name'], converted_extra], axis=1)\n",
    "\n",
    "# Group by Name\n",
    "extra_summary = df_extra_combined.groupby('Name', as_index=False).sum()\n",
    "\n",
    "# Format extra summary\n",
    "def format_extra(row):\n",
    "    return \"Extra Weekday - {} days, {:.2f} hours | Extra Weekend - {} days, {:.2f} hours\".format(\n",
    "        int(row['Extra Weekday Days']), row['Extra Weekday Hours'],\n",
    "        int(row['Extra Weekend Days']), row['Extra Weekend Hours']\n",
    "    )\n",
    "\n",
    "extra_summary['Extra Hours Summary'] = extra_summary.apply(format_extra, axis=1)\n",
    "\n",
    "# === STEP 6: Format Shift Ranges per Name ===\n",
    "shifts_summary = df_log.groupby('Name')['Formatted Range'].apply(list).reset_index()\n",
    "\n",
    "# === STEP 7: Merge All Data ===\n",
    "final = duration_summary.merge(extra_summary, on='Name', how='outer')\n",
    "final = final.merge(shifts_summary, on='Name', how='outer')\n",
    "\n",
    "# === STEP 8: Final Display ===\n",
    "print(\"\\n========== FINAL SUMMARY ==========\\n\")\n",
    "for _, row in final.iterrows():\n",
    "    print(f\"=== Name: {row['Name']} ===\")\n",
    "    if isinstance(row['Formatted Range'], list):\n",
    "        for shift in row['Formatted Range']:\n",
    "            print(f\"   {shift}\")\n",
    "    else:\n",
    "        print(\"   No shift data available.\")\n",
    "    print(\"Total Worked \", row.get('Worked Summary', 'N/A'))\n",
    "    print(\"Extra Hours \", row.get('Extra Hours Summary', 'N/A'))\n",
    "    print()\n",
    "\n",
    "# === STEP 9: Export to Excel ===\n",
    "final.to_excel(\"Final_PagerDuty_Combined_Summary.xlsx\", index=False)\n",
    "print(\" Saved to 'Final_PagerDuty_Combined_Summary.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bfca2167-08b8-4a5e-9dbb-f926accb88e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Name  Weekday Days_Summary  Weekday Hours_Summary  \\\n",
      "4     Durai Ramalingam                     9                   0.00   \n",
      "7  Keerthivasan Kannan                     4                  23.75   \n",
      "8   Muthumani Gurusamy                     0                   0.00   \n",
      "\n",
      "   Weekday Days_Oncall  Weekday Hours_Oncall  Weekend Days_Summary  \\\n",
      "4                   10                   0.0                     5   \n",
      "7                    5                   0.0                     1   \n",
      "8                    4                  18.5                     0   \n",
      "\n",
      "   Weekend Hours_Summary  Weekend Days_Oncall  Weekend Hours_Oncall  \n",
      "4                   0.00                    4                  0.00  \n",
      "7                  14.22                    1                 13.97  \n",
      "8                   0.00                    0                  0.00  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the Excel files\n",
    "file_oncall = \"C:/Users/HP/Desktop/Final_Oncall_Data_Feb (1)(AutoRecovered).xlsx\"\n",
    "file_summary = \"C:/Users/HP/Desktop/Final_Summary_Output_FEB.xlsx\"\n",
    "\n",
    "df_oncall = pd.read_excel(file_oncall)\n",
    "df_summary = pd.read_excel(file_summary)\n",
    "\n",
    "# Helper function to parse durations like \"Weekdays - 5 days, 0.00 hours\\nWeekends/Holidays - 2 days, 5.50 hours\"\n",
    "def parse_duration(text):\n",
    "    match = re.findall(r'(\\d+)\\s+days?,\\s*([\\d.]+)\\s+hours?', str(text))\n",
    "    if len(match) >= 2:\n",
    "        weekday = (int(match[0][0]), float(match[0][1]))\n",
    "        weekend = (int(match[1][0]), float(match[1][1]))\n",
    "        return weekday, weekend\n",
    "    return (0, 0.0), (0, 0.0)\n",
    "\n",
    "# Parse 'W or H' column in Oncall data\n",
    "oncall_parsed = []\n",
    "for _, row in df_oncall.iterrows():\n",
    "    name = row['Employee name']\n",
    "    wh_text = str(row.get('W or H', ''))\n",
    "    weekday, weekend = parse_duration(wh_text)\n",
    "    oncall_parsed.append({\n",
    "        'Name': name.strip(),\n",
    "        'Weekday Days_Oncall': weekday[0],\n",
    "        'Weekday Hours_Oncall': weekday[1],\n",
    "        'Weekend Days_Oncall': weekend[0],\n",
    "        'Weekend Hours_Oncall': weekend[1]\n",
    "    })\n",
    "\n",
    "df_oncall_cleaned = pd.DataFrame(oncall_parsed)\n",
    "\n",
    "# Helper to parse \"5 days, 0.00 hours\"\n",
    "def extract_days_hours(text):\n",
    "    match = re.match(r\"(\\d+)\\s+days?,\\s*([\\d.]+)\\s+hours?\", str(text).strip())\n",
    "    if match:\n",
    "        return int(match[1]), float(match[2])\n",
    "    return 0, 0.0\n",
    "\n",
    "# Parse 'Weekday Count' and 'Weekend/Holiday Count' in Summary data\n",
    "df_summary_cleaned = df_summary[['Name', 'Weekday Count', 'Weekend/Holiday Count']].copy()\n",
    "df_summary_cleaned['Weekday Days_Summary'], df_summary_cleaned['Weekday Hours_Summary'] = zip(\n",
    "    *df_summary_cleaned['Weekday Count'].map(extract_days_hours)\n",
    ")\n",
    "df_summary_cleaned['Weekend Days_Summary'], df_summary_cleaned['Weekend Hours_Summary'] = zip(\n",
    "    *df_summary_cleaned['Weekend/Holiday Count'].map(extract_days_hours)\n",
    ")\n",
    "\n",
    "# Merge both dataframes on Name\n",
    "df_merged = pd.merge(df_summary_cleaned, df_oncall_cleaned, on='Name', how='inner')\n",
    "\n",
    "# Filter mismatches\n",
    "mismatches = df_merged[\n",
    "    (df_merged['Weekday Days_Summary'] != df_merged['Weekday Days_Oncall']) |\n",
    "    (df_merged['Weekday Hours_Summary'] != df_merged['Weekday Hours_Oncall']) |\n",
    "    (df_merged['Weekend Days_Summary'] != df_merged['Weekend Days_Oncall']) |\n",
    "    (df_merged['Weekend Hours_Summary'] != df_merged['Weekend Hours_Oncall'])\n",
    "]\n",
    "\n",
    "# Show only relevant columns\n",
    "result = mismatches[[\n",
    "    'Name',\n",
    "    'Weekday Days_Summary', 'Weekday Hours_Summary',\n",
    "    'Weekday Days_Oncall', 'Weekday Hours_Oncall',\n",
    "    'Weekend Days_Summary', 'Weekend Hours_Summary',\n",
    "    'Weekend Days_Oncall', 'Weekend Hours_Oncall'\n",
    "]]\n",
    "\n",
    "# Display result\n",
    "print(result)\n",
    "\n",
    "# Optionally, save to Excel\n",
    "result.to_excel(\"Mismatched_Durations_Report.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "572f33cd-c5da-4266-a53d-303eacbc0ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Comparison complete. Results saved to 'Oncall_vs_Summary_Comparison.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load files\n",
    "oncall_file = \"C:/Users/HP/Desktop/Final_Oncall_Data_Feb (1)(AutoRecovered).xlsx\"\n",
    "summary_file = \"C:/Users/HP/Desktop/Final_Summary_Output_FEB.xlsx\"\n",
    "\n",
    "df_oncall = pd.read_excel(oncall_file)\n",
    "df_summary = pd.read_excel(summary_file)\n",
    "\n",
    "# Standardize name columns\n",
    "df_oncall['Employee name'] = df_oncall['Employee name'].str.strip()\n",
    "df_summary['Name'] = df_summary['Name'].str.strip()\n",
    "\n",
    "# Function to extract durations from \"W or H\" column\n",
    "def extract_durations(cell):\n",
    "    result = {\n",
    "        \"Weekday_Days\": 0, \"Weekday_Hours\": 0.0,\n",
    "        \"Weekend_Days\": 0, \"Weekend_Hours\": 0.0,\n",
    "        \"Extra_Weekday_Hours\": 0.0,\n",
    "        \"Extra_Weekend_Hours\": 0.0\n",
    "    }\n",
    "    if not isinstance(cell, str):\n",
    "        return result\n",
    "\n",
    "    # Extract Weekdays\n",
    "    match = re.search(r\"Weekdays\\s*-\\s*(\\d+)\\s*days,\\s*([\\d.]+)\\s*hours\", cell)\n",
    "    if match:\n",
    "        result[\"Weekday_Days\"] = int(match.group(1))\n",
    "        result[\"Weekday_Hours\"] = float(match.group(2))\n",
    "\n",
    "    # Extract Weekends/Holidays\n",
    "    match = re.search(r\"Weekends/Holidays\\s*-\\s*(\\d+)\\s*days,\\s*([\\d.]+)\\s*hours\", cell)\n",
    "    if match:\n",
    "        result[\"Weekend_Days\"] = int(match.group(1))\n",
    "        result[\"Weekend_Hours\"] = float(match.group(2))\n",
    "\n",
    "    # Extract Extra Weekday\n",
    "    match = re.search(r\"Extra\\s*-\\s*Weekdays\\s*-\\s*([\\d.]+)\\s*hours\", cell)\n",
    "    if match:\n",
    "        result[\"Extra_Weekday_Hours\"] = float(match.group(1))\n",
    "\n",
    "    # Extract Extra Weekend\n",
    "    match = re.search(r\"Extra\\s*-\\s*.*?Weekends/Holidays\\s*-\\s*([\\d.]+)\\s*hours\", cell)\n",
    "    if match:\n",
    "        result[\"Extra_Weekend_Hours\"] = float(match.group(1))\n",
    "\n",
    "    return result\n",
    "\n",
    "# Apply extraction\n",
    "duration_data = df_oncall[\"W or H\"].apply(extract_durations)\n",
    "duration_df = pd.DataFrame(duration_data.tolist())\n",
    "df_oncall = pd.concat([df_oncall[['Employee name']], duration_df], axis=1)\n",
    "\n",
    "# Merge with summary\n",
    "df_merged = pd.merge(\n",
    "    df_oncall,\n",
    "    df_summary,\n",
    "    left_on=\"Employee name\",\n",
    "    right_on=\"Name\",\n",
    "    how=\"outer\"\n",
    ")\n",
    "\n",
    "# Convert columns from summary to numeric\n",
    "numeric_columns = [\n",
    "    'Weekday Count', 'Weekend/Holiday Count',\n",
    "    'ExtraWeekday Hours', 'ExtraWeekendHoliday Hours'\n",
    "]\n",
    "\n",
    "for col in numeric_columns:\n",
    "    df_merged[col] = pd.to_numeric(df_merged[col], errors='coerce')\n",
    "\n",
    "# Fill missing extracted values with 0\n",
    "df_merged[['Weekday_Days', 'Weekend_Days', 'Extra_Weekday_Hours', 'Extra_Weekend_Hours']] = (\n",
    "    df_merged[['Weekday_Days', 'Weekend_Days', 'Extra_Weekday_Hours', 'Extra_Weekend_Hours']].fillna(0)\n",
    ")\n",
    "\n",
    "# Compute differences\n",
    "df_merged['Weekday_Days_Diff'] = df_merged['Weekday_Days'] - df_merged['Weekday Count']\n",
    "df_merged['Weekend_Days_Diff'] = df_merged['Weekend_Days'] - df_merged['Weekend/Holiday Count']\n",
    "df_merged['Extra_Weekday_Hours_Diff'] = df_merged['Extra_Weekday_Hours'] - df_merged['ExtraWeekday Hours']\n",
    "df_merged['Extra_Weekend_Hours_Diff'] = df_merged['Extra_Weekend_Hours'] - df_merged['ExtraWeekendHoliday Hours']\n",
    "\n",
    "# Save output\n",
    "df_merged.to_excel(\"Oncall_vs_Summary_Comparison.xlsx\", index=False)\n",
    "\n",
    "print(\" Comparison complete. Results saved to 'Oncall_vs_Summary_Comparison.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "60cba577-e16a-400b-93e1-ae968ec0b8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Differences for Keerthivasan Kannan:\n",
      "  - Weekday Days  Oncall: 5 | Summary: nan\n",
      "  - Weekend Days  Oncall: 1 | Summary: nan\n",
      "  - Extra Weekday Hours  Oncall: 0.0 | Summary: nan\n",
      "  - Extra Weekend Hours  Oncall: 0.0 | Summary: nan\n",
      "\n",
      " Differences for Ayush Rajeev:\n",
      "  - Weekday Days  Oncall: 5 | Summary: nan\n",
      "  - Weekend Days  Oncall: 2 | Summary: nan\n",
      "  - Extra Weekday Hours  Oncall: 0.0 | Summary: nan\n",
      "  - Extra Weekend Hours  Oncall: 0.0 | Summary: nan\n",
      "\n",
      " Differences for Muthumani Gurusamy:\n",
      "  - Weekday Days  Oncall: 4 | Summary: nan\n",
      "  - Weekend Days  Oncall: 0 | Summary: nan\n",
      "  - Extra Weekday Hours  Oncall: 0.0 | Summary: nan\n",
      "  - Extra Weekend Hours  Oncall: 0.0 | Summary: nan\n",
      "\n",
      " Differences for Durai Ramalingam:\n",
      "  - Weekday Days  Oncall: 10 | Summary: nan\n",
      "  - Weekend Days  Oncall: 4 | Summary: nan\n",
      "  - Extra Weekday Hours  Oncall: 0.0 | Summary: nan\n",
      "  - Extra Weekend Hours  Oncall: 0.0 | Summary: nan\n",
      "\n",
      " Differences for Jithin Johnson:\n",
      "  - Weekday Days  Oncall: 10 | Summary: nan\n",
      "  - Weekend Days  Oncall: 4 | Summary: nan\n",
      "  - Extra Weekday Hours  Oncall: 0.0 | Summary: nan\n",
      "  - Extra Weekend Hours  Oncall: 0.0 | Summary: nan\n",
      "\n",
      " Differences for Ahalya Hegde:\n",
      "  - Weekday Days  Oncall: 4 | Summary: nan\n",
      "  - Weekend Days  Oncall: 2 | Summary: nan\n",
      "  - Extra Weekday Hours  Oncall: 0.0 | Summary: nan\n",
      "  - Extra Weekend Hours  Oncall: 0.0 | Summary: nan\n",
      "\n",
      " Differences for Basudev Singh Munda:\n",
      "  - Weekday Days  Oncall: 6 | Summary: nan\n",
      "  - Weekend Days  Oncall: 2 | Summary: nan\n",
      "  - Extra Weekday Hours  Oncall: 0.0 | Summary: nan\n",
      "  - Extra Weekend Hours  Oncall: 0.0 | Summary: nan\n",
      "\n",
      " Differences for Dolly Chahar:\n",
      "  - Weekday Days  Oncall: 5 | Summary: nan\n",
      "  - Weekend Days  Oncall: 2 | Summary: nan\n",
      "  - Extra Weekday Hours  Oncall: 0.0 | Summary: nan\n",
      "  - Extra Weekend Hours  Oncall: 0.0 | Summary: nan\n",
      "\n",
      " Differences for Prakash Rajendran:\n",
      "  - Weekday Days  Oncall: 0 | Summary: nan\n",
      "  - Weekend Days  Oncall: 2 | Summary: nan\n",
      "  - Extra Weekday Hours  Oncall: 0.0 | Summary: nan\n",
      "  - Extra Weekend Hours  Oncall: 0.0 | Summary: nan\n",
      "\n",
      " Differences for Kapil Jugnu:\n",
      "  - Weekday Days  Oncall: 5 | Summary: nan\n",
      "  - Weekend Days  Oncall: 2 | Summary: nan\n",
      "  - Extra Weekday Hours  Oncall: 0.0 | Summary: nan\n",
      "  - Extra Weekend Hours  Oncall: 0.0 | Summary: nan\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load files\n",
    "oncall_file = \"C:/Users/HP/Desktop/Final_Oncall_Data_Feb (1)(AutoRecovered).xlsx\"\n",
    "summary_file = \"C:/Users/HP/Desktop/Final_Summary_Output_FEB.xlsx\"\n",
    "\n",
    "\n",
    "df_oncall = pd.read_excel(oncall_file)\n",
    "df_summary = pd.read_excel(summary_file)\n",
    "\n",
    "# Standardize name columns\n",
    "df_oncall['Employee name'] = df_oncall['Employee name'].str.strip()\n",
    "df_summary['Name'] = df_summary['Name'].str.strip()\n",
    "\n",
    "# Function to extract durations from \"W or H\" column\n",
    "def extract_durations(cell):\n",
    "    result = {\n",
    "        \"Weekday_Days\": 0, \"Weekday_Hours\": 0.0,\n",
    "        \"Weekend_Days\": 0, \"Weekend_Hours\": 0.0,\n",
    "        \"Extra_Weekday_Hours\": 0.0,\n",
    "        \"Extra_Weekend_Hours\": 0.0\n",
    "    }\n",
    "    if not isinstance(cell, str):\n",
    "        return result\n",
    "\n",
    "    match = re.search(r\"Weekdays\\s*-\\s*(\\d+)\\s*days,\\s*([\\d.]+)\\s*hours\", cell)\n",
    "    if match:\n",
    "        result[\"Weekday_Days\"] = int(match.group(1))\n",
    "        result[\"Weekday_Hours\"] = float(match.group(2))\n",
    "\n",
    "    match = re.search(r\"Weekends/Holidays\\s*-\\s*(\\d+)\\s*days,\\s*([\\d.]+)\\s*hours\", cell)\n",
    "    if match:\n",
    "        result[\"Weekend_Days\"] = int(match.group(1))\n",
    "        result[\"Weekend_Hours\"] = float(match.group(2))\n",
    "\n",
    "    match = re.search(r\"Extra\\s*-\\s*Weekdays\\s*-\\s*([\\d.]+)\\s*hours\", cell)\n",
    "    if match:\n",
    "        result[\"Extra_Weekday_Hours\"] = float(match.group(1))\n",
    "\n",
    "    match = re.search(r\"Extra\\s*-\\s*.*?Weekends/Holidays\\s*-\\s*([\\d.]+)\\s*hours\", cell)\n",
    "    if match:\n",
    "        result[\"Extra_Weekend_Hours\"] = float(match.group(1))\n",
    "\n",
    "    return result\n",
    "\n",
    "# Apply extraction\n",
    "duration_data = df_oncall[\"W or H\"].apply(extract_durations)\n",
    "duration_df = pd.DataFrame(duration_data.tolist())\n",
    "df_oncall = pd.concat([df_oncall[['Employee name']], duration_df], axis=1)\n",
    "\n",
    "# Merge with summary\n",
    "df_merged = pd.merge(\n",
    "    df_oncall,\n",
    "    df_summary,\n",
    "    left_on=\"Employee name\",\n",
    "    right_on=\"Name\",\n",
    "    how=\"inner\"  # only matched names\n",
    ")\n",
    "\n",
    "# Ensure numerical columns are in proper format\n",
    "numeric_columns = ['Weekday Count', 'Weekend/Holiday Count', 'ExtraWeekday Hours', 'ExtraWeekendHoliday Hours']\n",
    "for col in numeric_columns:\n",
    "    df_merged[col] = pd.to_numeric(df_merged[col], errors='coerce')\n",
    "\n",
    "df_merged[['Weekday_Days', 'Weekend_Days', 'Extra_Weekday_Hours', 'Extra_Weekend_Hours']] = (\n",
    "    df_merged[['Weekday_Days', 'Weekend_Days', 'Extra_Weekday_Hours', 'Extra_Weekend_Hours']].fillna(0)\n",
    ")\n",
    "\n",
    "# Print only the mismatches\n",
    "for _, row in df_merged.iterrows():\n",
    "    diffs = []\n",
    "    if row['Weekday_Days'] != row['Weekday Count']:\n",
    "        diffs.append(f\"Weekday Days  Oncall: {row['Weekday_Days']} | Summary: {row['Weekday Count']}\")\n",
    "    if row['Weekend_Days'] != row['Weekend/Holiday Count']:\n",
    "        diffs.append(f\"Weekend Days  Oncall: {row['Weekend_Days']} | Summary: {row['Weekend/Holiday Count']}\")\n",
    "    if round(row['Extra_Weekday_Hours'], 2) != round(row['ExtraWeekday Hours'], 2):\n",
    "        diffs.append(f\"Extra Weekday Hours  Oncall: {row['Extra_Weekday_Hours']} | Summary: {row['ExtraWeekday Hours']}\")\n",
    "    if round(row['Extra_Weekend_Hours'], 2) != round(row['ExtraWeekendHoliday Hours'], 2):\n",
    "        diffs.append(f\"Extra Weekend Hours  Oncall: {row['Extra_Weekend_Hours']} | Summary: {row['ExtraWeekendHoliday Hours']}\")\n",
    "    \n",
    "    if diffs:\n",
    "        print(f\"\\n Differences for {row['Employee name']}:\")\n",
    "        for d in diffs:\n",
    "            print(\"  -\", d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "78614ff5-fdfd-4436-800d-60c75f96cdf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Employee name  Weekday_Day_Diff  Weekday_Hour_Diff  Weekend_Day_Diff  \\\n",
      "0  Keerthivasan Kannan               1.0             -23.75               0.0   \n",
      "1         Ayush Rajeev               0.0               0.00               0.0   \n",
      "2   Muthumani Gurusamy               4.0              18.50               0.0   \n",
      "3     Durai Ramalingam               1.0               0.00              -1.0   \n",
      "4       Jithin Johnson               0.0               0.00               0.0   \n",
      "5         Ahalya Hegde               0.0               0.00               0.0   \n",
      "6  Basudev Singh Munda               0.0               0.00               0.0   \n",
      "7         Dolly Chahar               0.0               0.00               0.0   \n",
      "8    Prakash Rajendran               0.0               0.00               0.0   \n",
      "9          Kapil Jugnu               0.0               0.00               0.0   \n",
      "\n",
      "   Weekend_Hour_Diff  Extra_WD_Hour_Diff  Extra_WE_Hour_Diff  \n",
      "0              -0.25               -1.17                1.17  \n",
      "1               0.00                0.25               -0.25  \n",
      "2               0.00               -0.50                0.00  \n",
      "3               0.00                0.00                0.00  \n",
      "4               0.00                0.00                0.00  \n",
      "5               0.00                0.00                0.00  \n",
      "6               0.00                0.00                0.00  \n",
      "7               0.00                0.00                0.00  \n",
      "8               0.00                0.00                0.00  \n",
      "9               0.00                0.00                0.00  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1.  Load both workbooks\n",
    "# ------------------------------------------------------------------\n",
    "ONCALL_PATH  = \"C:/Users/HP/Desktop/Final_Oncall_Data_Feb (1)(AutoRecovered).xlsx\"\n",
    "SUMMARY_PATH = \"C:/Users/HP/Desktop/Final_Summary_Output_FEB.xlsx\"\n",
    "\n",
    "oncall_df  = pd.read_excel(ONCALL_PATH)\n",
    "summary_df = pd.read_excel(SUMMARY_PATH)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2.  Parser for the messy W or H column\n",
    "# ------------------------------------------------------------------\n",
    "def parse_wh_cell(text: str) -> pd.Series:\n",
    "    \"\"\"\n",
    "    From one WorH cell, return:\n",
    "      Weekday_Days, Weekday_Hours,\n",
    "      Weekend_Days, Weekend_Hours,\n",
    "      Extra_Weekday_Hours, Extra_Weekend_Hours\n",
    "    \"\"\"\n",
    "    text = str(text)\n",
    "\n",
    "    # Defaults\n",
    "    wd_days = wd_hours = we_days = we_hours = 0.0\n",
    "    ex_wd_hours = ex_we_hours = 0.0\n",
    "\n",
    "    # --- main weekday line --------------------------------------------------\n",
    "    m = re.search(\n",
    "        r\"Weekdays?\\s*-\\s*(\\d+)\\s+days?,?\\s*([\\d.]+)\\s+hours?\",\n",
    "        text,\n",
    "        flags=re.I,\n",
    "    )\n",
    "    if m:\n",
    "        wd_days, wd_hours = int(m.group(1)), float(m.group(2))\n",
    "\n",
    "    # --- main weekend / holiday line ----------------------------------------\n",
    "    m = re.search(\n",
    "        r\"Weekends?/Holidays?\\s*-\\s*(\\d+)\\s+days?,?\\s*([\\d.]+)\\s+hours?\",\n",
    "        text,\n",
    "        flags=re.I,\n",
    "    )\n",
    "    if m:\n",
    "        we_days, we_hours = int(m.group(1)), float(m.group(2))\n",
    "\n",
    "    # --- extra hours block ---------------------------------------------------\n",
    "    # Robust to arbitrary spacing / line breaks\n",
    "    m = re.search(\n",
    "        r\"Extra\\s+hours.*?Weekday\\s*=\\s*([\\d.]+)\\s+hours?\",\n",
    "        text,\n",
    "        flags=re.I | re.S,\n",
    "    )\n",
    "    if m:\n",
    "        ex_wd_hours = float(m.group(1))\n",
    "\n",
    "    m = re.search(\n",
    "        r\"Extra\\s+hours.*?Weekend/Holidays\\s*=\\s*([\\d.]+)\\s+hours?\",\n",
    "        text,\n",
    "        flags=re.I | re.S,\n",
    "    )\n",
    "    if m:\n",
    "        ex_we_hours = float(m.group(1))\n",
    "\n",
    "    return pd.Series(\n",
    "        [\n",
    "            wd_days, wd_hours,\n",
    "            we_days, we_hours,\n",
    "            ex_wd_hours, ex_we_hours,\n",
    "        ],\n",
    "        index=[\n",
    "            \"Weekday_Days\", \"Weekday_Hours\",\n",
    "            \"Weekend_Days\", \"Weekend_Hours\",\n",
    "            \"Extra_Weekday_Hours\", \"Extra_Weekend_Hours\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "# Apply to every row\n",
    "oncall_df = oncall_df.join(oncall_df[\"W or H\"].apply(parse_wh_cell))\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3.  Parse the alreadystructured columns in the summary file\n",
    "# ------------------------------------------------------------------\n",
    "def parse_days_hours(cell: str) -> tuple[int, float]:\n",
    "    \"\"\"\n",
    "    Convert \"7 days, 3.25 hours\"  (7, 3.25)\n",
    "    \"\"\"\n",
    "    m = re.match(r\"\\s*(\\d+)\\s+days?,\\s*([\\d.]+)\\s+hours?\", str(cell))\n",
    "    return (int(m.group(1)), float(m.group(2))) if m else (0, 0.0)\n",
    "\n",
    "def parse_hours_only(cell: str) -> float:\n",
    "    \"\"\"\n",
    "    Convert \"1.50 hours\"  1.50\n",
    "    \"\"\"\n",
    "    m = re.match(r\"\\s*([\\d.]+)\\s+hours?\", str(cell))\n",
    "    return float(m.group(1)) if m else 0.0\n",
    "\n",
    "summary_df[[\"Sum_WD_Days\", \"Sum_WD_Hours\"]] = (\n",
    "    summary_df[\"Weekday Count\"].apply(parse_days_hours).apply(pd.Series)\n",
    ")\n",
    "summary_df[[\"Sum_WE_Days\", \"Sum_WE_Hours\"]] = (\n",
    "    summary_df[\"Weekend/Holiday Count\"].apply(parse_days_hours).apply(pd.Series)\n",
    ")\n",
    "summary_df[\"Sum_Extra_WD_Hours\"] = summary_df[\"ExtraWeekday Hours\"].apply(parse_hours_only)\n",
    "summary_df[\"Sum_Extra_WE_Hours\"] = summary_df[\"ExtraWeekendHoliday Hours\"].apply(parse_hours_only)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4.  Merge on employee name\n",
    "# ------------------------------------------------------------------\n",
    "merged = oncall_df.merge(\n",
    "    summary_df,\n",
    "    left_on=\"Employee name\",\n",
    "    right_on=\"Name\",\n",
    "    how=\"inner\",\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 5.  Compute the deltas\n",
    "# ------------------------------------------------------------------\n",
    "merged[\"Weekday_Day_Diff\"]   = merged[\"Weekday_Days\"]        - merged[\"Sum_WD_Days\"]\n",
    "merged[\"Weekday_Hour_Diff\"]  = merged[\"Weekday_Hours\"]       - merged[\"Sum_WD_Hours\"]\n",
    "merged[\"Weekend_Day_Diff\"]   = merged[\"Weekend_Days\"]        - merged[\"Sum_WE_Days\"]\n",
    "merged[\"Weekend_Hour_Diff\"]  = merged[\"Weekend_Hours\"]       - merged[\"Sum_WE_Hours\"]\n",
    "merged[\"Extra_WD_Hour_Diff\"] = merged[\"Extra_Weekday_Hours\"] - merged[\"Sum_Extra_WD_Hours\"]\n",
    "merged[\"Extra_WE_Hour_Diff\"] = merged[\"Extra_Weekend_Hours\"] - merged[\"Sum_Extra_WE_Hours\"]\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 6.  Slice the columns you care about\n",
    "# ------------------------------------------------------------------\n",
    "diff_output = merged[\n",
    "    [\n",
    "        \"Employee name\",\n",
    "        \"Weekday_Day_Diff\", \"Weekday_Hour_Diff\",\n",
    "        \"Weekend_Day_Diff\", \"Weekend_Hour_Diff\",\n",
    "        \"Extra_WD_Hour_Diff\", \"Extra_WE_Hour_Diff\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 7.  Save or display\n",
    "# ------------------------------------------------------------------\n",
    "# Save to Excel if you like:\n",
    "# diff_output.to_excel(\"/mnt/data/oncall_vs_summary_diffs.xlsx\", index=False)\n",
    "# print(\"Saved: oncall_vs_summary_diffs.xlsx\")\n",
    "\n",
    "print(diff_output)     # quick look in the console\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a5080d3e-39ee-461a-8406-5e52bbd01e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Employee name, Weekday_Day_Diff, Weekday_Hour_Diff, Weekend_Day_Diff, Weekend_Hour_Diff, Extra_WD_Hour_Diff, Extra_WE_Hour_Diff]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1.  Load both workbooks\n",
    "# ------------------------------------------------------------------\n",
    "ONCALL_PATH  = \"C:/Users/HP/Desktop/Final_Oncall_Data_Feb (1)(AutoRecovered).xlsx\"\n",
    "SUMMARY_PATH = \"C:/Users/HP/Desktop/Final_Summary_Output_FEB.xlsx\"\n",
    "\n",
    "oncall_df  = pd.read_excel(ONCALL_PATH)\n",
    "summary_df = pd.read_excel(SUMMARY_PATH)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2.  Parser for the messy W or H column\n",
    "# ------------------------------------------------------------------\n",
    "def parse_wh_cell(text: str) -> pd.Series:\n",
    "    \"\"\"\n",
    "    From one WorH cell, return:\n",
    "      Weekday_Days, Weekday_Hours,\n",
    "      Weekend_Days, Weekend_Hours,\n",
    "      Extra_Weekday_Hours, Extra_Weekend_Hours\n",
    "    \"\"\"\n",
    "    text = str(text)\n",
    "\n",
    "    # Defaults\n",
    "    wd_days = wd_hours = we_days = we_hours = 0.0\n",
    "    ex_wd_hours = ex_we_hours = 0.0\n",
    "\n",
    "    # --- main weekday line --------------------------------------------------\n",
    "    m = re.search(\n",
    "        r\"Weekdays?\\s*-\\s*(\\d+)\\s+days?,?\\s*([\\d.]+)\\s+hours?\",\n",
    "        text, flags=re.I\n",
    "    )\n",
    "    if m:\n",
    "        wd_days, wd_hours = int(m.group(1)), float(m.group(2))\n",
    "\n",
    "    # --- main weekend / holiday line ----------------------------------------\n",
    "    m = re.search(\n",
    "        r\"Weekends?/Holidays?\\s*-\\s*(\\d+)\\s+days?,?\\s*([\\d.]+)\\s+hours?\",\n",
    "        text, flags=re.I\n",
    "    )\n",
    "    if m:\n",
    "        we_days, we_hours = int(m.group(1)), float(m.group(2))\n",
    "\n",
    "    # --- extra hours block ---------------------------------------------------\n",
    "    m = re.search(\n",
    "        r\"Extra\\s+hours.*?Weekday\\s*=\\s*([\\d.]+)\\s+hours?\",\n",
    "        text, flags=re.I | re.S\n",
    "    )\n",
    "    if m:\n",
    "        ex_wd_hours = float(m.group(1))\n",
    "\n",
    "    m = re.search(\n",
    "        r\"Extra\\s+hours.*?Weekend/Holidays\\s*=\\s*([\\d.]+)\\s+hours?\",\n",
    "        text, flags=re.I | re.S\n",
    "    )\n",
    "    if m:\n",
    "        ex_we_hours = float(m.group(1))\n",
    "\n",
    "    return pd.Series(\n",
    "        [\n",
    "            wd_days, wd_hours,\n",
    "            we_days, we_hours,\n",
    "            ex_wd_hours, ex_we_hours,\n",
    "        ],\n",
    "        index=[\n",
    "            \"Weekday_Days\", \"Weekday_Hours\",\n",
    "            \"Weekend_Days\", \"Weekend_Hours\",\n",
    "            \"Extra_Weekday_Hours\", \"Extra_Weekend_Hours\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "# Apply to every row\n",
    "oncall_df = oncall_df.join(oncall_df[\"W or H\"].apply(parse_wh_cell))\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3.  Parse the structured columns in the summary workbook\n",
    "# ------------------------------------------------------------------\n",
    "def parse_days_hours(cell: str) -> tuple[int, float]:\n",
    "    \"\"\"Convert '7 days, 3.25 hours'  (7, 3.25).\"\"\"\n",
    "    m = re.match(r\"\\s*(\\d+)\\s+days?,\\s*([\\d.]+)\\s+hours?\", str(cell))\n",
    "    return (int(m.group(1)), float(m.group(2))) if m else (0, 0.0)\n",
    "\n",
    "def parse_hours_only(cell: str) -> float:\n",
    "    \"\"\"Convert '1.50 hours'  1.50.\"\"\"\n",
    "    m = re.match(r\"\\s*([\\d.]+)\\s+hours?\", str(cell))\n",
    "    return float(m.group(1)) if m else 0.0\n",
    "\n",
    "summary_df[[\"Sum_WD_Days\", \"Sum_WD_Hours\"]] = (\n",
    "    summary_df[\"Weekday Count\"].apply(parse_days_hours).apply(pd.Series)\n",
    ")\n",
    "summary_df[[\"Sum_WE_Days\", \"Sum_WE_Hours\"]] = (\n",
    "    summary_df[\"Weekend/Holiday Count\"].apply(parse_days_hours).apply(pd.Series)\n",
    ")\n",
    "summary_df[\"Sum_Extra_WD_Hours\"] = summary_df[\"ExtraWeekday Hours\"].apply(parse_hours_only)\n",
    "summary_df[\"Sum_Extra_WE_Hours\"] = summary_df[\"ExtraWeekendHoliday Hours\"].apply(parse_hours_only)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4.  Merge on employee name\n",
    "# ------------------------------------------------------------------\n",
    "merged = oncall_df.merge(\n",
    "    summary_df,\n",
    "    left_on=\"Employee name\",\n",
    "    right_on=\"Name\",\n",
    "    how=\"inner\",\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 5.  Compute the differences\n",
    "# ------------------------------------------------------------------\n",
    "merged[\"Weekday_Day_Diff\"]   = merged[\"Weekday_Days\"]        - merged[\"Sum_WD_Days\"]\n",
    "merged[\"Weekday_Hour_Diff\"]  = merged[\"Weekday_Hours\"]       - merged[\"Sum_WD_Hours\"]\n",
    "merged[\"Weekend_Day_Diff\"]   = merged[\"Weekend_Days\"]        - merged[\"Sum_WE_Days\"]\n",
    "merged[\"Weekend_Hour_Diff\"]  = merged[\"Weekend_Hours\"]       - merged[\"Sum_WE_Hours\"]\n",
    "merged[\"Extra_WD_Hour_Diff\"] = merged[\"Extra_Weekday_Hours\"] - merged[\"Sum_Extra_WD_Hours\"]\n",
    "merged[\"Extra_WE_Hour_Diff\"] = merged[\"Extra_Weekend_Hours\"] - merged[\"Sum_Extra_WE_Hours\"]\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 6.  REMOVE any employee row where *any* difference is 0.0\n",
    "# ------------------------------------------------------------------\n",
    "diff_cols = [\n",
    "    \"Weekday_Day_Diff\", \"Weekday_Hour_Diff\",\n",
    "    \"Weekend_Day_Diff\", \"Weekend_Hour_Diff\",\n",
    "    \"Extra_WD_Hour_Diff\", \"Extra_WE_Hour_Diff\",\n",
    "]\n",
    "\n",
    "# Keep rows where *all* six differences are nonzero\n",
    "filtered = merged[ (merged[diff_cols] != 0.0).all(axis=1) ]\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 7.  Final output\n",
    "# ------------------------------------------------------------------\n",
    "final_output = filtered[[\"Employee name\"] + diff_cols]\n",
    "\n",
    "# Save to Excel if you wish:\n",
    "# final_output.to_excel(\"/mnt/data/non_zero_diffs.xlsx\", index=False)\n",
    "# print(\"Saved: non_zero_diffs.xlsx\")\n",
    "\n",
    "print(final_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22e8082-b01b-4c7c-9f3d-e467d77e9a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
